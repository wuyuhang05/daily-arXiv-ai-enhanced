<div id=toc></div>

# Table of Contents

- [cs.IR](#cs.IR) [Total: 9]


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [1] [VERIRAG: Healthcare Claim Verification via Statistical Audit in Retrieval-Augmented Generation](https://arxiv.org/abs/2507.17948)
*Shubham Mohole,Hongjun Choi,Shusen Liu,Christine Klymko,Shashank Kushwaha,Derek Shi,Wesam Sakla,Sainyam Galhotra,Ruben Glatt*

Main category: cs.IR

TL;DR: VERIRAG框架通过评估每个证据来源的方法论严谨性，硬变性评分和动态接受阈值，有效提升了RAG系统在临床决策支持中的性能。其测试结果在四个数据集上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前的RAG系统无法评估检索到的科学证据的质量，导致缺乏科学严谨性的研究与高质量的研究被等同对待。

Method: 引入三个新的机制：（i）一个名为Veritable的11项检查表，用于评估每个证据来源的方法严格性；（ii）一个称为Hard-to-Vary (HV) 的评分系统，用于定量聚合和加权证据质量与多样性；（iii）一个动态接受阈值，根据主张的不同寻常程度校准所需证据。

Result: 在四个数据集上，VERIRAG方法的F1得分在0.53到0.65之间，比次优方法提高了10到14分。

Conclusion: VERIRAG在所有基准上均表现优于传统方法，展示了其评价证据科学质量的有效性和重要性。

Abstract: Retrieval-augmented generation (RAG) systems are increasingly adopted in
clinical decision support, yet they remain methodologically blind-they retrieve
evidence but cannot vet its scientific quality. A paper claiming "Antioxidant
proteins decreased after alloferon treatment" and a rigorous multi-laboratory
replication study will be treated as equally credible, even if the former
lacked scientific rigor or was even retracted. To address this challenge, we
introduce VERIRAG, a framework that makes three notable contributions: (i) the
Veritable, an 11-point checklist that evaluates each source for methodological
rigor, including data integrity and statistical validity; (ii) a Hard-to-Vary
(HV) Score, a quantitative aggregator that weights evidence by its quality and
diversity; and (iii) a Dynamic Acceptance Threshold, which calibrates the
required evidence based on how extraordinary a claim is. Across four
datasets-comprising retracted, conflicting, comprehensive, and settled science
corpora-the VERIRAG approach consistently outperforms all baselines, achieving
absolute F1 scores ranging from 0.53 to 0.65, representing a 10 to 14 point
improvement over the next-best method in each respective dataset. We will
release all materials necessary for reproducing our results.

</details>


### [2] [Failure Prediction in Conversational Recommendation Systems](https://arxiv.org/abs/2507.17976)
*Maria Vlachou*

Main category: cs.IR

TL;DR: 提出了一种基于AutoEncoder的预测器，用于会话图像推荐任务中的性能预测，实验表明其在系统失败预测上效果不错，但在目录失败预测上效果较差。


<details>
  <summary>Details</summary>
Motivation: 在会话图像推荐任务中，用户可能会面临寻找目标物品失败的情况，导致用户需要进行更多交互，从而造成挫败感。本文的目标是设计一个任务来预测会话性能，以减少这种情况的发生。

Method: 使用基于AutoEncoder的预测器，通过学习训练轮次中最高检索项目的压缩表示，并结合分类标签来预测评估轮次。

Result: 实验结果表明，所提出的预测器在预测系统失败时表现良好，但是在预测目录失败的情况下表现较差。

Conclusion: 该研究表明提出的用于预测系统失败的预测器具有良好的效果，但在目录失败的情况下预测性能明显下降。

Abstract: In a Conversational Image Recommendation task, users can provide natural
language feedback on a recommended image item, which leads to an improved
recommendation in the next turn. While typical instantiations of this task
assume that the user's target item will (eventually) be returned, this might
often not be true, for example, the item the user seeks is not within the item
catalogue. Failing to return a user's desired item can lead to user
frustration, as the user needs to interact with the system for an increased
number of turns. To mitigate this issue, in this paper, we introduce the task
of Supervised Conversational Performance Prediction, inspired by Query
Performance Prediction (QPP) for predicting effectiveness in response to a
search engine query. In this regard, we propose predictors for conversational
performance that detect conversation failures using multi-turn semantic
information contained in the embedded representations of retrieved image items.
Specifically, our AutoEncoder-based predictor learns a compressed
representation of top-retrieved items of the train turns and uses the
classification labels to predict the evaluation turn. Our evaluation scenario
addressed two recommendation scenarios, by differentiating between system
failure, where the system is unable to find the target, and catalogue failure,
where the target does not exist in the item catalogue. In our experiments using
the Shoes and FashionIQ Dresses datasets, we measure the accuracy of predictors
for both system and catalogue failures. Our results demonstrate the promise of
our proposed predictors for predicting system failures (existing evaluation
scenario), while we detect a considerable decrease in predictive performance in
the case of catalogue failure prediction (when inducing a missing item
scenario) compared to system failures.

</details>


### [3] [Fashion-AlterEval: A Dataset for Improved Evaluation of Conversational Recommendation Systems with Alternative Relevant Items](https://arxiv.org/abs/2507.18017)
*Maria Vlachou*

Main category: cs.IR

TL;DR: 通过新的数据集和用户模拟器，改进了CRS的评价，使系统更快满足用户需求。


<details>
  <summary>Details</summary>
Motivation: 现有用户模拟器仅关注单一目标项目，无法准确评估CRS系统的有效性，特别是在用户可考虑多个替代项目的情况下。

Method: 提出Fashion-AlterEval数据集，通过增加新的注释以包含人类判断，并开发了两个新颖的元用户模拟器，以更准确地模拟用户在不同项目中的偏好和耐心变化。

Result: 实验表明，利用模拟器的替代知识可以显著影响CRS模型的评价，现有单一目标评价低估了CRS的有效性，而允许用户考虑替代相关项时，系统能更快响应以满足用户。

Conclusion: 通过采用新的Fashion-AlterEval数据集和两种新颖的元用户模拟器，对CRS模型的评价大大提高，实现了快速满足用户需求的能力。

Abstract: In Conversational Recommendation Systems (CRS), a user provides feedback on
recommended items at each turn, leading the CRS towards improved
recommendations. Due to the need for a large amount of data, a user simulator
is employed for both training and evaluation. Such user simulators critique the
current retrieved item based on knowledge of a single target item. However,
system evaluation in offline settings with simulators is limited by the focus
on a single target item and their unlimited patience over a large number of
turns. To overcome these limitations of existing simulators, we propose
Fashion-AlterEval, a new dataset that contains human judgments for a selection
of alternative items by adding new annotations in common fashion CRS datasets.
Consequently, we propose two novel meta-user simulators that use the collected
judgments and allow simulated users not only to express their preferences about
alternative items to their original target, but also to change their mind and
level of patience. In our experiments using the Shoes and Fashion IQ as the
original datasets and three CRS models, we find that using the knowledge of
alternatives by the simulator can have a considerable impact on the evaluation
of existing CRS models, specifically that the existing single-target evaluation
underestimates their effectiveness, and when simulatedusers are allowed to
instead consider alternative relevant items, the system can rapidly respond to
more quickly satisfy the user.

</details>


### [4] [RecPS: Privacy Risk Scoring for Recommender Systems](https://arxiv.org/abs/2507.18365)
*Jiajie He,Yuechun Gu,Keke Chen*

Main category: cs.IR

TL;DR: 本文提出RecPS，通过MIA来量化推荐系统中的隐私风险，以提高隐私保护能力，并展示了在风险评估和模型去学习中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的推荐系统依赖于敏感的用户-物品交互数据，缺乏量化不同交互敏感性的方法。因此，量化推荐系统训练数据的隐私风险对隐私敏感的系统开发和部署至关重要。

Method: 通过MIA（membership-inference attack）的隐私评分方法RecPS测量交互和用户层面的隐私风险，交互层面的评分基于差分隐私，扩展到用户层面。关键组件是RecLiRA方法，用于高质量的成员估算。

Result: 实验表明，RecPS评分在风险评估和推荐系统模型去学习方面有显著效果。

Conclusion: 提出RecPS方法，通过MIA的隐私评分，量化和评估RecSys的隐私风险，为用户提供不共享敏感数据的选择权。经过实验验证，该方法在风险评估和模型去学习方面具有独特优势。

Abstract: Recommender systems (RecSys) have become an essential component of many web
applications. The core of the system is a recommendation model trained on
highly sensitive user-item interaction data. While privacy-enhancing techniques
are actively studied in the research community, the real-world model
development still depends on minimal privacy protection, e.g., via controlled
access. Users of such systems should have the right to choose \emph{not} to
share highly sensitive interactions. However, there is no method allowing the
user to know which interactions are more sensitive than others. Thus,
quantifying the privacy risk of RecSys training data is a critical step to
enabling privacy-aware RecSys model development and deployment. We propose a
membership-inference attack (MIA)- based privacy scoring method, RecPS, to
measure privacy risks at both the interaction and user levels. The RecPS
interaction-level score definition is motivated and derived from differential
privacy, which is then extended to the user-level scoring method. A critical
component is the interaction-level MIA method RecLiRA, which gives high-quality
membership estimation. We have conducted extensive experiments on well-known
benchmark datasets and RecSys models to show the unique features and benefits
of RecPS scoring in risk assessment and RecSys model unlearning. Our code is
available at https://anonymous.4open.science/r/RsLiRA-4BD3/readme.md.

</details>


### [5] [LLM-based Embedders for Prior Case Retrieval](https://arxiv.org/abs/2507.18455)
*Damith Premasiri,Tharindu Ranasinghe,Ruslan Mitkov*

Main category: cs.IR

TL;DR: 本文通过使用LLM-based文本嵌入技术，解决了先例检索中长文本输入和缺乏训练数据的问题，性能优于BM25和传统transformer模型。


<details>
  <summary>Details</summary>
Motivation: 在普通法系中，法律专业人士依赖先例来构建他们的论点。随着案件数量的急剧增加，如何有效地检索过往案例变得至关重要。然而，目前的大多数先例检索（PCR）方法依旧依赖于传统的信息检索技术如BM25，而最新的深度学习信息检索方法在PCR中未能取得成功。

Method: 研究通过利用基于大规模语言模型（LLM）的文本嵌入技术来应对PCR中的挑战，这些嵌入器能够支持较长的输入长度，并且可以以无监督的方式使用，不需要训练数据。

Result: 在四个PCR基准数据集上评估了先进的LLM-based文本嵌入器，结果表明它们优于BM25和以监督方式训练的基于transformer的模型。

Conclusion: 利用LLM-based文本嵌入器可以有效解决PCR中的长文本输入限制和缺乏法律训练数据的问题，从而在先例检索任务中取得显著的效果提升。

Abstract: In common law systems, legal professionals such as lawyers and judges rely on
precedents to build their arguments. As the volume of cases has grown massively
over time, effectively retrieving prior cases has become essential. Prior case
retrieval (PCR) is an information retrieval (IR) task that aims to
automatically identify the most relevant court cases for a specific query from
a large pool of potential candidates. While IR methods have seen several
paradigm shifts over the last few years, the vast majority of PCR methods
continue to rely on traditional IR methods, such as BM25. The state-of-the-art
deep learning IR methods have not been successful in PCR due to two key
challenges: i. Lengthy legal text limitation; when using the powerful
BERT-based transformer models, there is a limit of input text lengths, which
inevitably requires to shorten the input via truncation or division with a loss
of legal context information. ii. Lack of legal training data; due to data
privacy concerns, available PCR datasets are often limited in size, making it
difficult to train deep learning-based models effectively. In this research, we
address these challenges by leveraging LLM-based text embedders in PCR.
LLM-based embedders support longer input lengths, and since we use them in an
unsupervised manner, they do not require training data, addressing both
challenges simultaneously. In this paper, we evaluate state-of-the-art
LLM-based text embedders in four PCR benchmark datasets and show that they
outperform BM25 and supervised transformer-based models.

</details>


### [6] [How Well Do LLMs Predict Prerequisite Skills? Zero-Shot Comparison to Expert-Defined Concepts](https://arxiv.org/abs/2507.18479)
*Ngoc Luyen Le,Marie-Hélène Abel*

Main category: cs.IR

TL;DR: 研究探讨了LLMs在零样本场景下预测前提技能的能力，结果显示多种先进的LLMs能够在没有监督的情况下，准确预测前提技能，这可能支持个性化学习和智能辅导等应用。


<details>
  <summary>Details</summary>
Motivation: 前提技能对于有效学习、评估和技能缺口分析非常重要。然而，传统上由领域专家策划的这些关系难以维护且难以扩展。因此，研究探讨LLMs能否在不进行特定任务微调的情况下，仅利用自然语言描述预测前提技能。

Method: 使用标准化的提示策略，并利用13种最先进的LLMs进行实验，包括GPT-4、Claude 3、Gemini、LLaMA 4、Qwen2和DeepSeek，评估其在语义相似性、BERTScore和推理延迟方面的表现。

Result: 研究结果表明，像LLaMA4-Maverick、Claude-3-7-Sonnet和Qwen2-72B等模型能够产生与专家定义的前提技能关系一致的预测。

Conclusion: 研究表明，LLMs可以在零样本场景下预测前提技能，与专家定义的标准相符，展示出在没有监督的情况下的强大语义推理能力。

Abstract: Prerequisite skills - foundational competencies required before mastering
more advanced concepts - are important for supporting effective learning,
assessment, and skill-gap analysis. Traditionally curated by domain experts,
these relationships are costly to maintain and difficult to scale. This paper
investigates whether large language models (LLMs) can predict prerequisite
skills in a zero-shot setting, using only natural language descriptions and
without task-specific fine-tuning. We introduce ESCO-PrereqSkill, a benchmark
dataset constructed from the ESCO taxonomy, comprising 3,196 skills and their
expert-defined prerequisite links. Using a standardized prompting strategy, we
evaluate 13 state-of-the-art LLMs, including GPT-4, Claude 3, Gemini, LLaMA 4,
Qwen2, and DeepSeek, across semantic similarity, BERTScore, and inference
latency. Our results show that models such as LLaMA4-Maverick,
Claude-3-7-Sonnet, and Qwen2-72B generate predictions that closely align with
expert ground truth, demonstrating strong semantic reasoning without
supervision. These findings highlight the potential of LLMs to support scalable
prerequisite skill modeling for applications in personalized learning,
intelligent tutoring, and skill-based recommender systems.

</details>


### [7] [The Best is Yet to Come: Graph Convolution in the Testing Phase for Multimodal Recommendation](https://arxiv.org/abs/2507.18489)
*Jinfeng Xu,Zheyu Chen,Shuo Yang,Jinze Li,Edith C. H. Ngai*

Main category: cs.IR

TL;DR: 提出FastMMRec框架，在测试阶段使用图卷积网络，提高推荐系统的效率和可扩展性，并在实验中证明了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 图卷积网络在推荐系统训练中的效率和可扩展性问题，以及不同模态间的隔离问题。

Method: 提出FastMMRec框架，并在测试阶段使用图卷积网络以提高效率和可扩展性。

Result: 在三个公共数据集上的实验表明，FastMMRec在性能上优于竞争基准，同时实现了效率和可扩展性。

Conclusion: FastMMRec在测试阶段使用图卷积网络，避免了训练阶段的高时间和空间成本，提高了推荐系统的效率和可扩展性，同时减少了不同模态间的隔离。

Abstract: The efficiency and scalability of graph convolution networks (GCNs) in
training recommender systems remain critical challenges, hindering their
practical deployment in real-world scenarios. In the multimodal recommendation
(MMRec) field, training GCNs requires more expensive time and space costs and
exacerbates the gap between different modalities, resulting in sub-optimal
recommendation accuracy. This paper critically points out the inherent
challenges associated with adopting GCNs during the training phase in MMRec,
revealing that GCNs inevitably create unhelpful and even harmful pairs during
model optimization and isolate different modalities. To this end, we propose
FastMMRec, a highly efficient multimodal recommendation framework that deploys
graph convolutions exclusively during the testing phase, bypassing their use in
training. We demonstrate that adopting GCNs solely in the testing phase
significantly improves the model's efficiency and scalability while alleviating
the modality isolation problem often caused by using GCNs during the training
phase. We conduct extensive experiments on three public datasets, consistently
demonstrating the performance superiority of FastMMRec over competitive
baselines while achieving efficiency and scalability.

</details>


### [8] [Transform Before You Query: A Privacy-Preserving Approach for Vector Retrieval with Embedding Space Alignment](https://arxiv.org/abs/2507.18518)
*Ruiqi He,Zekun Fei,Jiaqi Li,Xinyuan Zhu,Biao Yi,Siyi Lv,Weijie Liu,Zheli Liu*

Main category: cs.IR

TL;DR: STEER框架可以利用近似嵌入保护用户查询隐私，且在几乎不影响准确性的基础上，大幅优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前的VDB服务提供商主要使用专有的黑盒模型，用户必须通过API暴露原始查询文本以换取向量检索服务，尤其是当查询涉及机密记录时，这会导致敏感信息泄露。

Method: 提出一种称为STEER的私人向量检索框架，该框架利用不同嵌入模型语义空间之间的对齐关系来派生查询文本的近似嵌入。

Result: 实验结果显示，STEER在检索准确性方面基本仅下降不到5%。即使在数百万条目中进行搜索，STEER的Recall@20准确度也比当前基线高出20%。

Conclusion: STEER能在不修改服务器的情况下，有效保护查询文本的隐私，同时保持检索准确性。即使近似嵌入是专有模型嵌入的近似值，它们仍阻止提供商通过嵌入反演攻击恢复查询文本。

Abstract: Vector Database (VDB) can efficiently index and search high-dimensional
vector embeddings from unstructured data, crucially enabling fast semantic
similarity search essential for modern AI applications like generative AI and
recommendation systems. Since current VDB service providers predominantly use
proprietary black-box models, users are forced to expose raw query text to them
via API in exchange for the vector retrieval services. Consequently, if query
text involves confidential records from finance or healthcare domains, this
mechanism inevitably leads to critical leakage of user's sensitive information.
To address this issue, we introduce STEER (\textbf{S}ecure \textbf{T}ransformed
\textbf{E}mbedding v\textbf{E}ctor\textbf{ R}etrieval), a private vector
retrieval framework that leverages the alignment relationship between the
semantic spaces of different embedding models to derive approximate embeddings
for the query text. STEER performs the retrieval using the approximate
embeddings within the original VDB and requires no modifications to the server
side. Our theoretical and experimental analyses demonstrate that STEER
effectively safeguards query text privacy while maintaining the retrieval
accuracy. Even though approximate embeddings are approximations of the
embeddings from proprietary models, they still prevent the providers from
recovering the query text through Embedding Inversion Attacks (EIAs). Extensive
experimental results show that Recall@100 of STEER can basically achieve a
decrease of less than 5\%. Furthermore, even when searching within a text
corpus of millions of entries, STEER achieves a Recall@20 accuracy 20\% higher
than current baselines.

</details>


### [9] [DR.EHR: Dense Retrieval for Electronic Health Record with Knowledge Injection and Synthetic Data](https://arxiv.org/abs/2507.18583)
*Zhengyun Zhao,Huaiyuan Ying,Yue Zhong,Sheng Yu*

Main category: cs.IR

TL;DR: 开发了专为EHR检索设计的DR.EHR模型，提出了两阶段训练流程，显著提升了检索性能，特别是在处理复杂语义匹配时。


<details>
  <summary>Details</summary>
Motivation: 现有的密集检索模型在EHR检索中存在医学知识不足或训练语料不匹配的问题。

Method: 本文提出了一个两阶段训练流程，首先进行医学实体提取和来自生物医学知识图谱的知识注入，然后利用大型语言模型生成多样化的训练数据。

Result: 我们的DR.EHR模型在CliniQ基准测试中显著超越了所有现有的密集检索器，获得了最新的结果，并在多种匹配和查询类型下表现出色。

Conclusion: 我们开发的密集检索模型DR.EHR在EHR检索中表现优异，显著优于现有的检索模型，并证明其在不同语义匹配和查询类型上的优越性。

Abstract: Electronic Health Records (EHRs) are pivotal in clinical practices, yet their
retrieval remains a challenge mainly due to semantic gap issues. Recent
advancements in dense retrieval offer promising solutions but existing models,
both general-domain and biomedical-domain, fall short due to insufficient
medical knowledge or mismatched training corpora. This paper introduces
\texttt{DR.EHR}, a series of dense retrieval models specifically tailored for
EHR retrieval. We propose a two-stage training pipeline utilizing MIMIC-IV
discharge summaries to address the need for extensive medical knowledge and
large-scale training data. The first stage involves medical entity extraction
and knowledge injection from a biomedical knowledge graph, while the second
stage employs large language models to generate diverse training data. We train
two variants of \texttt{DR.EHR}, with 110M and 7B parameters, respectively.
Evaluated on the CliniQ benchmark, our models significantly outperforms all
existing dense retrievers, achieving state-of-the-art results. Detailed
analyses confirm our models' superiority across various match and query types,
particularly in challenging semantic matches like implication and abbreviation.
Ablation studies validate the effectiveness of each pipeline component, and
supplementary experiments on EHR QA datasets demonstrate the models'
generalizability on natural language questions, including complex ones with
multiple entities. This work significantly advances EHR retrieval, offering a
robust solution for clinical applications.

</details>
