<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 91]
- [cs.CL](#cs.CL) [Total: 58]
- [cs.IR](#cs.IR) [Total: 13]
- [cs.AI](#cs.AI) [Total: 70]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [GAITEX: Human motion dataset from impaired gait and rehabilitation exercises of inertial and optical sensor data](https://arxiv.org/abs/2507.21069)
*Andreas Spilz,Heiko Oppel,Jochen Werner,Kathrin Stucke-Straub,Felix Capanni,Michael Munz*

Main category: cs.CV

TL;DR: 提供了一种可穿戴传感器数据集以支持机器学习模型开发，用于人体运动分析。


<details>
  <summary>Details</summary>
Motivation: 传感器模型的开发需要大量多样化的数据集，这些数据集的收集既昂贵又耗时。我们旨在提供一个高质量的开放资源数据集来支持此类研究。

Method: 数据集录制涉及使用同步IMU和标记式运动捕捉系统记录19名参与者的运动。每个IMU设备配备四个光学标记，以比较IMU导出的方向估计与MoCap系统的参考值。这些数据支持机器学习模型开发及验证。

Result: 提供了一组丰富的传感器数据，包括原始的IMU数据、处理后的方向估计和逆运动学结果，以支持机器学习模型的开发和验证。

Conclusion: 我们提出了一种多模态数据集，包含针对物理治疗练习和步态分析的传感器数据，旨在加速机器学习驱动的人体运动分析研究。

Abstract: Wearable inertial measurement units (IMUs) offer a cost-effective and
scalable means to assess human movement quality in clinical and everyday
settings. However, the development of robust sensor-based classification models
for physiotherapeutic exercises and gait analysis requires large, diverse
datasets, which are costly and time-consuming to collect. Here, we present a
multimodal dataset of physiotherapeutic exercises - including correct and
clinically relevant variants - and gait-related exercises - including both
normal and impaired gait patterns - recorded from 19 participants using
synchronized IMUs and marker-based motion capture (MoCap). The dataset includes
raw data from nine IMUs and thirty-five optical markers capturing full-body
kinematics. Each IMU is additionally equipped with four optical markers,
enabling precise comparison between IMU-derived orientation estimates and
reference values from the MoCap system. To support further analysis, we also
provide processed IMU orientations aligned with common segment coordinate
systems, subject-specific OpenSim models, inverse kinematics results, and tools
for visualizing IMU orientations in the musculoskeletal context. Detailed
annotations of movement execution quality and time-stamped segmentations
support diverse analysis goals. This dataset supports the development and
benchmarking of machine learning models for tasks such as automatic exercise
evaluation, gait analysis, temporal activity segmentation, and biomechanical
parameter estimation. To facilitate reproducibility, we provide code for
postprocessing, sensor-to-segment alignment, inverse kinematics computation,
and technical validation. This resource is intended to accelerate research in
machine learning-driven human movement analysis.

</details>


### [2] [Seeing Beyond Frames: Zero-Shot Pedestrian Intention Prediction with Raw Temporal Video and Multimodal Cues](https://arxiv.org/abs/2507.21161)
*Pallavi Zambare,Venkata Nikhil Thanikella,Ying Liu*

Main category: cs.CV

TL;DR: BF-PIP是一种基于Gemini 2.5 Pro的零样本行人意图预测方法，通过结合连续视频和多模态数据，在无训练条件下优于GPT-4V，预测准确率达73%。


<details>
  <summary>Details</summary>
Motivation: 在复杂城市环境中，实现自动驾驶需要准确预测行人意图，传统方法依赖于监督学习和大量重新训练来适应新场景，效果有限。因此，本文提出通过时间序列信息和多模态数据改善预测的方法。

Method: 本文提出的BF-PIP方法基于Gemini 2.5 Pro，采用零样本学习技术，通过短时连续视频片段和JAAD元数据的结合进行行人过马路意图的预测。相比于基于GPT-4V的离散帧方法，BF-PIP处理的是连续时间片段。同时，该方法还结合了边框注释和自车速度信息，以多模态提示为基础进行推断。

Result: BF-PIP方法在无需附加训练的情况下实现了73%的预测准确率，比GPT-4V基线高出18%，显示出优越的预测性能。

Conclusion: BF-PIP方法通过结合时间序列视频输入和上下文提示，能够在不经过额外训练的情况下提升复杂环境下的行人意图预测能力。

Abstract: Pedestrian intention prediction is essential for autonomous driving in
complex urban environments. Conventional approaches depend on supervised
learning over frame sequences and require extensive retraining to adapt to new
scenarios. Here, we introduce BF-PIP (Beyond Frames Pedestrian Intention
Prediction), a zero-shot approach built upon Gemini 2.5 Pro. It infers crossing
intentions directly from short, continuous video clips enriched with structured
JAAD metadata. In contrast to GPT-4V based methods that operate on discrete
frames, BF-PIP processes uninterrupted temporal clips. It also incorporates
bounding-box annotations and ego-vehicle speed via specialized multimodal
prompts. Without any additional training, BF-PIP achieves 73% prediction
accuracy, outperforming a GPT-4V baseline by 18 %. These findings illustrate
that combining temporal video inputs with contextual cues enhances
spatiotemporal perception and improves intent inference under ambiguous
conditions. This approach paves the way for agile, retraining-free perception
module in intelligent transportation system.

</details>


### [3] [ChartM$^3$: Benchmarking Chart Editing with Multimodal Instructions](https://arxiv.org/abs/2507.21167)
*Danglu Yang,Liang Zhang,Zihao Yue,Liangyu Chen,Yichen Xu,Wenxuan Wang,Qin Jin*

Main category: cs.CV

TL;DR: 引入多模态图表编辑方法和基准ChartM3，通过视觉和语言结合改善图表编辑，微调模型显示效果明显提升。


<details>
  <summary>Details</summary>
Motivation: 现有的图表编辑方法依赖于自然语言指令，难以支持细粒度编辑，需要结合视觉指标改善。

Method: 结合自然语言和视觉指标进行多模态图表编辑，并提供一个新的基准ChartM3进行评估。

Result: 通过在ChartM3-Train数据集上微调多模态大型语言模型，显著提升了模型在图表编辑中的表现。

Conclusion: 提出了ChartM3作为多模态图表编辑的基准，强调通过多模态监督可以有效改进图表编辑模型。

Abstract: Charts are a fundamental visualization format widely used in data analysis
across research and industry. While enabling users to edit charts based on
high-level intentions is of great practical value, existing methods primarily
rely on natural language instructions, which are often too ambiguous to support
fine-grained editing. In this work, we introduce a novel paradigm for
multimodal chart editing, where user intent is expressed through a combination
of natural language and visual indicators that explicitly highlight the
elements to be modified. To support this paradigm, we present
Chart$\text{M}^3$, a new benchmark for Multimodal chart editing with
Multi-level complexity and Multi-perspective evaluation. Chart$\text{M}^3$
contains 1,000 samples spanning four levels of editing difficulty. Each sample
includes triplets in the form of (chart, code, multimodal instructions). To
comprehensively evaluate chart editing models, Chart$\text{M}^3$ provides
metrics that assess both visual appearance and code correctness. Our benchmark
reveals significant limitations in current multimodal large language models
(MLLMs), including GPT-4o, particularly in their ability to interpret and act
on visual indicators. To address this, we construct Chart$\text{M}^3$-Train, a
large-scale training set with 24,000 multimodal chart editing samples.
Fine-tuning MLLMs on this dataset leads to substantial improvements,
demonstrating the importance of multimodal supervision in building practical
chart editing systems. Our datasets, codes, and evaluation tools are available
at https://github.com/MLrollIT/ChartM3. %https://github.com/MLrollIT/ChartM3Our
datasets, codes, and evaluation tools are available at
https://github.com/yaolinli/VCE.

</details>


### [4] [PanoGAN A Deep Generative Model for Panoramic Dental Radiographs](https://arxiv.org/abs/2507.21200)
*Soren Pedersen,Sanyam Jain,Mikkel Chavez,Viktor Ladehoff,Bruna Neves de Freitas,Ruben Pauwels*

Main category: cs.CV

TL;DR: 研究开发了用于合成牙科全景辐射照相的GAN，解决了牙科数据稀缺问题，模型表现为在细节和整体清晰度上的权衡。


<details>
  <summary>Details</summary>
Motivation: 应对牙科研究和教育中数据稀缺的问题。

Method: 使用深度卷积GAN（DCGAN），采用Waterstein损失和梯度惩罚（WGANGP）进行训练，数据集包括2322张不同质量的辐射照相，重点在牙槽区的辐射照相合成。

Result: 生成的辐射照相图像在解剖结构的可见性和现实感上获得较中等水平的评价，非去噪数据训练的模型在结构细节上有更好的表现，而去噪数据训练的模型则在整体图像清晰度上更优。

Conclusion: 本研究展示了使用生成对抗网络（GAN）合成牙科全景辐射照相的方法，尽管探索性研究性质，但着眼于解决牙科研究和教育中数据稀缺的问题。研究结果为未来的牙科影像中的GAN方法奠定了基础。

Abstract: This paper presents the development of a generative adversarial network (GAN)
for synthesizing dental panoramic radiographs. Although exploratory in nature,
the study aims to address the scarcity of data in dental research and
education. We trained a deep convolutional GAN (DCGAN) using a Wasserstein loss
with gradient penalty (WGANGP) on a dataset of 2322 radiographs of varying
quality. The focus was on the dentoalveolar regions, other anatomical
structures were cropped out. Extensive preprocessing and data cleaning were
performed to standardize the inputs while preserving anatomical variability. We
explored four candidate models by varying critic iterations, feature depth, and
the use of denoising prior to training. A clinical expert evaluated the
generated radiographs based on anatomical visibility and realism, using a
5-point scale (1 very poor 5 excellent). Most images showed moderate anatomical
depiction, although some were degraded by artifacts. A trade-off was observed
the model trained on non-denoised data yielded finer details especially in
structures like the mandibular canal and trabecular bone, while a model trained
on denoised data offered superior overall image clarity and sharpness. These
findings provide a foundation for future work on GAN-based methods in dental
imaging.

</details>


### [5] [On Explaining Visual Captioning with Hybrid Markov Logic Networks](https://arxiv.org/abs/2507.21246)
*Monika Shah,Somdeb Sarkhel,Deepak Venugopal*

Main category: cs.CV

TL;DR: 提出了一种新的解释框架，利用混合马尔可夫逻辑网络解释深度神经网络在生成图像标题时的信息整合。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在多模态任务中取得了显著进步，但如何解释这些模型是如何整合各种信息生成图像标题仍然是个挑战，因此需要一种新的解释框架来提供深刻的洞察力。

Method: 使用混合马尔可夫逻辑网络（HMLNs），该网络结合符号规则与实值函数，以学习训练实例上的分布，并通过对生成的样本进行条件推理来量化哪些实例可能为生成观察到的标题提供了丰富信息。

Result: 在Amazon Mechanical Turk上对几个最先进的图像标题生成模型进行的实验展示了我们的解释的可解释性，并允许我们在可解释性维度上比较这些模型。

Conclusion: 该研究通过开发基于混合马尔可夫逻辑网络（HMLNs）的解释框架来解释深度神经网络（DNNs）在多模态任务中如何综合视觉信息、语言信息和知识表示生成有意义的图像标题。

Abstract: Deep Neural Networks (DNNs) have made tremendous progress in multimodal tasks
such as image captioning. However, explaining/interpreting how these models
integrate visual information, language information and knowledge representation
to generate meaningful captions remains a challenging problem. Standard metrics
to measure performance typically rely on comparing generated captions with
human-written ones that may not provide a user with a deep insights into this
integration. In this work, we develop a novel explanation framework that is
easily interpretable based on Hybrid Markov Logic Networks (HMLNs) - a language
that can combine symbolic rules with real-valued functions - where we
hypothesize how relevant examples from the training data could have influenced
the generation of the observed caption. To do this, we learn a HMLN
distribution over the training instances and infer the shift in distributions
over these instances when we condition on the generated sample which allows us
to quantify which examples may have been a source of richer information to
generate the observed caption. Our experiments on captions generated for
several state-of-the-art captioning models using Amazon Mechanical Turk
illustrate the interpretability of our explanations, and allow us to compare
these models along the dimension of explainability.

</details>


### [6] [Dual Guidance Semi-Supervised Action Detection](https://arxiv.org/abs/2507.21247)
*Ankit Singh,Efstratios Gavves,Cees G. M. Snoek,Hilde Kuehne*

Main category: cs.CV

TL;DR: 提出了一种用于空间-时间动作定位的半监督学习方法，通过双重引导网络选择伪边界框，取得了优于基线的结果。


<details>
  <summary>Details</summary>
Motivation: 在深度学习模型中，当标注难以获取时，半监督学习显示了巨大的潜力。但目前为止，半监督学习主要应用于图像分类领域。本文研究其在空间-时间动作定位中的应用。

Method: 本文引入了一种双重引导网络，将帧级分类与边界框预测结合，以跨帧和边框强化动作类别一致性，从而选择更好的伪边界框。

Result: 实验结果表明，在UCF101-24、J-HMDB-21和AVA等知名空间-时间动作定位数据集上，我们提出的模块显著提高了模型的性能。

Conclusion: 本文提出的双重引导网络在空间-时间动作定位任务中有效提升了模型在有限标签数据集中的表现，优于扩展的基于图像的半监督基线。

Abstract: Semi-Supervised Learning (SSL) has shown tremendous potential to improve the
predictive performance of deep learning models when annotations are hard to
obtain. However, the application of SSL has so far been mainly studied in the
context of image classification. In this work, we present a semi-supervised
approach for spatial-temporal action localization. We introduce a dual guidance
network to select better pseudo-bounding boxes. It combines a frame-level
classification with a bounding-box prediction to enforce action class
consistency across frames and boxes. Our evaluation across well-known
spatial-temporal action localization datasets, namely UCF101-24 , J-HMDB-21 and
AVA shows that the proposed module considerably enhances the model's
performance in limited labeled data settings. Our framework achieves superior
results compared to extended image-based semi-supervised baselines.

</details>


### [7] [Tracking Moose using Aerial Object Detection](https://arxiv.org/abs/2507.21256)
*Christopher Indris,Raiyan Rahman,Goetz Bramesfeld,Guanghui Wang*

Main category: cs.CV

TL;DR: 本文研究了有限计算能力无人机环境下的小型目标检测，通过分块增强技术提高不同目标检测器的检测效果，分析表明简单模型表现良好。数据集和模型将公开。


<details>
  <summary>Details</summary>
Motivation: 飞机上的野生动物跟踪对于保护工作至关重要，需要检测地面上的小型目标。这项工作面临技术挑战：有人驾驶飞机昂贵、有风险且具有破坏性；而自主无人机的机载AI系统计算能力有限。由于目标对象可能仅在几个像素宽度上出现，小型目标检测是一个计算机视觉领域中固有的挑战，并需要考虑计算效率。

Method: 本文使用了一种分块增强技术应用于数据集，以研究模型在各种设置下的性能。进行了三种常见但架构不同的目标检测器的比较研究，通过改变分块方法的超参数来衡量检测准确性。

Result: 每个模型至少在一种分块配置下达到了93%的mAP@IoU=0.5。统计分析提供了各种因素影响的深入评论。分析还表明，对于这项任务，较快且简单的模型与需要更多计算能力的模型效果相当，并且在有限的分块规模下表现良好，鼓励无人机的部署。

Conclusion: 研究表明，在有限计算能力的环境下，使用快速且简单的模型，可以实现有效的小型目标检测，促进无人机在野生动物跟踪中使用。本文的研究推广了检测模型和数据集的适配性，提供了对各种架构和参数的全面统计分析。

Abstract: Aerial wildlife tracking is critical for conservation efforts and relies on
detecting small objects on the ground below the aircraft. It presents technical
challenges: crewed aircraft are expensive, risky and disruptive; autonomous
drones have limited computational capacity for onboard AI systems. Since the
objects of interest may appear only a few pixels wide, small object detection
is an inherently challenging computer vision subfield compounded by
computational efficiency needs. This paper applies a patching augmentation to
datasets to study model performance under various settings. A comparative study
of three common yet architecturally diverse object detectors is conducted using
the data, varying the patching method's hyperparameters against detection
accuracy. Each model achieved at least 93\% mAP@IoU=0.5 on at least one
patching configuration. Statistical analyses provide an in-depth commentary on
the effects of various factors. Analysis also shows that faster, simpler models
are about as effective as models that require more computational power for this
task and perform well given limited patch scales, encouraging UAV deployment.
Datasets and models will be made available via
https://github.com/chrisindris/Moose.

</details>


### [8] [HDR Environment Map Estimation with Latent Diffusion Models](https://arxiv.org/abs/2507.21261)
*Jack Hilliard,Adrian Hilton,Jean-Yves Guillemaut*

Main category: cs.CV

TL;DR: 本文通过引入潜在扩散模型和PanoDiT网络提高了单视图HDR环境图估计的质量，解决了ERP表示中的变形和接缝问题。


<details>
  <summary>Details</summary>
Motivation: 现有的环境图估计方法在使用ERP表示时存在极点变形和侧边接缝问题，本文旨在解决这些问题并提升环境图的质量和准确性。

Method: 本文采用了潜在扩散模型（LDM）以及ERP卷积填充的潜在自动编码器，提出了PanoDiT网络来适应ERP格式。

Result: 我们的模型能够生成高质量的环境图，与现有的先进方法在图像质量和灯光准确性方面竞争。

Conclusion: 本文提出了一种新颖的方法，通过利用潜在扩散模型（LDM）来估计HDR环境图，从而提高了在单视图图像处理中环境图估计的质量和可信度。

Abstract: We advance the field of HDR environment map estimation from a single-view
image by establishing a novel approach leveraging the Latent Diffusion Model
(LDM) to produce high-quality environment maps that can plausibly light
mirror-reflective surfaces. A common issue when using the ERP representation,
the format used by the vast majority of approaches, is distortions at the poles
and a seam at the sides of the environment map. We remove the border seam
artefact by proposing an ERP convolutional padding in the latent autoencoder.
Additionally, we investigate whether adapting the diffusion network
architecture to the ERP format can improve the quality and accuracy of the
estimated environment map by proposing a panoramically-adapted Diffusion
Transformer architecture. Our proposed PanoDiT network reduces ERP distortions
and artefacts, but at the cost of image quality and plausibility. We evaluate
with standard benchmarks to demonstrate that our models estimate high-quality
environment maps that perform competitively with state-of-the-art approaches in
both image quality and lighting accuracy.

</details>


### [9] [Fairness and Robustness of CLIP-Based Models for Chest X-rays](https://arxiv.org/abs/2507.21291)
*Théo Sourget,David Restrepo,Céline Hudelot,Enzo Ferrante,Stergios Christodoulidis,Maria Vakalopoulou*

Main category: cs.CV

TL;DR: 研究评估了CLIP模型在胸部X光片上的公平性和鲁棒性，发现年龄段间性能差距及对虚假相关性依赖。


<details>
  <summary>Details</summary>
Motivation: 由于CLIP模型在自然图像-文本领域的出色表现，研究人员希望将其应用于放射学等医疗领域，以利用大型成对数据集提升模型的准确性和辨别能力。

Method: 评估六种常用的CLIP模型在胸部X光片分类任务中的公平性和鲁棒性。使用MIMIC-CXR、NIH-CXR14和NEATX三个公开数据集进行测试，比较模型在不同患者群体中的表现，并分析嵌入生成的敏感属性分类能力。

Result: 在不同年龄段患者中存在性能差距，但性别和种族等属性表现较为公平；模型在无胸管图像上的性能下降，反映出对虚假相关性的依赖。通过嵌入分析发现，敏感属性可分类，但PCA未显示出此模式。

Conclusion: 在不同年龄段患者中存在性能差距，但在性别和种族等其他属性上表现较为公平。此外，模型在无胸管的图像上表现较弱，表明存在对虚假相关性的依赖。

Abstract: Motivated by the strong performance of CLIP-based models in natural
image-text domains, recent efforts have adapted these architectures to medical
tasks, particularly in radiology, where large paired datasets of images and
reports, such as chest X-rays, are available. While these models have shown
encouraging results in terms of accuracy and discriminative performance, their
fairness and robustness in the different clinical tasks remain largely
underexplored. In this study, we extensively evaluate six widely used
CLIP-based models on chest X-ray classification using three publicly available
datasets: MIMIC-CXR, NIH-CXR14, and NEATX. We assess the models fairness across
six conditions and patient subgroups based on age, sex, and race. Additionally,
we assess the robustness to shortcut learning by evaluating performance on
pneumothorax cases with and without chest drains. Our results indicate
performance gaps between patients of different ages, but more equitable results
for the other attributes. Moreover, all models exhibit lower performance on
images without chest drains, suggesting reliance on spurious correlations. We
further complement the performance analysis with a study of the embeddings
generated by the models. While the sensitive attributes could be classified
from the embeddings, we do not see such patterns using PCA, showing the
limitations of these visualisation techniques when assessing models. Our code
is available at https://github.com/TheoSourget/clip_cxr_fairness

</details>


### [10] [VoluMe -- Authentic 3D Video Calls from Live Gaussian Splat Prediction](https://arxiv.org/abs/2507.21311)
*Martin de La Gorce,Charlie Hewitt,Tibor Takacs,Robert Gerdisch,Zafiirah Hosenie,Givi Meishvili,Marek Kowalski,Thomas J. Cashman,Antonio Criminisi*

Main category: cs.CV

TL;DR: 该研究提出了一种从2D摄像实时生成3D图像的方法，解决了视频会议的硬件限制问题，实现了逼真和稳定的3D重建。


<details>
  <summary>Details</summary>
Motivation: 现有的3D会议解决方案在质量上的提升往往伴随着复杂硬件使用或固定外观限制，尚无法在视频会议应用中实现理想效果。因此，需要一种简化的3D表示方法来解决这一问题。

Method: 提出了一种从单个2D摄像头实时预测3D高斯重建的方法，使用视频帧独立进行条件处理，并引入稳定性损失以获得时间上稳定的重建。

Result: 我们的方法能在视觉质量和稳定性指标上达到先进水平，并可在真人面对面的3D会议中实时应用，仅需使用标准的2D摄像头和显示器。

Conclusion: 我们的方法显著提升了3D视频会议的实用性和效果，使之不仅具备实时性和真实性，还更具接近当前2D视频会议的设备需求。

Abstract: Virtual 3D meetings offer the potential to enhance copresence, increase
engagement and thus improve effectiveness of remote meetings compared to
standard 2D video calls. However, representing people in 3D meetings remains a
challenge; existing solutions achieve high quality by using complex hardware,
making use of fixed appearance via enrolment, or by inverting a pre-trained
generative model. These approaches lead to constraints that are unwelcome and
ill-fitting for videoconferencing applications. We present the first method to
predict 3D Gaussian reconstructions in real time from a single 2D webcam feed,
where the 3D representation is not only live and realistic, but also authentic
to the input video. By conditioning the 3D representation on each video frame
independently, our reconstruction faithfully recreates the input video from the
captured viewpoint (a property we call authenticity), while generalizing
realistically to novel viewpoints. Additionally, we introduce a stability loss
to obtain reconstructions that are temporally stable on video sequences. We
show that our method delivers state-of-the-art accuracy in visual quality and
stability metrics compared to existing methods, and demonstrate our approach in
live one-to-one 3D meetings using only a standard 2D camera and display. This
demonstrates that our approach can allow anyone to communicate volumetrically,
via a method for 3D videoconferencing that is not only highly accessible, but
also realistic and authentic.

</details>


### [11] [GLCP: Global-to-Local Connectivity Preservation for Tubular Structure Segmentation](https://arxiv.org/abs/2507.21328)
*Feixiang Zhou,Zhuangzhi Gao,He Zhao,Jianyang Xie,Yanda Meng,Yitian Zhao,Gregory Y. H. Lip,Yalin Zheng*

Main category: cs.CV

TL;DR: 我们提出了一种GLCP框架，解决了管状结构分割中的结构碎片化问题，通过综合感知全局和局部特征显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 准确分割管状结构，如血管网络，在各个医学领域中至关重要。但在这一任务中，结构碎片化仍然是一个显著挑战，对后续应用产生不利影响。现有方法主要专注于设计各种损失函数来约束整体拓扑结构，但常常忽略局部不连续区域，导致分割结果不理想。

Method: 提出了一种新颖的全局到局部连通性保持（GLCP）框架，能够同时感知管状网络的全局和局部结构特征。具体来说，我们提出了一种交互式多头分割（IMS）模块，能够分别学习全局分割、骨架图和局部不连续图。这使得我们的模型能够显式地定位局部不连续区域，同时保持整体拓扑完整性。此外，我们设计了一个轻量化双注意力精化（DAR）模块，以通过精化分割图进一步提高分割质量。

Result: 在2D和3D数据集上的大量实验表明，与几种最新方法相比，我们的GLCP在管状结构分割中实现了更高的准确性和连续性。

Conclusion: 提出的GLCP框架在保留管状结构的全局和局部连通性方面表现优异，显著提高了分割准确性和连续性。

Abstract: Accurate segmentation of tubular structures, such as vascular networks, plays
a critical role in various medical domains. A remaining significant challenge
in this task is structural fragmentation, which can adversely impact downstream
applications. Existing methods primarily focus on designing various loss
functions to constrain global topological structures. However, they often
overlook local discontinuity regions, leading to suboptimal segmentation
results. To overcome this limitation, we propose a novel Global-to-Local
Connectivity Preservation (GLCP) framework that can simultaneously perceive
global and local structural characteristics of tubular networks. Specifically,
we propose an Interactive Multi-head Segmentation (IMS) module to jointly learn
global segmentation, skeleton maps, and local discontinuity maps, respectively.
This enables our model to explicitly target local discontinuity regions while
maintaining global topological integrity. In addition, we design a lightweight
Dual-Attention-based Refinement (DAR) module to further improve segmentation
quality by refining the resulting segmentation maps. Extensive experiments on
both 2D and 3D datasets demonstrate that our GLCP achieves superior accuracy
and continuity in tubular structure segmentation compared to several
state-of-the-art approaches. The source codes will be available at
https://github.com/FeixiangZhou/GLCP.

</details>


### [12] [Analyzing the Sensitivity of Vision Language Models in Visual Question Answering](https://arxiv.org/abs/2507.21335)
*Monika Shah,Sudarshan Balaji,Somdeb Sarkhel,Sanorita Dey,Deepak Venugopal*

Main category: cs.CV

TL;DR: 研究视觉问答系统中视觉语言模型对对话违反Grice原则的敏感性，发现模型在处理复杂问题时表现下降。


<details>
  <summary>Details</summary>
Motivation: 研究视觉语言模型在处理违反Grice会话原则时的表现，探讨其是否能够像人类一样理解对话，即使需要更多认知努力。

Method: 向人工设计的问题中添加修饰符，分析视觉语言模型对这些修饰符的响应，使用VQA v2.0数据集中的问题对GPT-4o、Claude-3.5-Sonnet和Gemini-1.5-Flash进行测试。

Result: VLMs的表现随着修饰符的增加而持续下降，这表明这种方法可能是理解VLMs局限性的有前景的方向。

Conclusion: 视觉语言模型在处理违反Grice会话原则时表现不如人类，这揭示了其在理解复杂对话上的局限性。

Abstract: We can think of Visual Question Answering as a (multimodal) conversation
between a human and an AI system. Here, we explore the sensitivity of Vision
Language Models (VLMs) through the lens of cooperative principles of
conversation proposed by Grice. Specifically, even when Grice's maxims of
conversation are flouted, humans typically do not have much difficulty in
understanding the conversation even though it requires more cognitive effort.
Here, we study if VLMs are capable of handling violations to Grice's maxims in
a manner that is similar to humans. Specifically, we add modifiers to
human-crafted questions and analyze the response of VLMs to these modifiers. We
use three state-of-the-art VLMs in our study, namely, GPT-4o, Claude-3.5-Sonnet
and Gemini-1.5-Flash on questions from the VQA v2.0 dataset. Our initial
results seem to indicate that the performance of VLMs consistently diminish
with the addition of modifiers which indicates our approach as a promising
direction to understand the limitations of VLMs.

</details>


### [13] [Enhancing and Accelerating Brain MRI through Deep Learning Reconstruction Using Prior Subject-Specific Imaging](https://arxiv.org/abs/2507.21349)
*Amirmohammad Shamaei,Alexander Stebner,Salome,Bosshart,Johanna Ospel,Gouri Ginde,Mariana Bento,Roberto Souza*

Main category: cs.CV

TL;DR: 该研究提出了一种新型的深度学习MRI重建框架，通过结合先前扫描信息来提高重建质量，并显著减少重建时间，适合实时临床应用。


<details>
  <summary>Details</summary>
Motivation: 解决MRI扫描过程中长时间获取带来的高成本和病人不适等挑战，利用深度学习模型结合先前特定个体MRI扫描的信息来改善当前扫描的重建质量。

Method: 提出了一种包括初始重建网络、深度配准模型和基于Transformer的增强网络的新型深度学习MRI重建框架，并通过长时间追踪的T1加权MRI扫描数据集进行验证。

Result: 使用Wilcoxon符号秩检验验证，在四个加速因子下的方法表现优于现有方法，并且提升了脑分割任务的准确性和体积一致性，显著降低了使用传统配准算法方法的重建时间。

Conclusion: 新的深度学习MRI重建框架相较于现有方法在重建质量上更具优势，并显著缩短了总重建时间，适合实时临床应用。

Abstract: Magnetic resonance imaging (MRI) is a crucial medical imaging modality.
However, long acquisition times remain a significant challenge, leading to
increased costs, and reduced patient comfort. Recent studies have shown the
potential of using deep learning models that incorporate information from prior
subject-specific MRI scans to improve reconstruction quality of present scans.
Integrating this prior information requires registration of the previous scan
to the current image reconstruction, which can be time-consuming. We propose a
novel deep-learning-based MRI reconstruction framework which consists of an
initial reconstruction network, a deep registration model, and a
transformer-based enhancement network. We validated our method on a
longitudinal dataset of T1-weighted MRI scans with 2,808 images from 18
subjects at four acceleration factors (R5, R10, R15, R20). Quantitative metrics
confirmed our approach's superiority over existing methods (p < 0.05, Wilcoxon
signed-rank test). Furthermore, we analyzed the impact of our MRI
reconstruction method on the downstream task of brain segmentation and observed
improved accuracy and volumetric agreement with reference segmentations. Our
approach also achieved a substantial reduction in total reconstruction time
compared to methods that use traditional registration algorithms, making it
more suitable for real-time clinical applications. The code associated with
this work is publicly available at
https://github.com/amirshamaei/longitudinal-mri-deep-recon.

</details>


### [14] [Group Relative Augmentation for Data Efficient Action Detection](https://arxiv.org/abs/2507.21353)
*Deep Anil Patel,Iain Melvin,Zachary Izzo,Martin Renqiang Min*

Main category: cs.CV

TL;DR: 提出了一种适配大规模视频语言模型进行动作检测的新方法，结合参数高效调谐和内部特征增强，并在复杂数据集上展示了优秀的性能与数据效率。


<details>
  <summary>Details</summary>
Motivation: 在使用少量样例适配大型视频语言模型（VLMs）进行动作检测时，会遇到过拟合和从场景级预训练到所需的人物中心理解之间的细粒度不匹配的问题。

Method: 提出了一种高效的适应策略，将参数高效调谐(LoRA)与新颖的可学习内部特征增强相结合。在冻结的VLM主干中使用FiLM，这些增强生成与任务直接相关的多样化特征变化。此外，提出了一种组加权损失函数，根据每个增强样本与组平均值的预测偏差动态调节其训练贡献。

Result: 该方法在复杂的多标签、多人的动作检测数据集(AVA, MOMA)上展示了强劲的平均精度性能，并体现了VLMs从有限样本中适应的显著数据效率。

Conclusion: 在多标签、多人的动作检测数据集上，该方法显示了强大的平均精度性能，并展示了在有限样本情况下适应大规模视频语言模型的显著数据效率。

Abstract: Adapting large Video-Language Models (VLMs) for action detection using only a
few examples poses challenges like overfitting and the granularity mismatch
between scene-level pre-training and required person-centric understanding. We
propose an efficient adaptation strategy combining parameter-efficient tuning
(LoRA) with a novel learnable internal feature augmentation. Applied within the
frozen VLM backbone using FiLM, these augmentations generate diverse feature
variations directly relevant to the task. Additionally, we introduce a
group-weighted loss function that dynamically modulates the training
contribution of each augmented sample based on its prediction divergence
relative to the group average. This promotes robust learning by prioritizing
informative yet reasonable augmentations. We demonstrate our method's
effectiveness on complex multi-label, multi-person action detection datasets
(AVA, MOMA), achieving strong mAP performance and showcasing significant data
efficiency for adapting VLMs from limited examples.

</details>


### [15] [Collaborative Perceiver: Elevating Vision-based 3D Object Detection via Local Density-Aware Spatial Occupancy](https://arxiv.org/abs/2507.21358)
*Jicheng Yuan,Manh Nguyen Duc,Qian Liu,Manfred Hauswirth,Danh Le Phuoc*

Main category: cs.CV

TL;DR: The paper introduces Collaborative Perceiver (CoP), enhancing BEV 3D object detection by integrating spatial occupancy info and achieving better performance on nuScenes benchmark.


<details>
  <summary>Details</summary>
Motivation: Existing vision-based BEV 3D object detection methods often neglect intrinsic environmental contexts, leading to less comprehensive perception of physical world characteristics. The paper aims to improve spatial representations and feature refinement by integrating environmental context.

Method: The paper proposes a multi-task learning framework, Collaborative Perceiver (CoP), using spatial occupancy as auxiliary information. It includes generating dense occupancy ground truths with local density information, voxel-height-guided sampling for fine-grained local features, and a global-local collaborative feature fusion module.

Result: Collaborative Perceiver (CoP) achieves superior results compared to existing frameworks on the nuScenes benchmark with 49.5% mAP and 59.2% NDS, showcasing enhanced BEV representations.

Conclusion: Collaborative Perceiver (CoP) significantly improves BEV 3D object detection performance by integrating spatial occupancy information and feature refinement techniques, outperforming existing methods.

Abstract: Vision-based bird's-eye-view (BEV) 3D object detection has advanced
significantly in autonomous driving by offering cost-effectiveness and rich
contextual information. However, existing methods often construct BEV
representations by collapsing extracted object features, neglecting intrinsic
environmental contexts, such as roads and pavements. This hinders detectors
from comprehensively perceiving the characteristics of the physical world. To
alleviate this, we introduce a multi-task learning framework, Collaborative
Perceiver (CoP), that leverages spatial occupancy as auxiliary information to
mine consistent structural and conceptual similarities shared between 3D object
detection and occupancy prediction tasks, bridging gaps in spatial
representations and feature refinement. To this end, we first propose a
pipeline to generate dense occupancy ground truths incorporating local density
information (LDO) for reconstructing detailed environmental information. Next,
we employ a voxel-height-guided sampling (VHS) strategy to distill fine-grained
local features according to distinct object properties. Furthermore, we develop
a global-local collaborative feature fusion (CFF) module that seamlessly
integrates complementary knowledge between both tasks, thus composing more
robust BEV representations. Extensive experiments on the nuScenes benchmark
demonstrate that CoP outperforms existing vision-based frameworks, achieving
49.5\% mAP and 59.2\% NDS on the test set. Code and supplementary materials are
available at this link https://github.com/jichengyuan/Collaborative-Perceiver.

</details>


### [16] [Evaluating Deep Learning Models for African Wildlife Image Classification: From DenseNet to Vision Transformers](https://arxiv.org/abs/2507.21364)
*Lukman Jibril Aliyu,Umar Sani Muhammad,Bilqisu Ismail,Nasiru Muhammad,Almustapha A Wakili,Seid Muhie Yimam,Shamsuddeen Hassan Muhammad,Mustapha Abdullahi*

Main category: cs.CV

TL;DR: 研究比较了深度学习模型在非洲野生动物图像分类的效果，DenseNet-201适合在实地部署，ViT-H/14尽管准确度高但计算成本过高。


<details>
  <summary>Details</summary>
Motivation: 由于非洲野生动物数量锐减，该研究旨在利用深度学习图像分类技术，以支持生物多样性监测和野生动物保护。

Method: 使用深度学习模型中的迁移学习技术，并采用冻结特征提取器进行图像分类，对四种野生动物物种进行识别。

Result: DenseNet-201在卷积神经网络中取得了最高67%的准确率，而Vision Transformer ViT-H/14达到了99%的总体最高准确率。但ViT-H/14计算成本高，而DenseNet-201被证明适合部署在资源受限的保护环境中。

Conclusion: DenseNet-201和Vision Transformer ViT-H/14在非洲野生动物图像分类任务中表现卓越。DenseNet-201在多层卷积网络中有最佳表现，而ViT-H/14在整体准确率上最优，但计算成本高。DenseNet-201因其较低的资源需求已成功应用于实地部署。

Abstract: Wildlife populations in Africa face severe threats, with vertebrate numbers
declining by over 65% in the past five decades. In response, image
classification using deep learning has emerged as a promising tool for
biodiversity monitoring and conservation. This paper presents a comparative
study of deep learning models for automatically classifying African wildlife
images, focusing on transfer learning with frozen feature extractors. Using a
public dataset of four species: buffalo, elephant, rhinoceros, and zebra; we
evaluate the performance of DenseNet-201, ResNet-152, EfficientNet-B4, and
Vision Transformer ViT-H/14. DenseNet-201 achieved the best performance among
convolutional networks (67% accuracy), while ViT-H/14 achieved the highest
overall accuracy (99%), but with significantly higher computational cost,
raising deployment concerns. Our experiments highlight the trade-offs between
accuracy, resource requirements, and deployability. The best-performing CNN
(DenseNet-201) was integrated into a Hugging Face Gradio Space for real-time
field use, demonstrating the feasibility of deploying lightweight models in
conservation settings. This work contributes to African-grounded AI research by
offering practical insights into model selection, dataset preparation, and
responsible deployment of deep learning tools for wildlife conservation.

</details>


### [17] [Exploring Probabilistic Modeling Beyond Domain Generalization for Semantic Segmentation](https://arxiv.org/abs/2507.21367)
*I-Hsiang Chen,Hua-En Chang,Wei-Ting Chen,Jenq-Neng Hwang,Sy-Yen Kuo*

Main category: cs.CV

TL;DR: PDAF通过引入潜在域先验和扩散过程显著提高了语义分割的泛化能力，在复杂城市场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有研究在增强特征对齐时常忽略内在潜在域先验，导致结果次优，因此需要一种新的框架来捕捉域偏移并改进泛化性能。

Method: 使用PDAF框架，包括三个模块：潜在先验提取器（LPE）、域补偿模块（DCM）和扩散先验估计器（DPE）来模型域偏移，并逐步细化特征表示。

Result: 实验验证表明，PDAF在各种复杂的城市场景中有效提升了性能。

Conclusion: PDAF通过引入潜在域先验（LDP），利用这种先验作为条件因素来对齐源域和看不见的目标域，从而提高现有分割网络的泛化能力。

Abstract: Domain Generalized Semantic Segmentation (DGSS) is a critical yet challenging
task, as domain shifts in unseen environments can severely compromise model
performance. While recent studies enhance feature alignment by projecting
features into the source domain, they often neglect intrinsic latent domain
priors, leading to suboptimal results. In this paper, we introduce PDAF, a
Probabilistic Diffusion Alignment Framework that enhances the generalization of
existing segmentation networks through probabilistic diffusion modeling. PDAF
introduces a Latent Domain Prior (LDP) to capture domain shifts and uses this
prior as a conditioning factor to align both source and unseen target domains.
To achieve this, PDAF integrates into a pre-trained segmentation model and
utilizes paired source and pseudo-target images to simulate latent domain
shifts, enabling LDP modeling. The framework comprises three modules: the
Latent Prior Extractor (LPE) predicts the LDP by supervising domain shifts; the
Domain Compensation Module (DCM) adjusts feature representations to mitigate
domain shifts; and the Diffusion Prior Estimator (DPE) leverages a diffusion
process to estimate the LDP without requiring paired samples. This design
enables PDAF to iteratively model domain shifts, progressively refining feature
representations to enhance generalization under complex target conditions.
Extensive experiments validate the effectiveness of PDAF across diverse and
challenging urban scenes.

</details>


### [18] [Top2Pano: Learning to Generate Indoor Panoramas from Top-Down View](https://arxiv.org/abs/2507.21371)
*Zitong Zhang,Suranjan Gautam,Rui Yu*

Main category: cs.CV

TL;DR: Top2Pano, an end-to-end model, successfully synthesizes realistic 360-degree indoor panoramas from 2D top-down views, outperforming baselines in terms of structural fidelity and realism.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the challenge of generating realistic 360-degree indoor panoramas from 2D top-down views, which is crucial for applications in VR, interior design, and other fields, as well as overcoming the lack of explicit 3D structure and ensuring geometric consistency and photorealism.

Method: The proposed Top2Pano model estimates volumetric occupancy to infer 3D structures and utilizes volumetric rendering to generate coarse color and depth panoramas. It then employs a diffusion-based refinement stage using ControlNet to enhance realism and structural fidelity.

Result: Top2Pano outperforms existing baselines on two datasets in reconstructing geometry, occlusions, and spatial arrangements. It generalizes well to produce high-quality panoramas from schematic floorplans.

Conclusion: Top2Pano effectively bridges the gap between 2D top-down views and immersive 360-degree indoor panorama synthesis.

Abstract: Generating immersive 360{\deg} indoor panoramas from 2D top-down views has
applications in virtual reality, interior design, real estate, and robotics.
This task is challenging due to the lack of explicit 3D structure and the need
for geometric consistency and photorealism. We propose Top2Pano, an end-to-end
model for synthesizing realistic indoor panoramas from top-down views. Our
method estimates volumetric occupancy to infer 3D structures, then uses
volumetric rendering to generate coarse color and depth panoramas. These guide
a diffusion-based refinement stage using ControlNet, enhancing realism and
structural fidelity. Evaluations on two datasets show Top2Pano outperforms
baselines, effectively reconstructing geometry, occlusions, and spatial
arrangements. It also generalizes well, producing high-quality panoramas from
schematic floorplans. Our results highlight Top2Pano's potential in bridging
top-down views with immersive indoor synthesis.

</details>


### [19] [Multimodal LLMs as Customized Reward Models for Text-to-Image Generation](https://arxiv.org/abs/2507.21391)
*Shijie Zhou,Ruiyi Zhang,Huaisheng Zhu,Branislav Kveton,Yufan Zhou,Jiuxiang Gu,Jian Chen,Changyou Chen*

Main category: cs.CV

TL;DR: LLaVA-Reward模型通过直接使用MLLM的隐藏状态来评估文本到图像生成，并引入SkipCA模块以改进性能，实验结果表明该模型优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM模型需要带有指令的数据进行监督微调，并通过分析文本来评估生成质量，这种方法耗时且训练困难。

Method: 提出了一种称为LLaVA-Reward的模型，利用MLLM中的隐藏状态直接处理文本图像对，并引入Skip连接交叉注意力模块以增强视觉和文本表示之间的交互。

Result: 实验证明LLaVA-Reward在生成符合人类标准的评分以及推理时间内的文本到图像生成方面优于传统方法和基于MLLM的方法。

Conclusion: LLaVA-Reward是一种高效的奖励模型，用于自动评估文本到图像的生成，可以高效微调并在多种评估视角中表现优异。

Abstract: We introduce LLaVA-Reward, an efficient reward model designed to
automatically evaluate text-to-image (T2I) generations across multiple
perspectives, leveraging pretrained multimodal large language models (MLLMs).
Existing MLLM-based approaches require instruction-following data for
supervised fine-tuning and evaluate generation quality on analyzing text
response, which is time-consuming and difficult to train. To address this
problem, we propose LLaVA-Reward, which directly utilizes the hidden states of
MLLMs given text-image pairs. To enhance the bidirectional interaction between
visual and textual representations in decoder-only MLLMs, we further propose
adding a Skip-connection Cross Attention (SkipCA) module. This design enhances
text-image correlation reasoning by connecting early-layer visual features with
later-layer hidden representations.In addition, LLaVA-Reward supports different
types of preference data for efficient fine-tuning, including paired preference
data and unpaired data. We train LLaVA-Reward on four evaluation perspectives:
text-image alignment, fidelity/artifact, safety, and overall ranking. Empirical
results demonstrate that LLaVA-Reward outperforms conventional and MLLM-based
methods in generating human-aligned scores for automatic evaluations and
inference-time scaling in text-to-image generations.

</details>


### [20] [ReGATE: Learning Faster and Better with Fewer Tokens in MLLMs](https://arxiv.org/abs/2507.21420)
*Chaoyu Li,Yogesh Kulkarni,Pooyan Fazli*

Main category: cs.CV

TL;DR: 本文提出了ReGATE，一种自适应token剪枝方法，在训练中显著降低计算成本，并提高模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有的提高效率的方法主要针对推理阶段，效果有限，训练阶段仍需大量计算资源。需要一种方法在训练阶段降低计算开销。

Method: 提出了一种自适应的token剪枝方法ReGATE，通过使用教师-学生框架，让被训练的MLLM作为学生，一个冻结的参考大语言模型作为教师，计算每个token的参考损失，并结合学生的难度分数的指数移动平均值，选择性处理重要的token。

Result: 实验表明，在应用于VideoLLaMA2时，ReGATE能够以最多快2倍的训练速度达到标准训练的峰值准确度，同时只使用35%的token。在额外训练后，它在多个多模态基准测试中甚至超越了标准效果，总token减少超过41%。

Conclusion: ReGATE显著降低了MLLM训练的计算成本，能够在减少大量token的情况下，提高训练效率，并在多个多模态基准测试中超越基线效果。

Abstract: The computational cost of training multimodal large language models (MLLMs)
rapidly increases with the number of tokens involved. Existing efficiency
methods primarily target inference and rely on token reduction or merging,
offering limited benefit during training. In this paper, we propose ReGATE
(Reference$-$Guided Adaptive Token Elision), an adaptive token pruning method
for accelerating MLLM training. Specifically, ReGATE adopts a teacher-student
framework in which the MLLM being trained serves as the student, and a frozen
reference large language model (LLM) acts as the teacher. The teacher computes
per-token reference losses, which are combined with an exponential moving
average (EMA) of the student's own difficulty scores. This adaptive
difficulty-based scoring enables the selective processing of crucial tokens
while bypassing less informative ones in the forward pass, significantly
reducing computational overhead. Experiments demonstrate that ReGATE, when
applied to VideoLLaMA2, matches the peak accuracy of standard training on
MVBench up to 2$\times$ faster, using only 35% of the tokens. With additional
training, it even surpasses the baseline on several multimodal benchmarks, all
while reducing the total token count by over 41%. Code and models will be
released soon.

</details>


### [21] [MapDiffusion: Generative Diffusion for Vectorized Online HD Map Construction and Uncertainty Estimation in Autonomous Driving](https://arxiv.org/abs/2507.21423)
*Thomas Monninger,Zihan Zhang,Zhipeng Mo,Md Zafar Anwar,Steffen Staab,Sihao Ding*

Main category: cs.CV

TL;DR: 论文提出MapDiffusion，通过生成多种矢量地图样本来改善传统地图的不确定性，实验结果表明其在地图构建的准确性和不确定性认识上有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统地图构建模型未能捕捉现实环境中的不确定性和固有模糊性，存在遮挡和车道标记缺失时，确定性点估计不足以提供完整的环境理解。

Method: 采用新颖的生成方法MapDiffusion，将扩散范式应用于矢量化地图的分布学习，并通过迭代优化初始随机查询，以生成多个可能的地图样本。

Result: 实验表明MapDiffusion在在线地图构建中表现优越，单样本性能超过基线5%，多样本聚合进一步提升性能，并在遮挡区域提供更高的不确定性估计。

Conclusion: MapDiffusion提高了在线矢量化高清地图构建的鲁棒性和可靠性，为自动驾驶车辆在复杂环境中进行不确定性感知决策提供了可能。

Abstract: Autonomous driving requires an understanding of the static environment from
sensor data. Learned Bird's-Eye View (BEV) encoders are commonly used to fuse
multiple inputs, and a vector decoder predicts a vectorized map representation
from the latent BEV grid. However, traditional map construction models provide
deterministic point estimates, failing to capture uncertainty and the inherent
ambiguities of real-world environments, such as occlusions and missing lane
markings. We propose MapDiffusion, a novel generative approach that leverages
the diffusion paradigm to learn the full distribution of possible vectorized
maps. Instead of predicting a single deterministic output from learned queries,
MapDiffusion iteratively refines randomly initialized queries, conditioned on a
BEV latent grid, to generate multiple plausible map samples. This allows
aggregating samples to improve prediction accuracy and deriving uncertainty
estimates that directly correlate with scene ambiguity. Extensive experiments
on the nuScenes dataset demonstrate that MapDiffusion achieves state-of-the-art
performance in online map construction, surpassing the baseline by 5% in
single-sample performance. We further show that aggregating multiple samples
consistently improves performance along the ROC curve, validating the benefit
of distribution modeling. Additionally, our uncertainty estimates are
significantly higher in occluded areas, reinforcing their value in identifying
regions with ambiguous sensor input. By modeling the full map distribution,
MapDiffusion enhances the robustness and reliability of online vectorized HD
map construction, enabling uncertainty-aware decision-making for autonomous
vehicles in complex environments.

</details>


### [22] [Dual Cross-image Semantic Consistency with Self-aware Pseudo Labeling for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2507.21440)
*Han Wu,Chong Wang,Zhiming Cui*

Main category: cs.CV

TL;DR: DuCiSC是一种新的半监督框架，解决了医疗图像分割中的特征差异问题，通过区域级语义一致性提供优越的分割结果。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在处理医疗图像分割中通过伪标签进行图像内像素级一致性训练，忽略了更综合的语义级别一致性（如对象区域），且受限于标记数据和未标记数据的不平衡所产生的特征差异。

Method: 提出了一个新的双重跨图像语义一致性（DuCiSC）学习框架，通过样本原型对齐鼓励区域级语义一致性，并设计一种自我意识的置信度估计策略以精确选择可靠的伪标签。

Result: DuCiSC在四个数据集上进行了广泛验证，包括两个二元基准、一个多类自动心脏诊断挑战数据集和一个具有复杂解剖结构的困难场景，表现出优越的分割结果。

Conclusion: 通过创造性的双重范式，DuCiSC能够有效地通过原型表示建立一致的跨图像语义，从而解决特征差异问题，并在泛化到未标记数据时表现出色。

Abstract: Semi-supervised learning has proven highly effective in tackling the
challenge of limited labeled training data in medical image segmentation. In
general, current approaches, which rely on intra-image pixel-wise consistency
training via pseudo-labeling, overlook the consistency at more comprehensive
semantic levels (e.g., object region) and suffer from severe discrepancy of
extracted features resulting from an imbalanced number of labeled and unlabeled
data. To overcome these limitations, we present a new \underline{Du}al
\underline{C}ross-\underline{i}mage \underline{S}emantic
\underline{C}onsistency (DuCiSC) learning framework, for semi-supervised
medical image segmentation. Concretely, beyond enforcing pixel-wise semantic
consistency, DuCiSC proposes dual paradigms to encourage region-level semantic
consistency across: 1) labeled and unlabeled images; and 2) labeled and fused
images, by explicitly aligning their prototypes. Relying on the dual paradigms,
DuCiSC can effectively establish consistent cross-image semantics via prototype
representations, thereby addressing the feature discrepancy issue. Moreover, we
devise a novel self-aware confidence estimation strategy to accurately select
reliable pseudo labels, allowing for exploiting the training dynamics of
unlabeled data. Our DuCiSC method is extensively validated on four datasets,
including two popular binary benchmarks in segmenting the left atrium and
pancreas, a multi-class Automatic Cardiac Diagnosis Challenge dataset, and a
challenging scenario of segmenting the inferior alveolar nerve that features
complicated anatomical structures, showing superior segmentation results over
previous state-of-the-art approaches. Our code is publicly available at
\href{https://github.com/ShanghaiTech-IMPACT/DuCiSC}{https://github.com/ShanghaiTech-IMPACT/DuCiSC}.

</details>


### [23] [Recursive Visual Imagination and Adaptive Linguistic Grounding for Vision Language Navigation](https://arxiv.org/abs/2507.21450)
*Bolei Chen,Jiaxu Kang,Yifei Wang,Ping Zhong,Qi Wu,Jianxin Wang*

Main category: cs.CV

TL;DR: 本文提出了一种改进视觉语言导航的策略，通过递归视觉想象和自适应语言基础技术，提高了导航性能。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉语言导航代理存在过于详细的场景表示和模糊的视觉语言对齐问题，削弱了导航过程中理解高层次场景的能力。

Method: 采用递归视觉想象（RVI）技术来集中于视觉过渡的规律性和场景布局的语义，而不是处理误导性的几何细节；同时采用自适应语言基础（ALG）技术来有针对性地对齐学习的情境记忆与不同语言成分。

Result: 该导航策略在复杂的VLN-CE和ObjectNav任务中优于现有的最先进方法，证明了本文提出的RVI和ALG技术在视觉语言导航中的优越性。

Conclusion: 本文提出了一种导航策略，通过递归总结沿途的视觉感知，自适应地与指令对齐，以增强语言基础。

Abstract: Vision Language Navigation (VLN) typically requires agents to navigate to
specified objects or remote regions in unknown scenes by obeying linguistic
commands. Such tasks require organizing historical visual observations for
linguistic grounding, which is critical for long-sequence navigational
decisions. However, current agents suffer from overly detailed scene
representation and ambiguous vision-language alignment, which weaken their
comprehension of navigation-friendly high-level scene priors and easily lead to
behaviors that violate linguistic commands. To tackle these issues, we propose
a navigation policy by recursively summarizing along-the-way visual
perceptions, which are adaptively aligned with commands to enhance linguistic
grounding. In particular, by structurally modeling historical trajectories as
compact neural grids, several Recursive Visual Imagination (RVI) techniques are
proposed to motivate agents to focus on the regularity of visual transitions
and semantic scene layouts, instead of dealing with misleading geometric
details. Then, an Adaptive Linguistic Grounding (ALG) technique is proposed to
align the learned situational memories with different linguistic components
purposefully. Such fine-grained semantic matching facilitates the accurate
anticipation of navigation actions and progress. Our navigation policy
outperforms the state-of-the-art methods on the challenging VLN-CE and
ObjectNav tasks, showing the superiority of our RVI and ALG techniques for VLN.

</details>


### [24] [Boost Self-Supervised Dataset Distillation via Parameterization, Predefined Augmentation, and Approximation](https://arxiv.org/abs/2507.21455)
*Sheng-Feng Yu,Jia-Jiun Yao,Wei-Chen Chiu*

Main category: cs.CV

TL;DR: 该研究提出了一种新的自监督数据集蒸馏技术，通过多个新颖技术提高数据蒸馏的效率和可迁移性。


<details>
  <summary>Details</summary>
Motivation: 随着数据集规模的不断增长，训练大型深度模型的成本越来越高，因此需要一种方法来缩小数据集规模以降低计算成本。

Method: 研究提出了一种自监督数据集蒸馏的方法，通过提取自监督训练图像及其表示来缩小数据集。这里包括创新的图像和表示参数化方法，通过低维基选择关键特征，并解决数据增强随机性带来的不稳定性，同时使用轻量级网络来建模增强视图之间的关系。

Result: 大量实验验证了该方法在蒸馏效率、跨架构泛化和迁移学习性能等方面的优越性。

Conclusion: 自监督数据集蒸馏能够有效提取真实数据集中的丰富信息，并提升蒸馏集的跨架构泛化能力。

Abstract: Although larger datasets are crucial for training large deep models, the
rapid growth of dataset size has brought a significant challenge in terms of
considerable training costs, which even results in prohibitive computational
expenses. Dataset Distillation becomes a popular technique recently to reduce
the dataset size via learning a highly compact set of representative exemplars,
where the model trained with these exemplars ideally should have comparable
performance with respect to the one trained with the full dataset. While most
of existing works upon dataset distillation focus on supervised datasets, we
instead aim to distill images and their self-supervisedly trained
representations into a distilled set. This procedure, named as Self-Supervised
Dataset Distillation, effectively extracts rich information from real datasets,
yielding the distilled sets with enhanced cross-architecture generalizability.
Particularly, in order to preserve the key characteristics of original dataset
more faithfully and compactly, several novel techniques are proposed: 1) we
introduce an innovative parameterization upon images and representations via
distinct low-dimensional bases, where the base selection for parameterization
is experimentally shown to play a crucial role; 2) we tackle the instability
induced by the randomness of data augmentation -- a key component in
self-supervised learning but being underestimated in the prior work of
self-supervised dataset distillation -- by utilizing predetermined
augmentations; 3) we further leverage a lightweight network to model the
connections among the representations of augmented views from the same image,
leading to more compact pairs of distillation. Extensive experiments conducted
on various datasets validate the superiority of our approach in terms of
distillation efficiency, cross-architecture generalization, and transfer
learning performance.

</details>


### [25] [An Angular-Temporal Interaction Network for Light Field Object Tracking in Low-Light Scenes](https://arxiv.org/abs/2507.21460)
*Mianzhao Wang,Fan Shi,Xu Cheng,Feifei Zhang,Shengyong Chen*

Main category: cs.CV

TL;DR: 介绍了一种新的光场结构表示，利用角度互动网络在低光场景下有效跟踪对象，并提供了一个大规模数据集进行实验验证，结果表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有技术难以在复杂的低光照场景中实现可靠的时间域角度建模。

Method: 本文提出了一个角度互动网络（ATINet），用于学习光场中的角度感知表示，并在时间域内进行几何特征互动。

Result: ATINet在单对象跟踪中达到了最新水平的性能，并在多对象跟踪中证明了高质量光场角度-时间建模的有效性。

Conclusion: 本文提出了一种新颖的光场深化极平面结构图像（ESI）表示，显著提升了低光照场景中的视觉表现，并减少了高维光场中的冗余。

Abstract: High-quality 4D light field representation with efficient angular feature
modeling is crucial for scene perception, as it can provide discriminative
spatial-angular cues to identify moving targets. However, recent developments
still struggle to deliver reliable angular modeling in the temporal domain,
particularly in complex low-light scenes. In this paper, we propose a novel
light field epipolar-plane structure image (ESI) representation that explicitly
defines the geometric structure within the light field. By capitalizing on the
abrupt changes in the angles of light rays within the epipolar plane, this
representation can enhance visual expression in low-light scenes and reduce
redundancy in high-dimensional light fields. We further propose an
angular-temporal interaction network (ATINet) for light field object tracking
that learns angular-aware representations from the geometric structural cues
and angular-temporal interaction cues of light fields. Furthermore, ATINet can
also be optimized in a self-supervised manner to enhance the geometric feature
interaction across the temporal domain. Finally, we introduce a large-scale
light field low-light dataset for object tracking. Extensive experimentation
demonstrates that ATINet achieves state-of-the-art performance in single object
tracking. Furthermore, we extend the proposed method to multiple object
tracking, which also shows the effectiveness of high-quality light field
angular-temporal modeling.

</details>


### [26] [Describe, Adapt and Combine: Empowering CLIP Encoders for Open-set 3D Object Retrieval](https://arxiv.org/abs/2507.21489)
*Zhichuan Wang,Yang Zhou,Zhe Liu,Rui Yu,Song Bai,Yulong Wang,Xinwei He,Xiang Bai*

Main category: cs.CV

TL;DR: DAC framework enhances open-set 3D object retrieval using CLIP and multi-modal language model with significant performance improvement over existing methods.


<details>
  <summary>Details</summary>
Motivation: Existing methods struggle with generalized representations due to insufficient 3D training data. Utilizing CLIP, which provides generalized representations through image-text pairs, aims to overcome this challenge.

Method: Describe, Adapt and Combine (DAC) framework utilizes multi-view images, CLIP model, and multi-modal large language model with Additive-Bias Low-Rank adaptation to learn generalized 3D representations.

Result: DAC surpasses prior methods by an average of +10.01% mAP on four open-set 3DOR datasets with validated generalization on image-based and cross-dataset setups.

Conclusion: DAC significantly improves the performance of open-set 3D object retrieval using multi-view images only, by synergizing CLIP model and multi-modal large language model.

Abstract: Open-set 3D object retrieval (3DOR) is an emerging task aiming to retrieve 3D
objects of unseen categories beyond the training set. Existing methods
typically utilize all modalities (i.e., voxels, point clouds, multi-view
images) and train specific backbones before fusion. However, they still
struggle to produce generalized representations due to insufficient 3D training
data. Being contrastively pre-trained on web-scale image-text pairs, CLIP
inherently produces generalized representations for a wide range of downstream
tasks. Building upon it, we present a simple yet effective framework named
Describe, Adapt and Combine (DAC) by taking only multi-view images for open-set
3DOR. DAC innovatively synergizes a CLIP model with a multi-modal large
language model (MLLM) to learn generalized 3D representations, where the MLLM
is used for dual purposes. First, it describes the seen category information to
align with CLIP's training objective for adaptation during training. Second, it
provides external hints about unknown objects complementary to visual cues
during inference. To improve the synergy, we introduce an Additive-Bias
Low-Rank adaptation (AB-LoRA), which alleviates overfitting and further
enhances the generalization to unseen categories. With only multi-view images,
DAC significantly surpasses prior arts by an average of +10.01\% mAP on four
open-set 3DOR datasets. Moreover, its generalization is also validated on
image-based and cross-dataset setups. Code is available at
https://github.com/wangzhichuan123/DAC.

</details>


### [27] [VAGU & GtS: LLM-Based Benchmark and Framework for Joint Video Anomaly Grounding and Understanding](https://arxiv.org/abs/2507.21507)
*Shibo Gao,Peipei Yang,Yangyang Liu,Yi Chen,Han Zhu,Xuyao Zhang,Linlin Huang*

Main category: cs.CV

TL;DR: 本文引入了VAGU基准以整合视频异常理解和定位任务，提出了GtS框架和JeAUG指标以提升检测准确性和解释能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视频异常检测方法无法同时支持异常理解和定位这两个任务，缺乏一个整合的模型或数据集。为了弥补这一不足，本文介绍了VAGU基准。

Method: 提出了一种名为“Glance then Scrutinize (GtS)”的无训练框架，利用文本提示指导进行视频异常检测。首先进行粗略定位高概率异常区域，然后进行详细异常解释和时间边界修正。

Result: 实验结果表明，VAGU基准、GtS框架和JeAUG评价指标在视频异常检测任务中表现出色，提供了更精确的异常定位和语义理解能力。

Conclusion: 本文引入了VAGU，这是首个整合视频异常识别和理解任务的基准。通过开发Glance then Scrutinize框架和JeAUG评价指标，实验结果验证了这些工具的有效性。

Abstract: Video Anomaly Detection (VAD) aims to identify anomalous events in videos and
accurately determine their time intervals. Current VAD methods mainly fall into
two categories: traditional DNN-based approaches that focus on temporal
localization, and LLM-based approaches that emphasize semantic understanding.
Both anomaly understanding and grounding are essential for comprehensive video
anomaly detection and can complement each other. However, no existing model or
dataset supports both tasks simultaneously. To address this, we introduce VAGU
(Video Anomaly Grounding and Understanding), the first benchmark to integrate
both tasks. Each VAGU instance includes annotations for anomaly category,
semantic explanation, precise temporal grounding and Video QA. We also provide
multiple-choice Video QA for objective evaluation. Based on this dataset, we
propose Glance then Scrutinize (GtS), a training-free framework guided by
textual prompts. The framework first enables coarse localization of
high-probability anomalous regions, followed by detailed anomaly interpretation
and temporal boundary refinement. Additionally, we propose the JeAUG metric,
which jointly evaluates semantic interpretability and temporal precision,
overcoming the limitations of traditional metrics. Extensive experiments verify
the effectiveness of our benchmark, framework, and evaluation metric.

</details>


### [28] [Optimizing Active Learning in Vision-Language Models via Parameter-Efficient Uncertainty Calibration](https://arxiv.org/abs/2507.21521)
*Athmanarayanan Lakshmi Narayanan,Amrutha Machireddy,Ranganath Krishnan*

Main category: cs.CV

TL;DR: 引入了一种结合不确定性校准损失的主动学习方法，在多个数据集实验表明该方法效率高且性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在大型视觉语言模型中面临不确定性估计和高效采样的挑战。

Method: 提出了一种新的参数高效学习方法，该方法在主动学习框架中结合了不确定性校准损失。

Result: 通过对多个数据集和视觉骨干进行广泛实验，证明我们的解决方案可以在高效计算的同时超越复杂的采样技术。

Conclusion: 我们的解决方案可以在保持高效的计算性能的同时匹配甚至超越复杂的基于特征的采样技术的性能。

Abstract: Active Learning (AL) has emerged as a powerful approach for minimizing
labeling costs by selectively sampling the most informative data for neural
network model development. Effective AL for large-scale vision-language models
necessitates addressing challenges in uncertainty estimation and efficient
sampling given the vast number of parameters involved. In this work, we
introduce a novel parameter-efficient learning methodology that incorporates
uncertainty calibration loss within the AL framework. We propose a
differentiable loss function that promotes uncertainty calibration for
effectively selecting fewer and most informative data samples for fine-tuning.
Through extensive experiments across several datasets and vision backbones, we
demonstrate that our solution can match and exceed the performance of complex
feature-based sampling techniques while being computationally very efficient.
Additionally, we investigate the efficacy of Prompt learning versus Low-rank
adaptation (LoRA) in sample selection, providing a detailed comparative
analysis of these methods in the context of efficient AL.

</details>


### [29] [Chain-of-Cooking:Cooking Process Visualization via Bidirectional Chain-of-Thought Guidance](https://arxiv.org/abs/2507.21529)
*Mengling Xu,Ming Tao,Bing-Kun Bao*

Main category: cs.CV

TL;DR: 本文提出了一个名为Chain-of-Cooking的模型，通过多个模块解决烹饪过程图像生成中的一致性和语义不一致性问题，并通过实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有工作的重点在于生成最终食物的图像，而在可视化烹饪过程时面临两大挑战：使食材的外观符合文本描述产生语义不一致性，以及维持图像顺序上的语境一致性。

Method: 本文提出了一个动态补丁选择模块，语义进化模块和双向链式思维（CoT）指导。动态补丁选择模块用于检索与当前文本内容最相关的先前生成的图像补丁作为参考。语义进化模块在潜在提示与当前烹饪步骤之间建立语义关联，并与潜在特征进行融合。双向链式思维指导用于更新合并的特征，以保证当前步骤与前一步骤保持一致性。

Result: 通过构建名为CookViz的数据集，定量和定性实验表明，所提出的方法在生成一致和语义一致的烹饪过程图像方面优于现有方法。

Conclusion: 本文介绍了一种新的烹饪过程可视化模型Chain-of-Cooking，通过使用动态补丁选择模块、语义进化模块和双向链式思维指导来改善图像生成的一致性和语义一致性。实验表明该方法优于现有方法。

Abstract: Cooking process visualization is a promising task in the intersection of
image generation and food analysis, which aims to generate an image for each
cooking step of a recipe. However, most existing works focus on generating
images of finished foods based on the given recipes, and face two challenges to
visualize the cooking process. First, the appearance of ingredients changes
variously across cooking steps, it is difficult to generate the correct
appearances of foods that match the textual description, leading to semantic
inconsistency. Second, the current step might depend on the operations of
previous step, it is crucial to maintain the contextual coherence of images in
sequential order. In this work, we present a cooking process visualization
model, called Chain-of-Cooking. Specifically, to generate correct appearances
of ingredients, we present a Dynamic Patch Selection Module to retrieve
previously generated image patches as references, which are most related to
current textual contents. Furthermore, to enhance the coherence and keep the
rational order of generated images, we propose a Semantic Evolution Module and
a Bidirectional Chain-of-Thought (CoT) Guidance. To better utilize the
semantics of previous texts, the Semantic Evolution Module establishes the
semantical association between latent prompts and current cooking step, and
merges it with the latent features. Then the CoT Guidance updates the merged
features to guide the current cooking step remain coherent with the previous
step. Moreover, we construct a dataset named CookViz, consisting of
intermediate image-text pairs for the cooking process. Quantitative and
qualitative experiments show that our method outperforms existing methods in
generating coherent and semantic consistent cooking process.

</details>


### [30] [Suppressing Gradient Conflict for Generalizable Deepfake Detection](https://arxiv.org/abs/2507.21530)
*Ming-Hui Liu,Harry Cheng,Xin Luo,Xin-Shun Xu*

Main category: cs.CV

TL;DR: 研究提出CS-DFD框架，利用UVS和CGR模块解决梯度冲突问题，提升深度伪造检测的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测模型需要能够泛化到不断发展的操控技术，但联合训练原始和在线合成伪造数据会导致性能下降，这与常识相悖。分析发现这种下降源于梯度冲突，导致源域准确性和目标域泛化间的权衡。

Method: CS-DFD框架包含两个协同模块：更新向量搜索模块(UVS)和冲突梯度减少模块(CGR)。UVS模块通过转化为极值优化问题来搜索更新向量，最大化各类数据的同时损失减少。CGR模块通过冲突下降损失实现低冲突特征嵌入空间，惩罚不对齐的梯度方向。

Result: 实验表明，CS-DFD框架显著缓解了参数优化和表征学习中的梯度干扰，在多个深度伪造基准上实现了最先进的性能。

Conclusion: CS-DFD框架通过缓解梯度冲突提高了深度伪造检测模型的性能，尤其在域内检测准确性和跨域泛化能力方面表现出色。

Abstract: Robust deepfake detection models must be capable of generalizing to
ever-evolving manipulation techniques beyond training data. A promising
strategy is to augment the training data with online synthesized fake images
containing broadly generalizable artifacts. However, in the context of deepfake
detection, it is surprising that jointly training on both original and online
synthesized forgeries may result in degraded performance. This contradicts the
common belief that incorporating more source-domain data should enhance
detection accuracy. Through empirical analysis, we trace this degradation to
gradient conflicts during backpropagation which force a trade-off between
source domain accuracy and target domain generalization. To overcome this
issue, we propose a Conflict-Suppressed Deepfake Detection (CS-DFD) framework
that explicitly mitigates the gradient conflict via two synergistic modules.
First, an Update Vector Search (UVS) module searches for an alternative update
vector near the initial gradient vector to reconcile the disparities of the
original and online synthesized forgeries. By further transforming the search
process into an extremum optimization problem, UVS yields the uniquely update
vector, which maximizes the simultaneous loss reductions for each data type.
Second, a Conflict Gradient Reduction (CGR) module enforces a low-conflict
feature embedding space through a novel Conflict Descent Loss. This loss
penalizes misaligned gradient directions and guides the learning of
representations with aligned, non-conflicting gradients. The synergy of UVS and
CGR alleviates gradient interference in both parameter optimization and
representation learning. Experiments on multiple deepfake benchmarks
demonstrate that CS-DFD achieves state-of-the-art performance in both in-domain
detection accuracy and cross-domain generalization.

</details>


### [31] [Sun sensor calibration algorithms: A systematic mapping and survey](https://arxiv.org/abs/2507.21541)
*Michael Herman,Olivia J. Pinon Fischer,Dimitri N. Mavris*

Main category: cs.CV

TL;DR: 该综述系统性汇总了关于日光传感器建模和校准的研究，分析了现有方法的优缺点，并指出未来需要解决的研究空白。


<details>
  <summary>Details</summary>
Motivation: 由于日光传感器的校准过程复杂且存在多种难以观察的空间和时间不确定性，现有技术无法系统性汇总相关研究。因此，需要提供一个全面的综述来整合这些研究，并推动技术进步。

Method: 本综述采用了系统性审查方法，分类整理了日光传感器建模和校准的算法和技术，进行了详细的调查和分析。

Result: 提供了多样化的日光传感器建模和校准技术的详尽的调查和分析，并指出了当前研究中的空白和未来研究的方向。

Conclusion: 该综述论文提出了一种系统的日光传感器建模和校准算法的映射，涵盖了多种传感器配置。它详细调查了每种方法，并分析了研究空白，同时提出了未来日光传感器建模和校准技术的建议。

Abstract: Attitude sensors determine the spacecraft attitude through the sensing of an
astronomical object, field or other phenomena. The Sun and fixed stars are the
two primary astronomical sensing objects. Attitude sensors are critical
components for the survival and knowledge improvement of spacecraft. Of these,
sun sensors are the most common and important sensor for spacecraft attitude
determination. The sun sensor measures the Sun vector in spacecraft
coordinates. The sun sensor calibration process is particularly difficult due
to the complex nature of the uncertainties involved. The uncertainties are
small, difficult to observe, and vary spatio-temporally over the lifecycle of
the sensor. In addition, the sensors are affected by numerous sources of
uncertainties, including manufacturing, electrical, environmental, and
interference sources. This motivates the development of advanced calibration
algorithms to minimize uncertainty over the sensor lifecycle and improve
accuracy. Although modeling and calibration techniques for sun sensors have
been explored extensively in the literature over the past two decades, there is
currently no resource that consolidates and systematically reviews this body of
work. The present review proposes a systematic mapping of sun sensor modeling
and calibration algorithms across a breadth of sensor configurations. It
specifically provides a comprehensive survey of each methodology, along with an
analysis of research gaps and recommendations for future directions in sun
sensor modeling and calibration techniques.

</details>


### [32] [Multi-View Reconstruction with Global Context for 3D Anomaly Detection](https://arxiv.org/abs/2507.21555)
*Yihan Sun,Yuqi Cheng,Yunkang Cao,Yuxin Zhang,Weiming Shen*

Main category: cs.CV

TL;DR: MVR方法通过多视图图像转换和重建框架提升了3D异常检测的全局信息学习能力，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的3D异常检测方法在高精度情境下由于缺乏全局信息，其性能下降，因此需要一种新方法来改进全局信息的学习。

Method: 提出了一种名为Multi-View Reconstruction (MVR)的方法，该方法将高分辨率点云无损地转换为多视图图像，并使用重建为基础的异常检测框架。

Result: 实验结果表明，MVR方法在Real3D-AD基准上的物体级AU-ROC达到89.6%，点级AU-ROC达到95.7%。

Conclusion: 该研究提出的方法MVR通过将高分辨率点云无损地转化为多视图图像并采用基于重建的异常检测框架增强全局信息学习，有效提升了3D异常检测性能。

Abstract: 3D anomaly detection is critical in industrial quality inspection. While
existing methods achieve notable progress, their performance degrades in
high-precision 3D anomaly detection due to insufficient global information. To
address this, we propose Multi-View Reconstruction (MVR), a method that
losslessly converts high-resolution point clouds into multi-view images and
employs a reconstruction-based anomaly detection framework to enhance global
information learning. Extensive experiments demonstrate the effectiveness of
MVR, achieving 89.6\% object-wise AU-ROC and 95.7\% point-wise AU-ROC on the
Real3D-AD benchmark.

</details>


### [33] [RelMap: Enhancing Online Map Construction with Class-Aware Spatial Relation and Semantic Priors](https://arxiv.org/abs/2507.21567)
*Tianhui Cai,Yun Zhang,Zewei Zhou,Zhiyu Huang,Jiaqi Ma*

Main category: cs.CV

TL;DR: RelMap通过融合空间关系和语义先验提高了在线地图构建的精度。它在多种数据集上实现了最新的性能。


<details>
  <summary>Details</summary>
Motivation: 在线高清地图构建在扩展自动驾驶系统方面变得越来越重要，现有方法忽略了地图元素间的空间和语义关系，影响了准确性和泛化能力。

Method: 引入了类感知空间关系先验和专家混合模型的语义先验，分别用于编码地图元素之间的相对位置依赖，并基于预测的类概率将特征路由到类特定专家以优化实例特征解码。

Result: 在nuScenes和Argoverse 2数据集上达到了最先进的性能。

Conclusion: RelMap在单帧和时序感知骨架上均表现优异，达到最先进的性能。

Abstract: Online high-definition (HD) map construction plays an increasingly important
role in scaling autonomous driving systems. Transformer-based methods have
become prevalent in online HD map construction; however, existing approaches
often neglect the inherent spatial and semantic relationships among map
elements, which limits their accuracy and generalization. To address this, we
propose RelMap, an end-to-end framework that enhances online map construction
by incorporating spatial relations and semantic priors. We introduce a
Class-aware Spatial Relation Prior, which explicitly encodes relative
positional dependencies between map elements using a learnable class-aware
relation encoder. Additionally, we propose a Mixture-of-Experts (MoE)-based
Semantic Prior, which routes features to class-specific experts based on
predicted class probabilities, refining instance feature decoding. Our method
is compatible with both single-frame and temporal perception backbones,
achieving state-of-the-art performance on both the nuScenes and Argoverse 2
datasets.

</details>


### [34] [LinDeps: A Fine-tuning Free Post-Pruning Method to Remove Layer-Wise Linear Dependencies with Guaranteed Performance Preservation](https://arxiv.org/abs/2507.21573)
*Maxim Henry,Adrien Deliège,Anthony Cioppa,Marc Van Droogenbroeck*

Main category: cs.CV

TL;DR: 提出一种新的后剪枝方法LinDeps，通过线性依赖分析提高现有剪枝技术的压缩率，同时保持性能，在低资源环境中显示出显著剪枝改进。


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络（CNN）广泛应用于许多计算机视觉任务，但其规模和复杂性日益增加，给资源受限的平台上的高效部署带来了巨大挑战。为此，网络剪枝成为减少神经网络规模和计算需求的有效方法。

Method: 本文提出了一种新的后剪枝方法LinDeps，可以应用于任何剪枝技术之上。LinDeps通过线性依赖分析系统性地识别和移除冗余滤波器，特别地，利用了pivoted QR分解来检测和剪除线性依赖滤波器。然后，通过一种新的信号恢复机制调整下一层的内核，以保持兼容性和性能，而无需进行任何微调。

Result: 实验表明，LinDeps在CIFAR-10和ImageNet上的VGG和ResNet骨干网能够提高现有剪枝技术的压缩率，并保持性能，成为CNN剪枝的新标杆。此外，在无法进行重新训练的低资源环境中进行基准测试，显示出显著的剪枝改进和推理加速。

Conclusion: LinDeps能够改善现有的剪枝技术并节省资源，是任何当前或未来剪枝技术的重要补充。

Abstract: Convolutional Neural Networks (CNN) are widely used in many computer vision
tasks. Yet, their increasing size and complexity pose significant challenges
for efficient deployment on resource-constrained platforms. Hence, network
pruning has emerged as an effective way of reducing the size and computational
requirements of neural networks by removing redundant or unimportant
parameters. However, a fundamental challenge with pruning consists in optimally
removing redundancies without degrading performance. Most existing pruning
techniques overlook structural dependencies across feature maps within a layer,
resulting in suboptimal pruning decisions. In this work, we introduce LinDeps,
a novel post-pruning method, i.e., a pruning method that can be applied on top
of any pruning technique, which systematically identifies and removes redundant
filters via linear dependency analysis. Particularly, LinDeps applies pivoted
QR decomposition to feature maps to detect and prune linearly dependent
filters. Then, a novel signal recovery mechanism adjusts the next layer's
kernels to preserve compatibility and performance without requiring any
fine-tuning. Our experiments on CIFAR-10 and ImageNet with VGG and ResNet
backbones demonstrate that LinDeps improves compression rates of existing
pruning techniques while preserving performances, leading to a new state of the
art in CNN pruning. We also benchmark LinDeps in low-resource setups where no
retraining can be performed, which shows significant pruning improvements and
inference speedups over a state-of-the-art method. LinDeps therefore
constitutes an essential add-on for any current or future pruning technique.

</details>


### [35] [TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs](https://arxiv.org/abs/2507.21584)
*Kejia Zhang,Keda Tao,Zhiming Luo,Chang Liu,Jiasheng Tang,Huan Wang*

Main category: cs.CV

TL;DR: TARS是一种新策略，减少MM LLMs幻觉生成，提升推理可靠性，性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有的直接偏好优化策略倾向于过度拟合于偏好数据中的表面语言线索，导致分布刚性和虚假的关联，从而削弱与因果相关的视觉信息的结合能力。为克服这一限制，需要新的策略。

Method: 提出TARS，一种令牌自适应偏好策略，将直接偏好优化重新定义为一个极小极大优化问题。TARS在语义约束下最大化令牌级别的分布变化以模拟对齐不确定性，同时最小化在这些控制扰动下的期望偏好损失。

Result: TARS在多个幻觉基准上表现优异，仅使用4.8k偏好样本且无专家反馈的情况下，将幻觉率从26.4%降至13.2%，认知值从2.5降至0.4。

Conclusion: TARS能够有效减少MM LLMs中的幻觉生成，降低幻觉率和认知值，在多个衡量标准上表现良好，超越标准的DPO方法并接近GPT-4o的效果。

Abstract: Multimodal large language models (MLLMs) enable vision-language reasoning,
yet often generate plausible outputs that are factually incorrect or visually
ungrounded, thereby compromising their reliability. Direct preference
optimization (DPO) is a common strategy for correcting hallucinations by
aligning model outputs with human preferences. Existing DPO strategies
typically treat hallucination-related preferences as fixed targets, relying on
static supervision signals during training. This approach tends to overfit to
superficial linguistic cues in preference data, leading to distributional
rigidity and spurious correlations that impair grounding in causally relevant
visual information. To overcome this limitation, we propose TARS, a
token-adaptive preference strategy that reformulates DPO as a min-max
optimization problem. TARS maximizes token-level distributional shifts under
semantic constraints to simulate alignment uncertainty, and simultaneously
minimizes the expected preference loss under these controlled perturbations.
This joint objective preserves causal grounding while mitigating overfitting to
preference patterns, thereby reducing hallucinations in multimodal reasoning.
We evaluate TARS on multiple hallucination benchmarks and find consistently
strong performance. Using only 4.8k preference samples and no expert feedback,
TARS reduces hallucination rates from 26.4% to 13.2% and decreases cognition
value from 2.5 to 0.4. It outperforms standard DPO and matches GPT-4o on
several key metrics.

</details>


### [36] [Emerging Trends in Pseudo-Label Refinement for Weakly Supervised Semantic Segmentation with Image-Level Supervision](https://arxiv.org/abs/2507.21587)
*Zheyuan Zhang,Wang Zhang*

Main category: cs.CV

TL;DR: 本文综述了图像级别注释的弱监督语义分割方法的最新进展，分类现有方法，并讨论其在特定领域应用中的挑战。


<details>
  <summary>Details</summary>
Motivation: 由于最新方法的迅速发展以及现有综述在捕捉近期趋势方面的局限性，迫切需要对使用图像级别标签的弱监督语义分割进行更新和全面的综述。

Method: 作者通过对现有方法进行分类，将其按额外监督的类型和级别进行整理，并评估在特定领域数据集中的应用挑战，分析当前面临的困难和现有方法的局限性。

Result: 提供了使用图像级别注释的WSSS最新技术进展的综合综述，对现有方法进行了分类，并指出了应用这些方法于特定领域数据集时面临的挑战。

Conclusion: 本文综述了使用图像级别注释的弱监督语义分割（WSSS）方法，为研究者提供了当前最新的技术进展和研究方向。未来研究应进一步解决领域特定数据集中的应用挑战。

Abstract: Unlike fully supervised semantic segmentation, weakly supervised semantic
segmentation (WSSS) relies on weaker forms of supervision to perform dense
prediction tasks. Among the various types of weak supervision, WSSS with image
level annotations is considered both the most challenging and the most
practical, attracting significant research attention. Therefore, in this
review, we focus on WSSS with image level annotations. Additionally, this
review concentrates on mainstream research directions, deliberately omitting
less influential branches.
  Given the rapid development of new methods and the limitations of existing
surveys in capturing recent trends, there is a pressing need for an updated and
comprehensive review. Our goal is to fill this gap by synthesizing the latest
advancements and state-of-the-art techniques in WSSS with image level labels.
  Basically, we provide a comprehensive review of recent advancements in WSSS
with image level labels, categorizing existing methods based on the types and
levels of additional supervision involved. We also examine the challenges of
applying advanced methods to domain specific datasets in WSSS,a topic that
remains underexplored. Finally, we discuss the current challenges, evaluate the
limitations of existing approaches, and outline several promising directions
for future research. This review is intended for researchers who are already
familiar with the fundamental concepts of WSSS and are seeking to deepen their
understanding of current advances and methodological innovations.

</details>


### [37] [Locally Controlled Face Aging with Latent Diffusion Models](https://arxiv.org/abs/2507.21600)
*Lais Isabelle Alves dos Santos,Julien Despois,Thibaut Chauffier,Sileye O. Ba,Giovanni Palma*

Main category: cs.CV

TL;DR: 提出一种通过潜在扩散模型实现局部面部区域老化的新方法，实验结果证明其在身份保持、真实感和可控老化方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前面部年龄变换方法存在局限性，通常将面部老化视为一个整体均质的过程，并忽视了面部区域由于内在和外在因素异质性老化的问题。这些问题激发了对于更切实的老化方法的需求。

Method: 该方法使用潜在扩散模型进行选择性面部区域老化，通过本地老化特征实现更细致的生成控制。然后使用潜在扩散细化器融入这些局部老化区域，确保合成的图像在整体上自然一致。

Result: 实验结果表明，该方法能够在成功的面部老化过程中实现三个关键标准：保持面部身份的鲁棒性、高保真和真实感的图像，以及自然可控的老化进程。

Conclusion: 该方法提供了一种更现实和个性化的面部年龄变换方式，通过对面部特定区域进行精细控制，实现自然一致的合成。

Abstract: We present a novel approach to face aging that addresses the limitations of
current methods which treat aging as a global, homogeneous process. Existing
techniques using GANs and diffusion models often condition generation on a
reference image and target age, neglecting that facial regions age
heterogeneously due to both intrinsic chronological factors and extrinsic
elements like sun exposure. Our method leverages latent diffusion models to
selectively age specific facial regions using local aging signs. This approach
provides significantly finer-grained control over the generation process,
enabling more realistic and personalized aging. We employ a latent diffusion
refiner to seamlessly blend these locally aged regions, ensuring a globally
consistent and natural-looking synthesis. Experimental results demonstrate that
our method effectively achieves three key criteria for successful face aging:
robust identity preservation, high-fidelity and realistic imagery, and a
natural, controllable aging progression.

</details>


### [38] [Decoupled Spatio-Temporal Consistency Learning for Self-Supervised Tracking](https://arxiv.org/abs/2507.21606)
*Yaozong Zheng,Bineng Zhong,Qihua Liang,Ning Li,Shuxiang Song*

Main category: cs.CV

TL;DR: 提出了一种名为Tracker的自监督跟踪框架，无需框标注，利用时空一致性学习和实例对比损失进行视觉跟踪，在多个数据集上取得优异成绩。


<details>
  <summary>Details</summary>
Motivation: 现有的跟踪数据集依赖人工框标注，需要巨大的人力投入，限制了数据集的规模和多样性。本文旨在通过自监督学习消除对框标注的需求。

Method: 提出了一种解耦的时空一致性训练框架，通过全局空间定位和局部时间关联学习丰富的目标信息。设计了实例对比损失，从多视角学习实例级对应关系。

Result: 通过在九个基准数据集上的广泛实验，Tracker在GOT10K、LaSOT、TrackingNet数据集的AUC (AO)评分中超过了现有自监督跟踪方法25.3%、20.4%和14.8%的改进。

Conclusion: 本文提出了一种新的自监督跟踪框架，即Tracker，无需框标注，通过消除繁重的人力标注需求实现更高效的视觉跟踪。

Abstract: The success of visual tracking has been largely driven by datasets with
manual box annotations. However, these box annotations require tremendous human
effort, limiting the scale and diversity of existing tracking datasets. In this
work, we present a novel Self-Supervised Tracking framework named
\textbf{{\tracker}}, designed to eliminate the need of box annotations.
Specifically, a decoupled spatio-temporal consistency training framework is
proposed to learn rich target information across timestamps through global
spatial localization and local temporal association. This allows for the
simulation of appearance and motion variations of instances in real-world
scenarios. Furthermore, an instance contrastive loss is designed to learn
instance-level correspondences from a multi-view perspective, offering robust
instance supervision without additional labels. This new design paradigm
enables {\tracker} to effectively learn generic tracking representations in a
self-supervised manner, while reducing reliance on extensive box annotations.
Extensive experiments on nine benchmark datasets demonstrate that {\tracker}
surpasses \textit{SOTA} self-supervised tracking methods, achieving an
improvement of more than 25.3\%, 20.4\%, and 14.8\% in AUC (AO) score on the
GOT10K, LaSOT, TrackingNet datasets, respectively. Code:
https://github.com/GXNU-ZhongLab/SSTrack.

</details>


### [39] [Semantic Segmentation of iPS Cells: Case Study on Model Complexity in Biomedical Imaging](https://arxiv.org/abs/2507.21608)
*Maoquan Zhang,Bisser Raytchev,Xiujuan Sun*

Main category: cs.CV

TL;DR: 简单经过调整的模型在特定医学图像分割任务中可优于复杂的基础模型。


<details>
  <summary>Details</summary>
Motivation: 基于医学图像分割需要在准确性和在挑战性成像条件下的鲁棒性之间达成平衡的需求。

Method: 配置DeepLabv3模型来进行诱导多能干细胞（iPS）细胞群的分割。

Result: 在实验条件下，经过精心配置的DeepLabv3模型在分割iPS细胞群中表现出色，优于大型基础模型如SAM2及其医疗变体MedSAM2。

Conclusion: 在特定任务中，简单且经过适当调整的模型可能提供强大的准确性和实用可靠性，而大型和更通用的架构并不总是可取的。

Abstract: Medical image segmentation requires not only accuracy but also robustness
under challenging imaging conditions. In this study, we show that a carefully
configured DeepLabv3 model can achieve high performance in segmenting induced
pluripotent stem (iPS) cell colonies, and, under our experimental conditions,
outperforms large-scale foundation models such as SAM2 and its medical variant
MedSAM2 without structural modifications. These results suggest that, for
specialized tasks characterized by subtle, low-contrast boundaries, increased
model complexity does not necessarily translate to better performance. Our work
revisits the assumption that ever-larger and more generalized architectures are
always preferable, and provides evidence that appropriately adapted, simpler
models may offer strong accuracy and practical reliability in domain-specific
biomedical applications. We also offer an open-source implementation that
includes strategies for small datasets and domain-specific encoding, with the
aim of supporting further advances in semantic segmentation for regenerative
medicine and related fields.

</details>


### [40] [Wind Turbine Feature Detection Using Deep Learning and Synthetic Data](https://arxiv.org/abs/2507.21611)
*Arash Shahirpour,Jakob Gebler,Manuel Sanders,Tim Reuscher*

Main category: cs.CV

TL;DR: 提出了一种生成合成数据的方法以增强风力涡轮机检测任务的数据集多样性，使用YOLOv11进行训练，在真实和合成图像中都表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖手动标注的真实世界图像，受到天气状况、光照条件、涡轮类型和图像复杂性等因素的限制，缺乏足够数量和多样性的训练数据集。

Method: 提出基于生成合成数据的方法，通过控制视觉和环境因素增强数据集多样性，并训练一个YOLOv11特征检测网络，该网络使用修改后的损失函数，专注于检测风力涡轮机及其关键特征。

Result: 评估显示，训练得到的网络在合成图像和一组真实世界风力涡轮机图像中表现良好，在未曾见过的真实图像上实现了0.97的Pose mAP50-95。

Conclusion: 使用合成数据训练的YOLOv11模型在检测风力涡轮机及其关键特征的任务中表现出色，在从未见过的真实图像上达到了Pose mAP50-95为0.97的高精度。

Abstract: For the autonomous drone-based inspection of wind turbine (WT) blades,
accurate detection of the WT and its key features is essential for safe drone
positioning and collision avoidance. Existing deep learning methods typically
rely on manually labeled real-world images, which limits both the quantity and
the diversity of training datasets in terms of weather conditions, lighting,
turbine types, and image complexity. In this paper, we propose a method to
generate synthetic training data that allows controlled variation of visual and
environmental factors, increasing the diversity and hence creating challenging
learning scenarios. Furthermore, we train a YOLOv11 feature detection network
solely on synthetic WT images with a modified loss function, to detect WTs and
their key features within an image. The resulting network is evaluated both
using synthetic images and a set of real-world WT images and shows promising
performance across both synthetic and real-world data, achieving a Pose
mAP50-95 of 0.97 on real images never seen during training.

</details>


### [41] [EMIT: Enhancing MLLMs for Industrial Anomaly Detection via Difficulty-Aware GRPO](https://arxiv.org/abs/2507.21619)
*Wei Guan,Jun Lan,Jian Cao,Hao Tan,Huijia Zhu,Weiqiang Wang*

Main category: cs.CV

TL;DR: EMIT是一个增强MLLM在工业异常检测中表现的框架，通过多种技术改进实现了显著性能提升，平均提高了7.77%。


<details>
  <summary>Details</summary>
Motivation: 当前的多模态大规模语言模型在工业异常检测中的效果有限，需进行领域特定的适应。

Method: 提出了EMIT框架，通过难度感知的组相对策略优化(GRPO)改进MLLM，并创建了一个多任务IAD数据集，结合GPT生成的对象文本描述来弥补缺失的有缺陷图像，集成了软提示和热图引导的对比嵌入以进行少量样本的异常检测。

Result: 在MMAD基准上的广泛实验表明EMIT显著增强了MLLM的IAD性能，在七个任务上相较基础模型(InternVL3-8B)平均提升了7.77%。

Conclusion: EMIT框架显著提高了MLLM在工业异常检测任务中的性能，比基础模型平均提高了7.77%。

Abstract: Industrial anomaly detection (IAD) plays a crucial role in maintaining the
safety and reliability of manufacturing systems. While multimodal large
language models (MLLMs) show strong vision-language reasoning abilities, their
effectiveness in IAD remains limited without domain-specific adaptation. In
this work, we propose EMIT, a unified framework that enhances MLLMs for IAD via
difficulty-aware group relative policy optimization (GRPO). EMIT constructs a
multi-task IAD dataset and utilizes GPT-generated object text descriptions to
compensate for missing defective images. For few-shot anomaly detection, it
integrates a soft prompt and heatmap-guided contrastive embeddings derived from
patch-level comparisons. To better handle difficult data samples, i.e., cases
where the MLLM struggles to generate correct answers, we propose a
difficulty-aware GRPO that extends the original GRPO by incorporating a
response resampling strategy to ensure the inclusion of correct answers in the
sampled responses, as well as an advantage reweighting mechanism to strengthen
learning from such difficult data samples. Extensive experiments on the MMAD
benchmark demonstrate that EMIT significantly enhances the IAD performance of
MLLMs, achieving an average improvement of 7.77\% over the base model
(InternVL3-8B) across seven tasks.

</details>


### [42] [GuidPaint: Class-Guided Image Inpainting with Diffusion Models](https://arxiv.org/abs/2507.21627)
*Qimin Wang,Xinda Liu,Guohua Geng*

Main category: cs.CV

TL;DR: 多模态图像修复的现有方法计算成本高，而新的GuidPaint框架通过分类器指导实现更精细的修复控制，无需训练，并提供视觉与语义一致性。


<details>
  <summary>Details</summary>
Motivation: 传统多模态修复方法需要架构修改和重新训练，计算成本高昂。而上下文感知扩散修复方法则利用模型的固有先验来调整中间去噪步骤，进行高质量修复且无需额外训练，显著降低计算量。然而，这些方法在细粒度控制方面存在不足，常导致语义不一致或视觉不合理的内容。

Method: 通过在去噪过程中引入分类器指导，GuidPaint实现了对掩模区域内中间生成结果的精确控制，确保语义一致性和视觉真实感。此外，它还集成了随机和确定性采样，让用户可以选择偏好的中间结果并进行确定性优化。

Result: 实验结果显示，GuidPaint在上下文感知修复方法方面取得了明显的改善。

Conclusion: GuidPaint 在定性和定量评估中均显示出明显优于现有上下文感知修复方法的改进。

Abstract: In recent years, diffusion models have been widely adopted for image
inpainting tasks due to their powerful generative capabilities, achieving
impressive results. Existing multimodal inpainting methods based on diffusion
models often require architectural modifications and retraining, resulting in
high computational cost. In contrast, context-aware diffusion inpainting
methods leverage the model's inherent priors to adjust intermediate denoising
steps, enabling high-quality inpainting without additional training and
significantly reducing computation. However, these methods lack fine-grained
control over the masked regions, often leading to semantically inconsistent or
visually implausible content. To address this issue, we propose GuidPaint, a
training-free, class-guided image inpainting framework. By incorporating
classifier guidance into the denoising process, GuidPaint enables precise
control over intermediate generations within the masked areas, ensuring both
semantic consistency and visual realism. Furthermore, it integrates stochastic
and deterministic sampling, allowing users to select preferred intermediate
results and deterministically refine them. Experimental results demonstrate
that GuidPaint achieves clear improvements over existing context-aware
inpainting methods in both qualitative and quantitative evaluations.

</details>


### [43] [The Evolution of Video Anomaly Detection: A Unified Framework from DNN to MLLM](https://arxiv.org/abs/2507.21649)
*Shibo Gao,Peipei Yang,Haiyang Guo,Yangyang Liu,Yi Chen,Shuai Li,Han Zhu,Jian Xu,Xu-Yao Zhang,Linlin Huang*

Main category: cs.CV

TL;DR: 本论文综述了视频异常检测（VAD）领域的大模型时代进展，提出了统一框架，分析了基于MLLMs和LLMs的VAD方法，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 视频异常检测（VAD）在智能监控和公共安全领域中具有重要意义。随着深度学习的发展，深度模型架构的不断演变推动了VAD方法的创新，大幅提升了特征表示和场景适应性。因此，急需对最近的进展进行系统性的综述。

Method: 本文通过系统性综述分析了基于多模态大模型（MLLMs）和大型语言模型（LLMs）的VAD方法，并提出了一个统一框架，涵盖基于深度神经网络（DNN）和大型语言模型的VAD方法。

Result: 本文构建了分类体系，并比较了不同方法的优缺点。此外，文章集中探讨了基于MLLMs/LLMs的当前VAD方法，提出了关键挑战和未来研究方向。

Conclusion: 本文提供了VAD领域在大模型时代的全面分析，指出了技术发展的瓶颈和未来的研究方向，为VAD社区提供了指导。

Abstract: Video anomaly detection (VAD) aims to identify and ground anomalous behaviors
or events in videos, serving as a core technology in the fields of intelligent
surveillance and public safety. With the advancement of deep learning, the
continuous evolution of deep model architectures has driven innovation in VAD
methodologies, significantly enhancing feature representation and scene
adaptability, thereby improving algorithm generalization and expanding
application boundaries. More importantly, the rapid development of multi-modal
large language (MLLMs) and large language models (LLMs) has introduced new
opportunities and challenges to the VAD field. Under the support of MLLMs and
LLMs, VAD has undergone significant transformations in terms of data
annotation, input modalities, model architectures, and task objectives. The
surge in publications and the evolution of tasks have created an urgent need
for systematic reviews of recent advancements. This paper presents the first
comprehensive survey analyzing VAD methods based on MLLMs and LLMs, providing
an in-depth discussion of the changes occurring in the VAD field in the era of
large models and their underlying causes. Additionally, this paper proposes a
unified framework that encompasses both deep neural network (DNN)-based and
LLM-based VAD methods, offering a thorough analysis of the new VAD paradigms
empowered by LLMs, constructing a classification system, and comparing their
strengths and weaknesses. Building on this foundation, this paper focuses on
current VAD methods based on MLLMs/LLMs. Finally, based on the trajectory of
technological advancements and existing bottlenecks, this paper distills key
challenges and outlines future research directions, offering guidance for the
VAD community.

</details>


### [44] [Automated Detection of Antarctic Benthic Organisms in High-Resolution In Situ Imagery to Aid Biodiversity Monitoring](https://arxiv.org/abs/2507.21665)
*Cameron Trotter,Huw Griffiths,Tasnuva Ming Khan,Rowan Whittle*

Main category: cs.CV

TL;DR: 提出了一种用于南极底栖生物识别的目标检测框架，并发布了一个数据集。该框架在检测中大型物种方面表现优异，但检测小型和稀有物种仍有难度。


<details>
  <summary>Details</summary>
Motivation: 了解气候变化对生态系统的影响，需要监测南极的底栖生物多样性。

Method: 提出了一种专门的目标检测框架，通过高分辨率拖曳相机影像识别和分类南极底栖生物，并发布了第一个公共的韦德尔海底栖生物多样性监测的计算机视觉数据集。

Result: 我们的方法在检测中大型生物方面表现出强劲的性能，可以识别25种细粒度形态类型。但对于小型和稀有生物的检测仍存在挑战，显示出当前检测架构的限制。

Conclusion: 该框架为未来的机辅助实时底栖生物多样性监测研究提供了可扩展的基础。

Abstract: Monitoring benthic biodiversity in Antarctica is vital for understanding
ecological change in response to climate-driven pressures. This work is
typically performed using high-resolution imagery captured in situ, though
manual annotation of such data remains laborious and specialised, impeding
large-scale analysis. We present a tailored object detection framework for
identifying and classifying Antarctic benthic organisms in high-resolution
towed camera imagery, alongside the first public computer vision dataset for
benthic biodiversity monitoring in the Weddell Sea. Our approach addresses key
challenges associated with marine ecological imagery, including limited
annotated data, variable object sizes, and complex seafloor structure. The
proposed framework combines resolution-preserving patching, spatial data
augmentation, fine-tuning, and postprocessing via Slicing Aided Hyper
Inference. We benchmark multiple object detection architectures and demonstrate
strong performance in detecting medium and large organisms across 25
fine-grained morphotypes, significantly more than other works in this area.
Detection of small and rare taxa remains a challenge, reflecting limitations in
current detection architectures. Our framework provides a scalable foundation
for future machine-assisted in situ benthic biodiversity monitoring research.

</details>


### [45] [APT: Improving Diffusion Models for High Resolution Image Generation with Adaptive Path Tracing](https://arxiv.org/abs/2507.21690)
*Sangmin Han,Jinho Jeong,Jinwoo Kim,Seon Joo Kim*

Main category: cs.CV

TL;DR: 提出自适应路径跟踪框架（APT），解决高分辨率图像生成中的补丁分布偏移和补丁单调性问题，生成更细腻的图像并提高推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的潜在扩散模型（LDMs）在训练时通常使用固定分辨率，这限制了其在生成高分辨率图像时的能力。在训练基础的方法需要大规模的数据和计算资源，这在实践中不太可行。无训练的方法，特别是基于补丁的方法，成为一种流行的替代方案。这些方法在高分辨率生成任务上显示了较强性能。

Method: 本文提出了一种名为自适应路径跟踪（APT）的框架，该框架结合统计匹配以确保补丁分布在上采样的潜在空间中保持一致，并通过尺度感知调度机制应对补丁单调性。APT还使去噪过程更快捷，并且质量下降最小。

Result: APT生成更清晰且细致的高分辨率图像，并且能够实现快速采样。实验结果表明，APT在生成更加详细的输出图像的同时提高了推理速度。

Conclusion: APT提供了高效且实用的高分辨率图像生成方法，它解决了补丁级别分布偏移和补丁单调性的两个关键问题。

Abstract: Latent Diffusion Models (LDMs) are generally trained at fixed resolutions,
limiting their capability when scaling up to high-resolution images. While
training-based approaches address this limitation by training on
high-resolution datasets, they require large amounts of data and considerable
computational resources, making them less practical. Consequently,
training-free methods, particularly patch-based approaches, have become a
popular alternative. These methods divide an image into patches and fuse the
denoising paths of each patch, showing strong performance on high-resolution
generation. However, we observe two critical issues for patch-based approaches,
which we call ``patch-level distribution shift" and ``increased patch
monotonicity." To address these issues, we propose Adaptive Path Tracing (APT),
a framework that combines Statistical Matching to ensure patch distributions
remain consistent in upsampled latents and Scale-aware Scheduling to deal with
the patch monotonicity. As a result, APT produces clearer and more refined
details in high-resolution images. In addition, APT enables a shortcut
denoising process, resulting in faster sampling with minimal quality
degradation. Our experimental results confirm that APT produces more detailed
outputs with improved inference speed, providing a practical approach to
high-resolution image generation.

</details>


### [46] [Semantics versus Identity: A Divide-and-Conquer Approach towards Adjustable Medical Image De-Identification](https://arxiv.org/abs/2507.21703)
*Yuan Tian,Shuo Wang,Rongzhao Zhang,Zijian Chen,Yankai Jiang,Chunyi Li,Xiangyang Zhu,Fang Yan,Qiang Hu,XiaoSong Wang,Guangtao Zhai*

Main category: cs.CV

TL;DR: 提议了一种新的去识别框架，该框架可以灵活调整隐私级别并保留医疗语义，在多个数据集和任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 目前的去识别方法无法特别保护医疗语义，也不能灵活调整隐私级别，需要一种方法既能保护医疗语义又能调整隐私级别。

Method: 提出一个 "分而治之 "的框架，包含两个步骤: (1) 身份阻断，通过阻断不同比例的身份相关区域来实现不同的隐私级别;(2) 医疗语义补偿，利用预训练的医疗基础模型（MFMs）提取医疗语义特征以补偿被阻断的区域。此外，采用一种基于最小描述长度原则的特征解耦策略，以有效解耦并丢弃残留的身份信息。

Result: 在七个数据集和三个下游任务中进行了广泛的评估，结果表明提出的方法性能优于现有方法。

Conclusion: 提出了一种新的去识别框架，可以在保护医疗语义的同时，灵活调整隐私级别，并在性能上优于现有方法。

Abstract: Medical imaging has significantly advanced computer-aided diagnosis, yet its
re-identification (ReID) risks raise critical privacy concerns, calling for
de-identification (DeID) techniques. Unfortunately, existing DeID methods
neither particularly preserve medical semantics, nor are flexibly adjustable
towards different privacy levels. To address these issues, we propose a
divide-and-conquer framework comprising two steps: (1) Identity-Blocking, which
blocks varying proportions of identity-related regions, to achieve different
privacy levels; and (2) Medical-Semantics-Compensation, which leverages
pre-trained Medical Foundation Models (MFMs) to extract medical semantic
features to compensate the blocked regions. Moreover, recognizing that features
from MFMs may still contain residual identity information, we introduce a
Minimum Description Length principle-based feature decoupling strategy, to
effectively decouple and discard such identity components. Extensive
evaluations against existing approaches across seven datasets and three
downstream tasks, demonstrates our state-of-the-art performance.

</details>


### [47] [Impact of Underwater Image Enhancement on Feature Matching](https://arxiv.org/abs/2507.21715)
*Jason M. Summers,Mark W. Jones*

Main category: cs.CV

TL;DR: 提出了一种用于评估水下图像增强效果的新框架，通过改善视觉质量来提高后继任务的性能，并证明了增强对SLAM算法的影响。


<details>
  <summary>Details</summary>
Motivation: 在水下环境中，由于光吸收、散射、海洋生物生长和碎片而导致的视觉降级问题，严重影响了后续任务如路径检测和自主导航的性能。因此，需要增强图像质量以提高特征提取和帧匹配的效果。

Method: 提出了一种全新的评估框架，运用基于度量的分析和实际匹配策略来评估图像增强方法的效果，特别适用于水下环境。

Result: 通过实验展示了图像视觉改进如何影响实际算法，如同时定位与地图构建（SLAM）的性能，从而证明了该框架在操作水下场景中的相关性。

Conclusion: 该评估框架提供了一个稳健且适应上下文的基准，可以用于比较不同图像增强方法的性能，识别现有方法的优势和局限性，以及它们在现实世界中的适用性差距。

Abstract: We introduce local matching stability and furthest matchable frame as
quantitative measures for evaluating the success of underwater image
enhancement. This enhancement process addresses visual degradation caused by
light absorption, scattering, marine growth, and debris. Enhanced imagery plays
a critical role in downstream tasks such as path detection and autonomous
navigation for underwater vehicles, relying on robust feature extraction and
frame matching. To assess the impact of enhancement techniques on
frame-matching performance, we propose a novel evaluation framework tailored to
underwater environments. Through metric-based analysis, we identify strengths
and limitations of existing approaches and pinpoint gaps in their assessment of
real-world applicability. By incorporating a practical matching strategy, our
framework offers a robust, context-aware benchmark for comparing enhancement
methods. Finally, we demonstrate how visual improvements affect the performance
of a complete real-world algorithm -- Simultaneous Localization and Mapping
(SLAM) -- reinforcing the framework's relevance to operational underwater
scenarios.

</details>


### [48] [Detection Transformers Under the Knife: A Neuroscience-Inspired Approach to Ablations](https://arxiv.org/abs/2507.21723)
*Nils Hütten,Florian Hölken,Hasan Tercan,Tobias Meisen*

Main category: cs.CV

TL;DR: 研究分析了检测变压器的内部组件，通过消融实验提高理解及透明度，发现具体模型的抗性模式和冗余结构。


<details>
  <summary>Details</summary>
Motivation: 了解内部组件的独特角色，以改善透明度和效率。

Method: 受神经科学消融研究启发，系统分析三种最先进检测变压器中的关键组件消融影响。

Result: 结果显示DETR对编码器MHSA和解码器MHCA消融敏感，而DDETR的多尺度可变形注意力提高了鲁棒性，DINO展现最大抵抗力。同时DDETR和DINO的解码器MHCA层存在结构冗余。

Conclusion: 这项研究阐明了内部组件对模型性能的贡献，提供了优化和改进关键应用中的透明性和效率的见解。

Abstract: In recent years, Explainable AI has gained traction as an approach to
enhancing model interpretability and transparency, particularly in complex
models such as detection transformers. Despite rapid advancements, a
substantial research gap remains in understanding the distinct roles of
internal components - knowledge that is essential for improving transparency
and efficiency. Inspired by neuroscientific ablation studies, which investigate
the functions of brain regions through selective impairment, we systematically
analyze the impact of ablating key components in three state-of-the-art
detection transformer models: Detection transformer (DETR), deformable
detection transformer (DDETR), and DETR with improved denoising anchor boxes
(DINO). The ablations target query embeddings, encoder and decoder multi-head
self-attentions (MHSA) as well as decoder multi-head cross-attention (MHCA)
layers. We evaluate the effects of these ablations on the performance metrics
gIoU and F1-score, quantifying effects on both the classification and
regression sub-tasks on the COCO dataset. To facilitate reproducibility and
future research, we publicly release the DeepDissect library. Our findings
reveal model-specific resilience patterns: while DETR is particularly sensitive
to ablations in encoder MHSA and decoder MHCA, DDETR's multi-scale deformable
attention enhances robustness, and DINO exhibits the greatest resilience due to
its look-forward twice update rule, which helps distributing knowledge across
blocks. These insights also expose structural redundancies, particularly in
DDETR's and DINO's decoder MHCA layers, highlighting opportunities for model
simplification without sacrificing performance. This study advances XAI for
DETRs by clarifying the contributions of internal components to model
performance, offering insights to optimize and improve transparency and
efficiency in critical applications.

</details>


### [49] [SAMITE: Position Prompted SAM2 with Calibrated Memory for Visual Object Tracking](https://arxiv.org/abs/2507.21732)
*Qianxiong Xu,Lanyun Zhu,Chenxi Liu,Guosheng Lin,Cheng Long,Ziyue Li,Rui Zhao*

Main category: cs.CV

TL;DR: SAMITE模型通过优化目标遮挡和干扰处理模块，提升视觉对象跟踪效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有视觉对象跟踪方法在处理时间帧纵向依赖和对未见类别泛化能力弱的问题，尤其是在处理目标遮挡和干扰物方面存在的挑战。

Method: SAMITE模型在SAM2基础上增加了原型记忆库和位置提示生成器模块来优化视觉目标跟踪。

Result: 实验显示，SAMITE在六个基准测试中表现出优越性，改善了跟踪误差的传播并增强了目标跟踪精度。

Conclusion: SAMITE模型通过添加模块有效改善了现有方法在处理目标遮挡和干扰物方面的问题，提高了视觉目标跟踪的准确性。

Abstract: Visual Object Tracking (VOT) is widely used in applications like autonomous
driving to continuously track targets in videos. Existing methods can be
roughly categorized into template matching and autoregressive methods, where
the former usually neglects the temporal dependencies across frames and the
latter tends to get biased towards the object categories during training,
showing weak generalizability to unseen classes. To address these issues, some
methods propose to adapt the video foundation model SAM2 for VOT, where the
tracking results of each frame would be encoded as memory for conditioning the
rest of frames in an autoregressive manner. Nevertheless, existing methods fail
to overcome the challenges of object occlusions and distractions, and do not
have any measures to intercept the propagation of tracking errors. To tackle
them, we present a SAMITE model, built upon SAM2 with additional modules,
including: (1) Prototypical Memory Bank: We propose to quantify the
feature-wise and position-wise correctness of each frame's tracking results,
and select the best frames to condition subsequent frames. As the features of
occluded and distracting objects are feature-wise and position-wise inaccurate,
their scores would naturally be lower and thus can be filtered to intercept
error propagation; (2) Positional Prompt Generator: To further reduce the
impacts of distractors, we propose to generate positional mask prompts to
provide explicit positional clues for the target, leading to more accurate
tracking. Extensive experiments have been conducted on six benchmarks, showing
the superiority of SAMITE. The code is available at
https://github.com/Sam1224/SAMITE.

</details>


### [50] [MAGE: Multimodal Alignment and Generation Enhancement via Bridging Visual and Semantic Spaces](https://arxiv.org/abs/2507.21741)
*Shaojun E,Yuchen Yang,Jiaheng Wu,Yan Zhang,Tiejun Zhao,Ziyan Chen*

Main category: cs.CV

TL;DR: MAGE框架通过创新的对齐机制有效解决了视觉数据编码后的信息损失，显著提升多模态学习模型的性能。


<details>
  <summary>Details</summary>
Motivation: 解决视觉数据编码后的空间和语义损失问题，特别是视觉编码器与大语言模型之间的耦合，以防止信息传播过程中出现向量间隔或语义差异。

Method: 提出了MAGE框架，通过创新的对齐机制和智能对齐网络（IAN）实现视觉与文本的维度和语义对齐，同时通过结合交叉熵和均方误差的训练策略来减少同义异质数据之间的差距。

Result: MAGE在多个评估基准，包括MME, MMBench和SEED上表现优于类似的工作。

Conclusion: MAGE框架显著提高了跨多种基准评估的性能，展示了其在多模态学习中的有效性。

Abstract: In the latest advancements in multimodal learning, effectively addressing the
spatial and semantic losses of visual data after encoding remains a critical
challenge. This is because the performance of large multimodal models is
positively correlated with the coupling between visual encoders and large
language models. Existing approaches often face issues such as vector gaps or
semantic disparities, resulting in information loss during the propagation
process. To address these issues, we propose MAGE (Multimodal Alignment and
Generation Enhancement), a novel framework that bridges the semantic spaces of
vision and text through an innovative alignment mechanism. By introducing the
Intelligent Alignment Network (IAN), MAGE achieves dimensional and semantic
alignment. To reduce the gap between synonymous heterogeneous data, we employ a
training strategy that combines cross-entropy and mean squared error,
significantly enhancing the alignment effect. Moreover, to enhance MAGE's
"Any-to-Any" capability, we developed a fine-tuning dataset for multimodal
tool-calling instructions to expand the model's output capability boundaries.
Finally, our proposed multimodal large model architecture, MAGE, achieved
significantly better performance compared to similar works across various
evaluation benchmarks, including MME, MMBench, and SEED. Complete code and
appendix are available at: https://github.com/GTCOM-NLP/MAGE.

</details>


### [51] [Adversarial Reconstruction Feedback for Robust Fine-grained Generalization](https://arxiv.org/abs/2507.21742)
*Shijie Wang,Jian Shi,Haojie Li*

Main category: cs.CV

TL;DR: 提出了一种对抗重构框架AdvRF，不依赖于预定义类别，提升了图像检索的泛化能力，取得了优异的实验结果。


<details>
  <summary>Details</summary>
Motivation: 现有的图像检索方法依赖于预定义的类别进行监督，使得其在未见类别上的泛化能力受限。

Method: 提出了AdvRF，一种新颖的对抗重构反馈框架，旨在学习与类别无关的差异表征。通过结合检索模型的类别感知差异定位与重构模型的类别无关特征学习，将FGIR重新制定为视觉差异重构任务。

Result: AdvRF在常用的数据集上表现优异，证明了其有效性。

Conclusion: AdvRF方法提高了图像检索中的泛化性能，能在广泛使用的精细和粗糙数据集上取得显著效果。

Abstract: Existing fine-grained image retrieval (FGIR) methods predominantly rely on
supervision from predefined categories to learn discriminative representations
for retrieving fine-grained objects. However, they inadvertently introduce
category-specific semantics into the retrieval representation, creating
semantic dependencies on predefined classes that critically hinder
generalization to unseen categories. To tackle this, we propose AdvRF, a novel
adversarial reconstruction feedback framework aimed at learning
category-agnostic discrepancy representations. Specifically, AdvRF reformulates
FGIR as a visual discrepancy reconstruction task via synergizing category-aware
discrepancy localization from retrieval models with category-agnostic feature
learning from reconstruction models. The reconstruction model exposes residual
discrepancies overlooked by the retrieval model, forcing it to improve
localization accuracy, while the refined signals from the retrieval model guide
the reconstruction model to improve its reconstruction ability. Consequently,
the retrieval model localizes visual differences, while the reconstruction
model encodes these differences into category-agnostic representations. This
representation is then transferred to the retrieval model through knowledge
distillation for efficient deployment. Quantitative and qualitative evaluations
demonstrate that our AdvRF achieves impressive performance on both widely-used
fine-grained and coarse-grained datasets.

</details>


### [52] [Few-Shot Vision-Language Reasoning for Satellite Imagery via Verifiable Rewards](https://arxiv.org/abs/2507.21745)
*Aybora Koksal,A. Aydin Alatan*

Main category: cs.CV

TL;DR: 研究提出一种RLVR框架，利用极少的例子显著提高遥感图像任务中的推理能力，无需标注数据。


<details>
  <summary>Details</summary>
Motivation: 大规模语言和视觉语言模型虽然推理能力强，但在数据匮乏的专业领域不实用，尤其是遥感领域。

Method: 提出一个1-shot RLVR范式，从语言模型适应到视觉语言模型，采用策略梯度优化，使卫星推理任务中模型结果对齐。

Result: 在多个遥感基准上进行的综合实验表明，即使是单个例子也能显著改进基础模型，扩展到128个例子时甚至能与经过数千标注样本训练的模型相媲美或超过。

Conclusion: 该研究展示了一种RLVR框架，在遥感图像任务中不需要标注数据，仅依赖轻量级的规则二值或IoU奖励。这一方法能够在使用极少例子的情况下改进模型的推理能力。

Abstract: Recent advances in large language and vision-language models have enabled
strong reasoning capabilities, yet they remain impractical for specialized
domains like remote sensing, where annotated data is scarce and expensive. We
present the first few-shot reinforcement learning with verifiable reward (RLVR)
framework for satellite imagery that eliminates the need for caption
supervision--relying solely on lightweight, rule-based binary or IoU-based
rewards. Adapting the "1-shot RLVR" paradigm from language models to
vision-language models, we employ policy-gradient optimization with as few as
one curated example to align model outputs for satellite reasoning tasks.
Comprehensive experiments across multiple remote sensing benchmarks--including
classification, visual question answering, and grounding--show that even a
single example yields substantial improvements over the base model. Scaling to
128 examples matches or exceeds models trained on thousands of annotated
samples. While the extreme one-shot setting can induce mild, task-specific
overfitting, our approach consistently demonstrates robust generalization and
efficiency across diverse tasks. Further, we find that prompt design and loss
weighting significantly influence training stability and final accuracy. Our
method enables cost-effective and data-efficient development of
domain-specialist vision-language reasoning models, offering a pragmatic recipe
for data-scarce fields: start from a compact VLM, curate a handful of
reward-checkable cases, and train via RLVR.

</details>


### [53] [LiteFat: Lightweight Spatio-Temporal Graph Learning for Real-Time Driver Fatigue Detection](https://arxiv.org/abs/2507.21756)
*Jing Ren,Suyu Ma,Hong Jia,Xiwei Xu,Ivan Lee,Haytham Fayek,Xiaodong Li,Feng Xia*

Main category: cs.CV

TL;DR: 本文提出LiteFat，一个轻量级时空图学习模型，通过人脸特征提取和时空图神经网络，实现了高效的驾驶员疲劳检测，减少了计算复杂性和延迟，可部署于嵌入式设备中。


<details>
  <summary>Details</summary>
Motivation: 由于疲劳驾驶是交通事故的主要原因之一，现有方法依赖高计算量的深度学习模型，导致延迟高，不适合在智能车辆等资源有限的嵌入式设备上使用，因此急需低计算需求、实时的疲劳检测方法。

Method: 本文设计了一种轻量级时空图学习模型LiteFat，通过人脸关键点检测，将流媒体视频数据转换为时空图。LiteFat使用MobileNet模型提取人脸特征，创建特征矩阵并通过轻量级时空图神经网络识别疲劳特征。

Result: 实验结果表明，LiteFat在基准数据集上表现出具有竞争力的检测性能，并且显著降低了计算复杂性和延迟，与当前先进方法相比具有优势。

Conclusion: LiteFat模型在减少计算复杂性和延迟的同时仍能保持较高的检测精度。这使得在资源受限的嵌入式设备上实现实时且高效的人体疲劳检测系统成为可能。

Abstract: Detecting driver fatigue is critical for road safety, as drowsy driving
remains a leading cause of traffic accidents. Many existing solutions rely on
computationally demanding deep learning models, which result in high latency
and are unsuitable for embedded robotic devices with limited resources (such as
intelligent vehicles/cars) where rapid detection is necessary to prevent
accidents. This paper introduces LiteFat, a lightweight spatio-temporal graph
learning model designed to detect driver fatigue efficiently while maintaining
high accuracy and low computational demands. LiteFat involves converting
streaming video data into spatio-temporal graphs (STG) using facial landmark
detection, which focuses on key motion patterns and reduces unnecessary data
processing. LiteFat uses MobileNet to extract facial features and create a
feature matrix for the STG. A lightweight spatio-temporal graph neural network
is then employed to identify signs of fatigue with minimal processing and low
latency. Experimental results on benchmark datasets show that LiteFat performs
competitively while significantly decreasing computational complexity and
latency as compared to current state-of-the-art methods. This work enables the
development of real-time, resource-efficient human fatigue detection systems
that can be implemented upon embedded robotic devices.

</details>


### [54] [MOR-VIT: Efficient Vision Transformer with Mixture-of-Recursions](https://arxiv.org/abs/2507.21761)
*YiZhou Li*

Main category: cs.CV

TL;DR: MoR-ViT通过动态递归机制提高ViT的效率和精度，减少参数冗余，拓展了ViT在实际应用中的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统的ViT架构中存在参数冗余和高计算成本的问题，影响其实用性。因此，需要一种更高效的架构来改善这一问题。

Method: MoR-ViT引入了一种新的动态递归机制，使每个token可以自适应地决定其处理深度，灵活分配计算资源。

Result: 实验表明，MoR-ViT在减少70%参数和提升2.5倍推理速度的同时，依然能够取得最先进的精度表现。

Conclusion: MoR-ViT引入了动态递归机制，使得视觉Transformer在减少参数冗余的同时提升了推理速度和精度，展示了动态递归作为高效视觉Transformer的一种有效策略。

Abstract: Vision Transformers (ViTs) have achieved remarkable success in image
recognition, yet standard ViT architectures are hampered by substantial
parameter redundancy and high computational cost, limiting their practical
deployment. While recent efforts on efficient ViTs primarily focus on static
model compression or token-level sparsification, they remain constrained by
fixed computational depth for all tokens. In this work, we present MoR-ViT, a
novel vision transformer framework that, for the first time, incorporates a
token-level dynamic recursion mechanism inspired by the Mixture-of-Recursions
(MoR) paradigm. This approach enables each token to adaptively determine its
processing depth, yielding a flexible and input-dependent allocation of
computational resources. Extensive experiments on ImageNet-1K and transfer
benchmarks demonstrate that MoR-ViT not only achieves state-of-the-art accuracy
with up to 70% parameter reduction and 2.5x inference acceleration, but also
outperforms leading efficient ViT baselines such as DynamicViT and TinyViT
under comparable conditions. These results establish dynamic recursion as an
effective strategy for efficient vision transformers and open new avenues for
scalable and deployable deep learning models in real-world scenarios.

</details>


### [55] [AU-LLM: Micro-Expression Action Unit Detection via Enhanced LLM-Based Feature Fusion](https://arxiv.org/abs/2507.21778)
*Zhishu Liu,Kaishen Yuan,Bo Zhao,Yong Xu,Zitong Yu*

Main category: cs.CV

TL;DR: 本文提出AU-LLM框架，将大型语言模型用于微表情动作单元检测，使用增强融合投影器解决视觉与语言语义之间的差距，取得了新的技术状态。


<details>
  <summary>Details</summary>
Motivation: 微表情动作单元检测对于解码隐蔽且不自主的人类情感至关重要，而将LLM应用于微表情检测领域尚属未探讨的方向。

Method: 提出了一种增强融合投影器（EFP）的方法，使用多层感知器（MLP）融合3D-CNN主干网络的中层和高层视觉特征，形成信息密集的单一标记以支持LLM的微妙推理。

Result: AU-LLM通过扩展评估在CASME II和SAMM基准数据集上设定了新的技术状态，证明了LLM在微表情分析中的巨大潜力和鲁棒性。

Conclusion: 本文引入了AU-LLM，这是一个将大型语言模型（LLM）应用于微表情数据集中动作单元（AUs）检测的创新框架，并在基准数据集上验证了其有效性，设定了新的技术状态。

Abstract: The detection of micro-expression Action Units (AUs) is a formidable
challenge in affective computing, pivotal for decoding subtle, involuntary
human emotions. While Large Language Models (LLMs) demonstrate profound
reasoning abilities, their application to the fine-grained, low-intensity
domain of micro-expression AU detection remains unexplored. This paper pioneers
this direction by introducing \textbf{AU-LLM}, a novel framework that for the
first time uses LLM to detect AUs in micro-expression datasets with subtle
intensities and the scarcity of data. We specifically address the critical
vision-language semantic gap, the \textbf{Enhanced Fusion Projector (EFP)}. The
EFP employs a Multi-Layer Perceptron (MLP) to intelligently fuse mid-level
(local texture) and high-level (global semantics) visual features from a
specialized 3D-CNN backbone into a single, information-dense token. This
compact representation effectively empowers the LLM to perform nuanced
reasoning over subtle facial muscle movements.Through extensive evaluations on
the benchmark CASME II and SAMM datasets, including stringent
Leave-One-Subject-Out (LOSO) and cross-domain protocols, AU-LLM establishes a
new state-of-the-art, validating the significant potential and robustness of
LLM-based reasoning for micro-expression analysis. The codes are available at
https://github.com/ZS-liu-JLU/AU-LLMs.

</details>


### [56] [MSGCoOp: Multiple Semantic-Guided Context Optimization for Few-Shot Learning](https://arxiv.org/abs/2507.21786)
*Zhaolong Wang,Tongfeng Sun,Mingzheng Du,Yachao Huang*

Main category: cs.CV

TL;DR: MSGCoOp框架在不增加计算负担的情况下，通过多语义引导上下文和多样性正则化提高少样本泛化能力。在多个基准数据集上表现出色，且在跨领域泛化任务中具备更好的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常在新类的泛化上表现不佳，这是由于在已知类别上的过拟合和对一般知识的遗忘造成的。为了在保持计算效率的同时提高少样本泛化能力，提出了MSGCoOp框架。

Method: 提出了一个多语义引导上下文优化（MSGCoOp）框架，采用并行的可学习上下文向量，以捕捉多样的语义特征。同时，引入语义引导机制，将上下文与由大型语言模型自动生成的类别描述对齐，并通过多样性正则化损失来促使上下文学习互补和正交的特征。

Result: 在11个基准数据集上的广泛实验表明，MSGCoOp在基础到新类别的泛化性能上显著提高，相较于KgCoOp基线平均提升了1.10%的谐波平均值。此外，MSGCoOp在跨领域泛化任务中表现出更高的鲁棒性。

Conclusion: 使用MSGCoOp可在不显著增加计算负担的情况下提高少样本的泛化能力。通过引入多个上下文向量和语义指导机制，促使生成的类别描述与语义保持一致，并且通过多样性正则化损失保持上下文的多样性和独特性。

Abstract: Vision-language pre-trained models (VLMs) such as CLIP have demonstrated
remarkable zero-shot generalization, and prompt learning has emerged as an
efficient alternative to full fine-tuning. However, existing methods often
struggle with generalization to novel classes, a phenomenon attributed to
overfitting on seen classes and forgetting general knowledge. Furthermore,
recent approaches that improve generalization often introduce complex
architectures or heavy computational overhead. In this paper, we propose a
Multiple Semantic-Guided Context Optimization (MSGCoOp) framework to enhance
few-shot generalization while maintaining computational efficiency. Our
approach leverages an ensemble of parallel learnable context vectors to capture
diverse semantic aspects. To enrich these prompts, we introduce a semantic
guidance mechanism that aligns them with comprehensive class descriptions
automatically generated by a Large Language Model (LLM). Furthermore, a
diversity regularization loss encourages the prompts to learn complementary and
orthogonal features, preventing them from collapsing into redundant
representations. Extensive experiments on 11 benchmark datasets show that
MSGCoOp significantly improves performance on base-to-novel generalization,
achieving an average harmonic mean improvement of 1.10\% over the strong KgCoOp
baseline. Our method also demonstrates enhanced robustness in cross-domain
generalization tasks. Our code is avaliable at:
\href{https://github.com/Rain-Bus/MSGCoOp}{https://github.com/Rain-Bus/MSGCoOp}.

</details>


### [57] [Distribution-Based Masked Medical Vision-Language Model Using Structured Reports](https://arxiv.org/abs/2507.21794)
*Shreyank N Gowda,Ruichi Zhang,Xiao Gu,Ying Weng,Lu Yang*

Main category: cs.CV

TL;DR: 本文介绍了一种不确定性感知的医学图像文本预训练模型，通过大型语言模型生成的结构化文本报告提高医学图像分析的泛化能力，并取得了领先的性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型难以处理医疗数据中的多样性和模糊性，限制了捕捉临床信息和不确定性的能力。

Method: 引入一个不确定性感知的医学图像文本预训练模型，利用大型语言模型生成的结构化文本报告来补充图像数据，以增强医学图像分析的泛化能力。

Result: 该模型在多个后续任务中取得了最先进的性能。

Conclusion: 通过对模态间和模态内的不确定性进行建模，框架能够捕捉医学图像和文本中的固有模糊性，从而改善表征和性能。

Abstract: Medical image-language pre-training aims to align medical images with
clinically relevant text to improve model performance on various downstream
tasks. However, existing models often struggle with the variability and
ambiguity inherent in medical data, limiting their ability to capture nuanced
clinical information and uncertainty. This work introduces an uncertainty-aware
medical image-text pre-training model that enhances generalization capabilities
in medical image analysis. Building on previous methods and focusing on Chest
X-Rays, our approach utilizes structured text reports generated by a large
language model (LLM) to augment image data with clinically relevant context.
These reports begin with a definition of the disease, followed by the
`appearance' section to highlight critical regions of interest, and finally
`observations' and `verdicts' that ground model predictions in clinical
semantics. By modeling both inter- and intra-modal uncertainty, our framework
captures the inherent ambiguity in medical images and text, yielding improved
representations and performance on downstream tasks. Our model demonstrates
significant advances in medical image-text pre-training, obtaining
state-of-the-art performance on multiple downstream tasks.

</details>


### [58] [HunyuanWorld 1.0: Generating Immersive, Explorable, and Interactive 3D Worlds from Words or Pixels](https://arxiv.org/abs/2507.21809)
*HunyuanWorld Team,Zhenwei Wang,Yuhao Liu,Junta Wu,Zixiao Gu,Haoyuan Wang,Xuhui Zuo,Tianyu Huang,Wenhuan Li,Sheng Zhang,Yihang Lian,Yulin Tsai,Lifu Wang,Sicong Liu,Puhua Jiang,Xianghui Yang,Dongyuan Guo,Yixuan Tang,Xinyue Mao,Jiaao Yu,Junlin Yu,Jihong Zhang,Meng Chen,Liang Dong,Yiwen Jia,Chao Zhang,Yonghao Tan,Hao Zhang,Zheng Ye,Peng He,Runzhou Wu,Minghui Chen,Zhan Li,Wangchen Qin,Lei Wang,Yifu Sun,Lin Niu,Xiang Yuan,Xiaofeng Yang,Yingping He,Jie Xiao,Yangyu Tao,Jianchen Zhu,Jinbao Xue,Kai Liu,Chongqing Zhao,Xinming Wu,Tian Liu,Peng Chen,Di Wang,Yuhong Liu,Linus,Jie Jiang,Tengfei Wang,Chunchao Guo*

Main category: cs.CV

TL;DR: HunyuanWorld 1.0是一种新的框架，结合视频和3D方法优点，生成沉浸式3D世界，并展示了在虚拟现实和游戏开发等应用中的先进表现。


<details>
  <summary>Details</summary>
Motivation: 文本和图像生成沉浸式可玩的3D世界是计算机视觉和图形学的基本挑战。现有的方法存在问题：视频方法缺乏3D一致性和渲染效率；3D方法几何一致但训练数据有限且表示记忆效率低。

Method: 引入HunyuanWorld 1.0框架，结合视频和3D方法的优点，使用语义分层3D网格表示，利用全景图像进行360度世界代理，实现语义感知的世界分解和重构。

Result: HunyuanWorld 1.0在生成连贯、可探索和交互的3D世界方面达到先进表现，支持虚拟现实、物理模拟、游戏开发和互动内容创建等应用。

Conclusion: HunyuanWorld 1.0解决了文本和图像生成3D世界的现有方法限制，提供了沉浸式、可探索和互动的体验，并具有灵活的应用潜力。

Abstract: Creating immersive and playable 3D worlds from texts or images remains a
fundamental challenge in computer vision and graphics. Existing world
generation approaches typically fall into two categories: video-based methods
that offer rich diversity but lack 3D consistency and rendering efficiency, and
3D-based methods that provide geometric consistency but struggle with limited
training data and memory-inefficient representations. To address these
limitations, we present HunyuanWorld 1.0, a novel framework that combines the
best of both worlds for generating immersive, explorable, and interactive 3D
scenes from text and image conditions. Our approach features three key
advantages: 1) 360{\deg} immersive experiences via panoramic world proxies; 2)
mesh export capabilities for seamless compatibility with existing computer
graphics pipelines; 3) disentangled object representations for augmented
interactivity. The core of our framework is a semantically layered 3D mesh
representation that leverages panoramic images as 360{\deg} world proxies for
semantic-aware world decomposition and reconstruction, enabling the generation
of diverse 3D worlds. Extensive experiments demonstrate that our method
achieves state-of-the-art performance in generating coherent, explorable, and
interactive 3D worlds while enabling versatile applications in virtual reality,
physical simulation, game development, and interactive content creation.

</details>


### [59] [Anyone Can Jailbreak: Prompt-Based Attacks on LLMs and T2Is](https://arxiv.org/abs/2507.21820)
*Ahmed B Mustafa,Zihan Ye,Yang Lu,Michael P Pound,Shreyank N Gowda*

Main category: cs.CV

TL;DR: 文本和图像生成模型易被用户利用简单提示策略攻击，贯穿整个审查过程存在安全漏洞，呼吁开发上下文感知防御。


<details>
  <summary>Details</summary>
Motivation: 大语言模型和文本到图像系统易受用户通过巧妙措辞实现的低门槛、高影响的越权攻击，为解决这一问题，本文进行系统调查以揭示普通用户使用策略绕过机制的过程。

Method: 本文采用了一种系统风格的方法，通过实证案例分析对文本输出和文本到图像模型的提示级越权攻击策略进行了统一分类，并揭示了用户如何通过简单策略绕过安全机制。

Result: 分析揭示了每个审查流程阶段都可以被用户通过简单策略绕过，从输入过滤到输出验证，均存在安全漏洞。

Conclusion: 现有的内容审查机制缺乏足够的上下文感知能力，无法有效应对用户轻松复现的越权攻击。为应对这一挑战，亟需开发更有效的上下文感知防御措施。

Abstract: Despite significant advancements in alignment and content moderation, large
language models (LLMs) and text-to-image (T2I) systems remain vulnerable to
prompt-based attacks known as jailbreaks. Unlike traditional adversarial
examples requiring expert knowledge, many of today's jailbreaks are low-effort,
high-impact crafted by everyday users with nothing more than cleverly worded
prompts. This paper presents a systems-style investigation into how non-experts
reliably circumvent safety mechanisms through techniques such as multi-turn
narrative escalation, lexical camouflage, implication chaining, fictional
impersonation, and subtle semantic edits. We propose a unified taxonomy of
prompt-level jailbreak strategies spanning both text-output and T2I models,
grounded in empirical case studies across popular APIs. Our analysis reveals
that every stage of the moderation pipeline, from input filtering to output
validation, can be bypassed with accessible strategies. We conclude by
highlighting the urgent need for context-aware defenses that reflect the ease
with which these jailbreaks can be reproduced in real-world settings.

</details>


### [60] [Cross-Architecture Distillation Made Simple with Redundancy Suppression](https://arxiv.org/abs/2507.21844)
*Weijia Zhang,Yuehao Liu,Wu Ran,Chao Ma*

Main category: cs.CV

TL;DR: 提出了一种简单方法进行跨架构知识蒸馏，通过减少架构专属信息来提升效率，并在CIFAR-100和ImageNet-1k上表现优于OFA。


<details>
  <summary>Details</summary>
Motivation: 现有方法由于引入复杂模块、架构针对性设计及大量参数而效率低下，影响适用性。因此，提出一种简单且高效的方法以提升跨架构知识蒸馏的效果。

Method: 采用了一种称为冗余抑制蒸馏（RSD）的损失方法，包括跨架构不变性最大化和特征去相关目标。同时设计了一个轻量级模块以保持学生模型的架构专有能力。

Result: 该方法不需架构专有设计及复杂操作，并在CIFAR-100和ImageNet-1k基准上超越OFA，且参数开销远小于OFA。

Conclusion: 本文提出了一种简单的跨架构知识蒸馏方法，通过减少冗余信息来提升知识传递的效率。

Abstract: We describe a simple method for cross-architecture knowledge distillation,
where the knowledge transfer is cast into a redundant information suppression
formulation. Existing methods introduce sophisticated modules,
architecture-tailored designs, and excessive parameters, which impair their
efficiency and applicability. We propose to extract the architecture-agnostic
knowledge in heterogeneous representations by reducing the redundant
architecture-exclusive information. To this end, we present a simple redundancy
suppression distillation (RSD) loss, which comprises cross-architecture
invariance maximisation and feature decorrelation objectives. To prevent the
student from entirely losing its architecture-specific capabilities, we further
design a lightweight module that decouples the RSD objective from the student's
internal representations. Our method is devoid of the architecture-specific
designs and complex operations in the pioneering method of OFA. It outperforms
OFA on CIFAR-100 and ImageNet-1k benchmarks with only a fraction of their
parameter overhead, which highlights its potential as a simple and strong
baseline to the cross-architecture distillation community.

</details>


### [61] [Unleashing the Power of Motion and Depth: A Selective Fusion Strategy for RGB-D Video Salient Object Detection](https://arxiv.org/abs/2507.21857)
*Jiahao He,Daerji Suolang,Keren Fu,Qijun Zhao*

Main category: cs.CV

TL;DR: SMFNet通过创新的选择性交叉模态融合策略显著改善了RGB-D视频的显著目标检测性能，优于多种现有最先进方法。


<details>
  <summary>Details</summary>
Motivation: 现有的RGB-D VSOD模型在利用光流和深度信息时，未能充分考虑这两者在不同场景中的不平等贡献，限制了模型的潜力。

Method: 提出了一种新的选择性交叉模态融合框架(SMFNet)，包括像素级选择性融合策略（PSF）和多维选择性注意模块（MSAM）。

Result: SMFNet在RDVS和DVisal等数据集上显著优于其他19种最先进模型。其评测是迄今为止最全面的RGB-D VSOD基准。

Conclusion: SMFNet可以有效利用光流和深度信息对RGB做出改进，实现更好的RGB-D显著目标检测效果。

Abstract: Applying salient object detection (SOD) to RGB-D videos is an emerging task
called RGB-D VSOD and has recently gained increasing interest, due to
considerable performance gains of incorporating motion and depth and that RGB-D
videos can be easily captured now in daily life. Existing RGB-D VSOD models
have different attempts to derive motion cues, in which extracting motion
information explicitly from optical flow appears to be a more effective and
promising alternative. Despite this, there remains a key issue that how to
effectively utilize optical flow and depth to assist the RGB modality in SOD.
Previous methods always treat optical flow and depth equally with respect to
model designs, without explicitly considering their unequal contributions in
individual scenarios, limiting the potential of motion and depth. To address
this issue and unleash the power of motion and depth, we propose a novel
selective cross-modal fusion framework (SMFNet) for RGB-D VSOD, incorporating a
pixel-level selective fusion strategy (PSF) that achieves optimal fusion of
optical flow and depth based on their actual contributions. Besides, we propose
a multi-dimensional selective attention module (MSAM) to integrate the fused
features derived from PSF with the remaining RGB modality at multiple
dimensions, effectively enhancing feature representation to generate refined
features. We conduct comprehensive evaluation of SMFNet against 19
state-of-the-art models on both RDVS and DVisal datasets, making the evaluation
the most comprehensive RGB-D VSOD benchmark up to date, and it also
demonstrates the superiority of SMFNet over other models. Meanwhile, evaluation
on five video benchmark datasets incorporating synthetic depth validates the
efficacy of SMFNet as well. Our code and benchmark results are made publicly
available at https://github.com/Jia-hao999/SMFNet.

</details>


### [62] [Low-Cost Test-Time Adaptation for Robust Video Editing](https://arxiv.org/abs/2507.21858)
*Jianhui Wang,Yinda Chen,Yangfan He,Xinyuan Song,Yi Xin,Dapeng Zhang,Zhongwei Wan,Bin Li,Rongchao Zhang*

Main category: cs.CV

TL;DR: Vid-TTA是一种轻量框架，改善视频编辑中的时序一致性和提示过拟合，适用于现有模型，计算开销低。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法面临时序一致性和过拟合问题，限制了编辑质量和模型泛化能力。

Method: 提出Vid-TTA框架，通过自监督辅助任务优化测试视频，使用运动感知帧重构机制和提示扰动策略，并通过元学习动态调节损失平衡机制。

Result: Vid-TTA显著改善了视频时序一致性和减轻了提示过拟合，同时保持低计算开销。

Conclusion: Vid-TTA为现有视频编辑模型提供了一种轻量的即插即用性能提升方案。

Abstract: Video editing is a critical component of content creation that transforms raw
footage into coherent works aligned with specific visual and narrative
objectives. Existing approaches face two major challenges: temporal
inconsistencies due to failure in capturing complex motion patterns, and
overfitting to simple prompts arising from limitations in UNet backbone
architectures. While learning-based methods can enhance editing quality, they
typically demand substantial computational resources and are constrained by the
scarcity of high-quality annotated data. In this paper, we present Vid-TTA, a
lightweight test-time adaptation framework that personalizes optimization for
each test video during inference through self-supervised auxiliary tasks. Our
approach incorporates a motion-aware frame reconstruction mechanism that
identifies and preserves crucial movement regions, alongside a prompt
perturbation and reconstruction strategy that strengthens model robustness to
diverse textual descriptions. These innovations are orchestrated by a
meta-learning driven dynamic loss balancing mechanism that adaptively adjusts
the optimization process based on video characteristics. Extensive experiments
demonstrate that Vid-TTA significantly improves video temporal consistency and
mitigates prompt overfitting while maintaining low computational overhead,
offering a plug-and-play performance boost for existing video editing models.

</details>


### [63] [CAPE: A CLIP-Aware Pointing Ensemble of Complementary Heatmap Cues for Embodied Reference Understanding](https://arxiv.org/abs/2507.21888)
*Fevziye Irem Eyiokur,Dogucan Yaman,Hazım Kemal Ekenel,Alexander Waibel*

Main category: cs.CV

TL;DR: 研究提出双模型框架和混合集成方法，以提高通过指点和语言理解场景中的对象识别的准确性，并在YouRefIt数据集上表现提升约4 mAP。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效利用视觉线索进行指代消歧，因此需要改进点指线的理解和模型组合。

Method: 提出了双模型框架，其中一个模型从头到指尖方向学习，另一个从手腕到指尖方向学习，并引入高斯射线热图表示来提高模型对点指线的关注度。同时，提出CLIP-Aware Pointing Ensemble模块，通过CLIP特征进行混合集成，并增加对象中心预测作为辅助任务。

Result: 在YouRefIt数据集上验证了该方法，在0.25 IoU阈值下实现了约4 mAP的性能提升。

Conclusion: 通过提出新的双模型框架和混合集成方法，改善了视觉线索的利用，提升了指代对象识别的准确性。

Abstract: We address the problem of Embodied Reference Understanding, which involves
predicting the object that a person in the scene is referring to through both
pointing gesture and language. Accurately identifying the referent requires
multimodal understanding: integrating textual instructions, visual pointing,
and scene context. However, existing methods often struggle to effectively
leverage visual clues for disambiguation. We also observe that, while the
referent is often aligned with the head-to-fingertip line, it occasionally
aligns more closely with the wrist-to-fingertip line. Therefore, relying on a
single line assumption can be overly simplistic and may lead to suboptimal
performance. To address this, we propose a dual-model framework, where one
model learns from the head-to-fingertip direction and the other from the
wrist-to-fingertip direction. We further introduce a Gaussian ray heatmap
representation of these lines and use them as input to provide a strong
supervisory signal that encourages the model to better attend to pointing cues.
To combine the strengths of both models, we present the CLIP-Aware Pointing
Ensemble module, which performs a hybrid ensemble based on CLIP features.
Additionally, we propose an object center prediction head as an auxiliary task
to further enhance referent localization. We validate our approach through
extensive experiments and analysis on the benchmark YouRefIt dataset, achieving
an improvement of approximately 4 mAP at the 0.25 IoU threshold.

</details>


### [64] [Aether Weaver: Multimodal Affective Narrative Co-Generation with Dynamic Scene Graphs](https://arxiv.org/abs/2507.21893)
*Saeed Ghorbani*

Main category: cs.CV

TL;DR: Aether Weaver通过同步生成文本、视觉和音景等多模态元素，提供了一个有力的平台，提高了叙事深度和情感表现。


<details>
  <summary>Details</summary>
Motivation: 为了克服顺序文本到视觉管道的限制，提出了一个新颖的综合框架，用于多模态叙事共同生成。

Method: 通过大型语言模型生成叙述文本和多模态提示，同时使用动态场景图管理器分析文本构建和维护故事世界的结构化表示式。

Result: 通过定性评估，我们证明Aether Weaver在各种叙事提示中增强了叙事深度、视觉保真度和情感共鸣。

Conclusion: Aether Weaver通过同时合成文本叙述、动态场景图表示、视觉场景和情感音景，显著增强了叙事深度、视觉保真度和情感共鸣。

Abstract: We introduce Aether Weaver, a novel, integrated framework for multimodal
narrative co-generation that overcomes limitations of sequential text-to-visual
pipelines. Our system concurrently synthesizes textual narratives, dynamic
scene graph representations, visual scenes, and affective soundscapes, driven
by a tightly integrated, co-generation mechanism. At its core, the Narrator, a
large language model, generates narrative text and multimodal prompts, while
the Director acts as a dynamic scene graph manager, and analyzes the text to
build and maintain a structured representation of the story's world, ensuring
spatio-temporal and relational consistency for visual rendering and subsequent
narrative generation. Additionally, a Narrative Arc Controller guides the
high-level story structure, influencing multimodal affective consistency,
further complemented by an Affective Tone Mapper that ensures congruent
emotional expression across all modalities. Through qualitative evaluations on
a diverse set of narrative prompts encompassing various genres, we demonstrate
that Aether Weaver significantly enhances narrative depth, visual fidelity, and
emotional resonance compared to cascaded baseline approaches. This integrated
framework provides a robust platform for rapid creative prototyping and
immersive storytelling experiences.

</details>


### [65] [Evaluating Deepfake Detectors in the Wild](https://arxiv.org/abs/2507.21905)
*Viacheslav Pirogov,Maksim Artemev*

Main category: cs.CV

TL;DR: 该研究评估了现代深度伪造检测器的有效性，通过模拟真实世界场景进行测试，并揭示了检测深度伪造的困难。测试表明简单的图像操作可能会显著降低检测器性能。


<details>
  <summary>Details</summary>
Motivation: 深度伪造技术对身份验证和数字媒体的真实性构成严重且不断演变的威胁，因此需要有效的检测器来应对这一挑战。

Method: 在研究中引入了一种新颖的测试程序，旨在模拟现实世界中的深度伪造检测场景。测试使用先进的深度伪造生成方法，建立了包含超过50万张高质量深度伪造图片的数据集进行评估。

Result: 检测深度伪造仍然是一个具有挑战性的任务。测试结果显示，少于半数的检测器的AUC评分超过60%，而最低得分为50%。同时，基本的图像操作如JPEG压缩或图像增强会显著降低模型性能。

Conclusion: 尽管开发了许多深度伪造检测器，但它们在实际数据中的有效性仍有待验证。该研究展示了当前检测器在模拟真实场景时的表现及其面临的挑战。

Abstract: Deepfakes powered by advanced machine learning models present a significant
and evolving threat to identity verification and the authenticity of digital
media. Although numerous detectors have been developed to address this problem,
their effectiveness has yet to be tested when applied to real-world data. In
this work we evaluate modern deepfake detectors, introducing a novel testing
procedure designed to mimic real-world scenarios for deepfake detection. Using
state-of-the-art deepfake generation methods, we create a comprehensive dataset
containing more than 500,000 high-quality deepfake images. Our analysis shows
that detecting deepfakes still remains a challenging task. The evaluation shows
that in fewer than half of the deepfake detectors tested achieved an AUC score
greater than 60%, with the lowest being 50%. We demonstrate that basic image
manipulations, such as JPEG compression or image enhancement, can significantly
reduce model performance. All code and data are publicly available at
https://github.com/messlav/Deepfake-Detectors-in-the-Wild.

</details>


### [66] [MetaCLIP 2: A Worldwide Scaling Recipe](https://arxiv.org/abs/2507.22062)
*Yung-Sung Chuang,Yang Li,Dong Wang,Ching-Feng Yeh,Kehan Lyu,Ramya Raghavendra,James Glass,Lifei Huang,Jason Weston,Luke Zettlemoyer,Xinlei Chen,Zhuang Liu,Saining Xie,Wen-tau Yih,Shang-Wen Li,Hu Xu*

Main category: cs.CV

TL;DR: MetaCLIP 2 overcomes multilingual limitations, enhancing CLIP by training on global data, achieving superior performance in multilingual benchmarks.


<details>
  <summary>Details</summary>
Motivation: To address challenges of scaling CLIP training to worldwide data and overcoming performance degradation in multilingual models.

Method: MetaCLIP 2, a recipe training CLIP from scratch using global web-scale image-text pairs with rigorous ablations.

Result: MetaCLIP 2 achieves state-of-the-art zero-shot classification and sets new benchmarks in multilingual tasks, surpassing English-only models.

Conclusion: MetaCLIP 2 successfully improves performance by integrating worldwide data without system-level confounding factors.

Abstract: Contrastive Language-Image Pretraining (CLIP) is a popular foundation model,
supporting from zero-shot classification, retrieval to encoders for multimodal
large language models (MLLMs). Although CLIP is successfully trained on
billion-scale image-text pairs from the English world, scaling CLIP's training
further to learning from the worldwide web data is still challenging: (1) no
curation method is available to handle data points from non-English world; (2)
the English performance from existing multilingual CLIP is worse than its
English-only counterpart, i.e., "curse of multilinguality" that is common in
LLMs. Here, we present MetaCLIP 2, the first recipe training CLIP from scratch
on worldwide web-scale image-text pairs. To generalize our findings, we conduct
rigorous ablations with minimal changes that are necessary to address the above
challenges and present a recipe enabling mutual benefits from English and
non-English world data. In zero-shot ImageNet classification, MetaCLIP 2
ViT-H/14 surpasses its English-only counterpart by 0.8% and mSigLIP by 0.7%,
and surprisingly sets new state-of-the-art without system-level confounding
factors (e.g., translation, bespoke architecture changes) on multilingual
benchmarks, such as CVQA with 57.4%, Babel-ImageNet with 50.2% and XM3600 with
64.3% on image-to-text retrieval.

</details>


### [67] [Predict Patient Self-reported Race from Skin Histological Images](https://arxiv.org/abs/2507.21912)
*Shengjia Chen,Ruchika Verma,Kevin Clare,Jannes Jegminat,Kuan-lin Huang,Brandon Veremis,Thomas Fuchs,Gabriele Campanella*

Main category: cs.CV

TL;DR: 研究探讨AI在病理学中的种族偏倚问题，发现模型可通过皮肤病理切片预测种族，强调数据管理和偏倚缓解的重要性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨AI在病理学中的潜在种族偏倚问题，以确保其公平性和有效性。

Method: 本研究使用关注机制来揭示与种族相关的形态特征，并评估三种数据集策划策略以控制混杂因素。

Result: 最终实验显示，虽然整体性能有所下降（AUC: 0.663），但白人和黑人群体的预测性能保持较高水平（AUC: 0.799, 0.762），重申表皮是一个关键预测特征。

Conclusion: 研究表明，深度学习模型可以通过数字化皮肤病理学切片预测自述种族，并指出AI在病理学中的公平部署需要进行谨慎的数据管理和偏倚缓解。

Abstract: Artificial Intelligence (AI) has demonstrated success in computational
pathology (CPath) for disease detection, biomarker classification, and
prognosis prediction. However, its potential to learn unintended demographic
biases, particularly those related to social determinants of health, remains
understudied. This study investigates whether deep learning models can predict
self-reported race from digitized dermatopathology slides and identifies
potential morphological shortcuts. Using a multisite dataset with a racially
diverse population, we apply an attention-based mechanism to uncover
race-associated morphological features. After evaluating three dataset curation
strategies to control for confounding factors, the final experiment showed that
White and Black demographic groups retained high prediction performance (AUC:
0.799, 0.762), while overall performance dropped to 0.663. Attention analysis
revealed the epidermis as a key predictive feature, with significant
performance declines when these regions were removed. These findings highlight
the need for careful data curation and bias mitigation to ensure equitable AI
deployment in pathology. Code available at:
https://github.com/sinai-computational-pathology/CPath_SAIF.

</details>


### [68] [ArtSeek: Deep artwork understanding via multimodal in-context reasoning and late interaction retrieval](https://arxiv.org/abs/2507.21917)
*Nicola Fanelli,Gennaro Vessio,Giovanna Castellano*

Main category: cs.CV

TL;DR: ArtSeek是一种多模态框架，可在多个测试中实现最新结果，推动可扩展的多模态AI研究。


<details>
  <summary>Details</summary>
Motivation: 分析数字化艺术作品需要视觉解释以及丰富的艺术、背景和历史知识。

Method: 引入ArtSeek，结合多模态大型语言模型与检索增强生成，依赖图像输入进行艺术分析。

Result: 在多个基准测试中取得最先进的结果，包括风格分类提高8.4% F1分数，ArtPedia上字幕提高7.1 BLEU@1。

Conclusion: ArtSeek可以解释视觉主题，推断历史背景，检索相关知识，支持可扩展的多模态AI研究，并且数据集和源码将公开。

Abstract: Analyzing digitized artworks presents unique challenges, requiring not only
visual interpretation but also a deep understanding of rich artistic,
contextual, and historical knowledge. We introduce ArtSeek, a multimodal
framework for art analysis that combines multimodal large language models with
retrieval-augmented generation. Unlike prior work, our pipeline relies only on
image input, enabling applicability to artworks without links to Wikidata or
Wikipedia-common in most digitized collections. ArtSeek integrates three key
components: an intelligent multimodal retrieval module based on late
interaction retrieval, a contrastive multitask classification network for
predicting artist, genre, style, media, and tags, and an agentic reasoning
strategy enabled through in-context examples for complex visual question
answering and artwork explanation via Qwen2.5-VL. Central to this approach is
WikiFragments, a Wikipedia-scale dataset of image-text fragments curated to
support knowledge-grounded multimodal reasoning. Our framework achieves
state-of-the-art results on multiple benchmarks, including a +8.4% F1
improvement in style classification over GraphCLIP and a +7.1 BLEU@1 gain in
captioning on ArtPedia. Qualitative analyses show that ArtSeek can interpret
visual motifs, infer historical context, and retrieve relevant knowledge, even
for obscure works. Though focused on visual arts, our approach generalizes to
other domains requiring external knowledge, supporting scalable multimodal AI
research. Both the dataset and the source code will be made publicly available
at https://github.com/cilabuniba/artseek.

</details>


### [69] [SwinECAT: A Transformer-based fundus disease classification model with Shifted Window Attention and Efficient Channel Attention](https://arxiv.org/abs/2507.21922)
*Peiran Gu,Teng Yao,Mengshen He,Fuhao Duan,Feiyan Liu,RenYuan Peng,Bao Ge*

Main category: cs.CV

TL;DR: 本文提出SwinECAT模型，通过创新的注意力机制提升眼底图像9分类任务的性能，获得88.29%准确率，优于基础模型。


<details>
  <summary>Details</summary>
Motivation: 由于某些眼底疾病中病变区域较小及疾病间细微差异，导致模型预测准确性降低及过拟合问题，因此需要一种创新方法来提升模型表现。

Method: 本文提出了一种基于Transformer的模型SwinECAT，该模型结合了Shifted Window注意力机制与Efficient Channel Attention机制。通过这些机制，该模型能够有效捕捉眼底图像中的局部空间结构及长距离依赖关系。

Result: SwinECAT在眼病图像数据集（EDID）上的9分类任务中达到88.29%的准确率，且加权F1分数为0.88，宏观F1分数为0.90。该模型的分类性能显著优于基础Swin Transformer及多个对比模型。

Conclusion: SwinECAT在细粒度的眼底疾病分类任务中表现优异，并且在已知的公共数据集上实现了最高的9分类报告性能。

Abstract: In recent years, artificial intelligence has been increasingly applied in the
field of medical imaging. Among these applications, fundus image analysis
presents special challenges, including small lesion areas in certain fundus
diseases and subtle inter-disease differences, which can lead to reduced
prediction accuracy and overfitting in the models. To address these challenges,
this paper proposes the Transformer-based model SwinECAT, which combines the
Shifted Window (Swin) Attention with the Efficient Channel Attention (ECA)
Attention. SwinECAT leverages the Swin Attention mechanism in the Swin
Transformer backbone to effectively capture local spatial structures and
long-range dependencies within fundus images. The lightweight ECA mechanism is
incorporated to guide the SwinECAT's attention toward critical feature
channels, enabling more discriminative feature representation. In contrast to
previous studies that typically classify fundus images into 4 to 6 categories,
this work expands fundus disease classification to 9 distinct types, thereby
enhancing the granularity of diagnosis. We evaluate our method on the Eye
Disease Image Dataset (EDID) containing 16,140 fundus images for 9-category
classification. Experimental results demonstrate that SwinECAT achieves 88.29\%
accuracy, with weighted F1-score of 0.88 and macro F1-score of 0.90. The
classification results of our proposed model SwinECAT significantly outperform
the baseline Swin Transformer and multiple compared baseline models. To our
knowledge, this represents the highest reported performance for 9-category
classification on this public dataset.

</details>


### [70] [MMAT-1M: A Large Reasoning Dataset for Multimodal Agent Tuning](https://arxiv.org/abs/2507.21924)
*Tianhong Gao,Yannian Fu,Weiqun Wu,Haixiao Yue,Shanshan Liu,Gang Zhang*

Main category: cs.CV

TL;DR: MMAT-1M 是首个支持多模态长链推理、反思和动态工具使用的百万级代理调优数据集，显著提升了多模态模型的性能。


<details>
  <summary>Details</summary>
Motivation: 目前多模态领域缺乏大规模、高质量的代理调优数据集来释放多模态大型语言模型的潜力。

Method: 为了构建 MMAT-1M 数据集，研究者首先收集公开的多模态数据集，包括问答对，然后利用 GPT-4o 生成这些对的推理，并通过多轮方法动态整合 API 调用和 RAG 信息。接着，通过反思精炼推理，确保逻辑一致性和准确性，形成包含推理和反思的多轮对话数据集。最后，研究者将多轮对话可选地压缩为单轮格式以提高效率。

Result: 通过对开源多模态模型在 MMAT-1M 数据集上的微调，实验证明显著的性能提升。例如，InternVL2.5-8B-RR 模型在八个公共基准上平均提高了 2.7%，在 RAG 基准测试 Dyn-VQA 上提高了 8.8%。

Conclusion: MMAT-1M 数据集通过增强多模态大型语言模型的推理和工具使用能力，提高了其整体性能。

Abstract: Large Language Models (LLMs), enhanced through agent tuning, have
demonstrated remarkable capabilities in Chain-of-Thought (CoT) and tool
utilization, significantly surpassing the performance of standalone models.
However, the multimodal domain still lacks a large-scale, high-quality agent
tuning dataset to unlock the full potential of multimodal large language
models. To bridge this gap, we introduce MMAT-1M, the first million-scale
multimodal agent tuning dataset designed to support CoT, reflection, and
dynamic tool usage. Our dataset is constructed through a novel four-stage data
engine: 1) We first curate publicly available multimodal datasets containing
question-answer pairs; 2) Then, leveraging GPT-4o, we generate rationales for
the original question-answer pairs and dynamically integrate API calls and
Retrieval Augmented Generation (RAG) information through a multi-turn paradigm;
3) Furthermore, we refine the rationales through reflection to ensure logical
consistency and accuracy, creating a multi-turn dialogue dataset with both
Rationale and Reflection (RR); 4) Finally, to enhance efficiency, we optionally
compress multi-turn dialogues into a One-turn Rationale and Reflection (ORR)
format. By fine-tuning open-source multimodal models on the MMAT-1M, we observe
significant performance gains. For instance, the InternVL2.5-8B-RR model
achieves an average improvement of 2.7% across eight public benchmarks and 8.8%
on the RAG benchmark Dyn-VQA, demonstrating the dataset's effectiveness in
enhancing multimodal reasoning and tool-based capabilities. The dataset is
publicly available at https://github.com/VIS-MPU-Agent/MMAT-1M.

</details>


### [71] [Attention-Driven Multimodal Alignment for Long-term Action Quality Assessment](https://arxiv.org/abs/2507.21945)
*Xin Wang,Peng-Jie Li,Yuan-Yuan Shen*

Main category: cs.CV

TL;DR: LMAC-Net通过多模态注意力一致性机制实现视觉和音频信息的稳定集成，提高了动作质量评估的精度，实验结果优于其他方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在长时动作质量评估任务中不能有效捕捉模态间的复杂交互和全局序列中关键性能变化的问题。

Method: 引入多模态注意力一致性机制，通过多模态局部查询编码模块捕获时间语义和跨模态关系，并采用两级评分评价与注意力和回归损失共同优化多模态对齐和评分融合。

Result: 在RG和Fis-V数据集上的实验表明，LMAC-Net显著优于现有方法。

Conclusion: LMAC-Net显著优于现有方法，验证了所提出方法的有效性。

Abstract: Long-term action quality assessment (AQA) focuses on evaluating the quality
of human activities in videos lasting up to several minutes. This task plays an
important role in the automated evaluation of artistic sports such as rhythmic
gymnastics and figure skating, where both accurate motion execution and
temporal synchronization with background music are essential for performance
assessment. However, existing methods predominantly fall into two categories:
unimodal approaches that rely solely on visual features, which are inadequate
for modeling multimodal cues like music; and multimodal approaches that
typically employ simple feature-level contrastive fusion, overlooking deep
cross-modal collaboration and temporal dynamics. As a result, they struggle to
capture complex interactions between modalities and fail to accurately track
critical performance changes throughout extended sequences. To address these
challenges, we propose the Long-term Multimodal Attention Consistency Network
(LMAC-Net). LMAC-Net introduces a multimodal attention consistency mechanism to
explicitly align multimodal features, enabling stable integration of visual and
audio information and enhancing feature representations. Specifically, we
introduce a multimodal local query encoder module to capture temporal semantics
and cross-modal relations, and use a two-level score evaluation for
interpretable results. In addition, attention-based and regression-based losses
are applied to jointly optimize multimodal alignment and score fusion.
Experiments conducted on the RG and Fis-V datasets demonstrate that LMAC-Net
significantly outperforms existing methods, validating the effectiveness of our
proposed approach.

</details>


### [72] [Enhancing Generalization in Data-free Quantization via Mixup-class Prompting](https://arxiv.org/abs/2507.21947)
*Jiwoong Park,Chaeun Lee,Yongseok Choi,Sein Park,Deokki Hong,Jungwook Choi*

Main category: cs.CV

TL;DR: 提出了混合式类提示生成合成数据的方法，提升了无训练量化模型的泛化能力和优化稳定性，并在低比特量化中实现了新的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 无训练量化 (PTQ) 在隐私约束下难以处理有限的校准数据。

Method: 通过使用生成对抗网络 (GANs) 和文本条件潜在扩散模型 (LDMs) 生成合成图像，并应用现有的 PTQ 算法，提出了一种混合式文本提示策略。

Result: 得到的合成数据增强了模型的泛化能力并提升了优化稳定性。实验表明该方法在极低比特场景下提高了性能，在2-bit权重、4-bit激活量化中达到新的最先进准确性。

Conclusion: 提出的混合式类提示策略在无训练量化领域中表现优异，有效提升了模型的泛化和优化稳定性。

Abstract: Post-training quantization (PTQ) improves efficiency but struggles with
limited calibration data, especially under privacy constraints. Data-free
quantization (DFQ) mitigates this by generating synthetic images using
generative models such as generative adversarial networks (GANs) and
text-conditioned latent diffusion models (LDMs), while applying existing PTQ
algorithms. However, the relationship between generated synthetic images and
the generalizability of the quantized model during PTQ remains underexplored.
Without investigating this relationship, synthetic images generated by previous
prompt engineering methods based on single-class prompts suffer from issues
such as polysemy, leading to performance degradation. We propose
\textbf{mixup-class prompt}, a mixup-based text prompting strategy that fuses
multiple class labels at the text prompt level to generate diverse, robust
synthetic data. This approach enhances generalization, and improves
optimization stability in PTQ. We provide quantitative insights through
gradient norm and generalization error analysis. Experiments on convolutional
neural networks (CNNs) and vision transformers (ViTs) show that our method
consistently outperforms state-of-the-art DFQ methods like GenQ. Furthermore,
it pushes the performance boundary in extremely low-bit scenarios, achieving
new state-of-the-art accuracy in challenging 2-bit weight, 4-bit activation
(W2A4) quantization.

</details>


### [73] [Contrast-Prior Enhanced Duality for Mask-Free Shadow Removal](https://arxiv.org/abs/2507.21949)
*Jiyu Wu,Yifan Liu,Jiancheng Huang,Mingfu Yan,Shifeng Chen*

Main category: cs.CV

TL;DR: 提出了一种无需shadow masks的阴影去除方法，能够使用内在图像线索进行高效处理，并获得了最先进的效果。


<details>
  <summary>Details</summary>
Motivation: 现有去除阴影的方法依赖于难以获取的阴影mask，因此探索内在图像线索如局部对比度信息是替代方案。但在复杂场景中，该方法难以区分真实阴影与低反射率物体及复杂背景纹理。

Method: 提出了自适应门控双分支注意机制（AGBA），以及扩散频率-对比度融合网络（FCFN），利用高频和对比度线索引导生成过程。

Result: 提出的方法在无mask方案中取得了最先进的结果，并且相对于使用mask的方法而言仍然保持了有竞争力的性能。

Conclusion: 我们的研究提出的方案在无mask的情况下，依然可以优秀地去除阴影，并能在保持与使用mask的方案相当的性能下取得突破性进展。

Abstract: Existing shadow removal methods often rely on shadow masks, which are
challenging to acquire in real-world scenarios. Exploring intrinsic image cues,
such as local contrast information, presents a potential alternative for
guiding shadow removal in the absence of explicit masks. However, the cue's
inherent ambiguity becomes a critical limitation in complex scenes, where it
can fail to distinguish true shadows from low-reflectance objects and intricate
background textures. To address this motivation, we propose the Adaptive Gated
Dual-Branch Attention (AGBA) mechanism. AGBA dynamically filters and re-weighs
the contrast prior to effectively disentangle shadow features from confounding
visual elements. Furthermore, to tackle the persistent challenge of restoring
soft shadow boundaries and fine-grained details, we introduce a diffusion-based
Frequency-Contrast Fusion Network (FCFN) that leverages high-frequency and
contrast cues to guide the generative process. Extensive experiments
demonstrate that our method achieves state-of-the-art results among mask-free
approaches while maintaining competitive performance relative to mask-based
methods.

</details>


### [74] [Mitigating Spurious Correlations in Weakly Supervised Semantic Segmentation via Cross-architecture Consistency Regularization](https://arxiv.org/abs/2507.21959)
*Zheyuan Zhang,Yen-chia Hsu*

Main category: cs.CV

TL;DR: 本文提出了一种新的弱监督语义分割框架，通过教师-学生结构结合CNN和ViT，解决了共现问题，无需依赖外部监督，提高了伪掩码质量。


<details>
  <summary>Details</summary>
Motivation: 获取像素级标签在实践中具有挑战性，尤其是在需要专家知识的领域，如工业烟的标注。弱监督语义分割（WSSS）被视为解决此问题的有效方法。然而，由于监督不足和模型固有偏差，现有的方法通常面临诸如前景覆盖不完整、对象边界不准确和虚假相关的问题。针对这些挑战，本文提出了一种新的WSSS框架。

Method: 本文采用一个教师-学生框架，结合卷积神经网络（CNNs）和视觉变换器（ViTs）。通过引入知识转移损失来实现跨架构一致性，并采用后处理技术以改善伪掩码质量。

Result: 通过提出的新框架，直接针对共现问题进行解决，无需依赖外部监督，并显著改善了语义分割的质量。

Conclusion: 通过本文提出的方法，有效解决模型固有的偏差和共现问题，为工业烟等领域的分割提供了更可靠的解决方案。

Abstract: Scarcity of pixel-level labels is a significant challenge in practical
scenarios. In specific domains like industrial smoke, acquiring such detailed
annotations is particularly difficult and often requires expert knowledge. To
alleviate this, weakly supervised semantic segmentation (WSSS) has emerged as a
promising approach. However, due to the supervision gap and inherent bias in
models trained with only image level labels, existing WSSS methods suffer from
limitations such as incomplete foreground coverage, inaccurate object
boundaries, and spurious correlations, especially in our domain, where
emissions are always spatially coupled with chimneys.
  Previous solutions typically rely on additional priors or external knowledge
to mitigate these issues, but they often lack scalability and fail to address
the model's inherent bias toward co-occurring context. To address this, we
propose a novel WSSS framework that directly targets the co-occurrence problem
without relying on external supervision. Unlike prior methods that adopt a
single network, we employ a teacher-student framework that combines CNNs and
ViTs. We introduce a knowledge transfer loss that enforces cross-architecture
consistency by aligning internal representations. Additionally, we incorporate
post-processing techniques to address partial coverage and further improve
pseudo mask quality.

</details>


### [75] [PanoSplatt3R: Leveraging Perspective Pretraining for Generalized Unposed Wide-Baseline Panorama Reconstruction](https://arxiv.org/abs/2507.21960)
*Jiahui Ren,Mochu Xiang,Jiajun Zhu,Yuchao Dai*

Main category: cs.CV

TL;DR: 提出PanoSplatt3R，不依赖准确姿态信息的宽基线全景重建方法，能够生成高质量视图并提供深度估计，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有宽基线全景重建方法依赖于准确的姿态信息，但在实际环境中，获取准确的姿态信息需要额外的计算资源，且容易受到噪声影响，限制了这些方法的广泛应用和实用性。

Method: 提出了一种新方法PanoSplatt3R，该方法不依赖姿态信息来进行宽基线全景重建。通过扩展和改进基础重建预训练，将其从视角域转换至全景域，并采用RoPE滚动技术，跨越不同注意力头来对旋转位置嵌入进行卷轴坐标处理，在建模全景图像水平周期性时，尽量减少对RoPE机制的修改。

Result: 实验表明，即使在没有姿态信息的情况下，PanoSplatt3R仍显著优于当前的现有最先进方法，无论在高质量的新视图生成还是深度估计的准确性方面都表现突出。

Conclusion: PanoSplatt3R展示了其在实际应用方面的巨大潜力，在生成高质量新视图以及估计深度准确性上优于目前的先进方法。

Abstract: Wide-baseline panorama reconstruction has emerged as a highly effective and
pivotal approach for not only achieving geometric reconstruction of the
surrounding 3D environment, but also generating highly realistic and immersive
novel views. Although existing methods have shown remarkable performance across
various benchmarks, they are predominantly reliant on accurate pose
information. In real-world scenarios, the acquisition of precise pose often
requires additional computational resources and is highly susceptible to noise.
These limitations hinder the broad applicability and practicality of such
methods. In this paper, we present PanoSplatt3R, an unposed wide-baseline
panorama reconstruction method. We extend and adapt the foundational
reconstruction pretrainings from the perspective domain to the panoramic
domain, thus enabling powerful generalization capabilities. To ensure a
seamless and efficient domain-transfer process, we introduce RoPE rolling that
spans rolled coordinates in rotary positional embeddings across different
attention heads, maintaining a minimal modification to RoPE's mechanism, while
modeling the horizontal periodicity of panorama images. Comprehensive
experiments demonstrate that PanoSplatt3R, even in the absence of pose
information, significantly outperforms current state-of-the-art methods. This
superiority is evident in both the generation of high-quality novel views and
the accuracy of depth estimation, thereby showcasing its great potential for
practical applications. Project page: https://npucvr.github.io/PanoSplatt3R

</details>


### [76] [A Deep Learning Pipeline Using Synthetic Data to Improve Interpretation of Paper ECG Images](https://arxiv.org/abs/2507.21968)
*Xiaoyu Wang,Ramesh Nadarajah,Zhiqiang Zhang,David Wong*

Main category: cs.CV

TL;DR: 研究开发了一个深度学习框架，用于分类纸质心电图图像，取得了优异的AUROC分数，被视为临床自动化心电图解释的有前途工具。


<details>
  <summary>Details</summary>
Motivation: 尽管历史上的研究集中于自动化数字信号心电图解释，临床实践中大部分心电图数据仍以图像形式存储或共享。为了弥合这一差距，研究者们希望开发能够自动识别图像形式心电图的工具。

Method: 提出了一种预处理流程以减少视觉噪音，并采用两阶段微调策略：首先在合成和外部ECG图像数据集上微调以学习领域特定特征，然后在目标数据集上进一步微调以增强疾病特异性识别。模型采用ConvNeXt架构作为基础。

Result: 该方法在2024年英国心脏基金会开放数据科学挑战赛中取得了获胜成绩，并在该挑战赛的公开验证集和私有测试集上分别获得了0.9688和0.9677的AUROC分数。

Conclusion: 该研究提出了一种深度学习框架，用于对纸质心电图图像进行分类，取得了高精度的结果，有望在临床工作流程中被用作自动化心电图解释工具。

Abstract: Cardiovascular diseases (CVDs) are the leading global cause of death, and
early detection is essential to improve patient outcomes. Electrocardiograms
(ECGs), especially 12-lead ECGs, play a key role in the identification of CVDs.
These are routinely interpreted by human experts, a process that is
time-consuming and requires expert knowledge. Historical research in this area
has focused on automatic ECG interpretation from digital signals, with recent
deep learning approaches achieving strong results. In practice, however, most
ECG data in clinical practice are stored or shared in image form. To bridge
this gap, we propose a deep learning framework designed specifically to
classify paper-like ECG images into five main diagnostic categories. Our method
was the winning entry to the 2024 British Heart Foundation Open Data Science
Challenge. It addresses two main challenges of paper ECG classification: visual
noise (e.g., shadows or creases) and the need to detect fine-detailed waveform
patterns. We propose a pre-processing pipeline that reduces visual noise and a
two-stage fine-tuning strategy: the model is first fine-tuned on synthetic and
external ECG image datasets to learn domain-specific features, and then further
fine-tuned on the target dataset to enhance disease-specific recognition. We
adopt the ConvNeXt architecture as the backbone of our model. Our method
achieved AUROC scores of 0.9688 on the public validation set and 0.9677 on the
private test set of the British Heart Foundation Open Data Science Challenge,
highlighting its potential as a practical tool for automated ECG interpretation
in clinical workflows.

</details>


### [77] [EIFNet: Leveraging Event-Image Fusion for Robust Semantic Segmentation](https://arxiv.org/abs/2507.21971)
*Zhijiang Li,Haoran He*

Main category: cs.CV

TL;DR: EIFNet是一种创新的多模态融合网络，通过新模块和注意力机制提高事件语义分割性能，在相关数据集上取得了领先的效果。


<details>
  <summary>Details</summary>
Motivation: 传统相机在动态范围和时间分辨率方面存在局限性，而事件相机可以提供高动态范围和精细的时间分辨率。为了在具有挑战性的环境中实现稳健的场景理解，本文探索如何使用事件相机进行语义分割。

Method: 提出了EIFNet，这是一种多模态融合网络，结合了事件和帧输入的优势。网络包含自适应事件特征优化模块，用于通过多尺度活动建模和空间注意力改善事件表征。此外，还引入了模态自适应重校准模块和多头注意力门控融合模块，通过注意力机制和门控融合策略实现跨模态特征对齐和整合。

Result: 在DDD17-Semantic和DSEC-Semantic数据集上的实验表明，EIFNet达到了最先进的性能，证明其在基于事件的语义分割中的有效性。

Conclusion: EIFNet通过创新的多模态融合机制，有效地解决了从稀疏且噪声大的事件流中提取可靠特征，以及与密集图像数据的结构和表示对齐和整合的问题，从而提升了事件语义分割的性能。

Abstract: Event-based semantic segmentation explores the potential of event cameras,
which offer high dynamic range and fine temporal resolution, to achieve robust
scene understanding in challenging environments. Despite these advantages, the
task remains difficult due to two main challenges: extracting reliable features
from sparse and noisy event streams, and effectively fusing them with dense,
semantically rich image data that differ in structure and representation. To
address these issues, we propose EIFNet, a multi-modal fusion network that
combines the strengths of both event and frame-based inputs. The network
includes an Adaptive Event Feature Refinement Module (AEFRM), which improves
event representations through multi-scale activity modeling and spatial
attention. In addition, we introduce a Modality-Adaptive Recalibration Module
(MARM) and a Multi-Head Attention Gated Fusion Module (MGFM), which align and
integrate features across modalities using attention mechanisms and gated
fusion strategies. Experiments on DDD17-Semantic and DSEC-Semantic datasets
show that EIFNet achieves state-of-the-art performance, demonstrating its
effectiveness in event-based semantic segmentation.

</details>


### [78] [Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition](https://arxiv.org/abs/2507.21977)
*Jihao Gu,Kun Li,Fei Wang,Yanyan Wei,Zhiliang Wu,Hehe Fan,Meng Wang*

Main category: cs.CV

TL;DR: 研究提出一种新网络，通过捕捉细微运动线索提高微动作识别性能，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有微动作识别方法常忽略微动作中的细微变化，导致识别准确度受限。

Method: 提出了一个新的运动引导调制网络(MMN)，通过运动引导骨骼调制模块(MSM)和运动引导时间调制模块(MTM)注入运动线索，增强空间和时间特征学习。

Result: 在Micro-Action 52和iMiGUE数据集上，MMN在骨骼微动作识别中表现出色，实现了最先进的性能。

Conclusion: 显式建立细微运动线索对提高微动作分类准确性至关重要。

Abstract: Micro-Actions (MAs) are an important form of non-verbal communication in
social interactions, with potential applications in human emotional analysis.
However, existing methods in Micro-Action Recognition often overlook the
inherent subtle changes in MAs, which limits the accuracy of distinguishing MAs
with subtle changes. To address this issue, we present a novel Motion-guided
Modulation Network (MMN) that implicitly captures and modulates subtle motion
cues to enhance spatial-temporal representation learning. Specifically, we
introduce a Motion-guided Skeletal Modulation module (MSM) to inject motion
cues at the skeletal level, acting as a control signal to guide spatial
representation modeling. In parallel, we design a Motion-guided Temporal
Modulation module (MTM) to incorporate motion information at the frame level,
facilitating the modeling of holistic motion patterns in micro-actions.
Finally, we propose a motion consistency learning strategy to aggregate the
motion cues from multi-scale features for micro-action classification.
Experimental results on the Micro-Action 52 and iMiGUE datasets demonstrate
that MMN achieves state-of-the-art performance in skeleton-based micro-action
recognition, underscoring the importance of explicitly modeling subtle motion
cues. The code will be available at https://github.com/momiji-bit/MMN.

</details>


### [79] [ZIUM: Zero-Shot Intent-Aware Adversarial Attack on Unlearned Models](https://arxiv.org/abs/2507.21985)
*Hyun Jun Yook,Ga San Jhun,Jae Hyun Cho,Min Jeon,Donghyun Kim,Tae Hyung Kim,Youn Kyu Lee*

Main category: cs.CV

TL;DR: ZIUM是一种针对遗忘模型的新型对抗性攻击方法，能够定制攻击内容并在不优化的情况下，实现快速且有效攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗性攻击方法在生成与攻击者意图一致的内容时面临挑战，并且识别成功的提示词需要高昂的计算成本。

Method: 提出了一种名为ZIUM的方法，它是一种针对遗忘模型的零次意图感知对抗性攻击，能够灵活定制目标攻击图像以反映攻击者的意图。

Result: ZIUM在多个机器遗忘场景中通过用户意图提示成功定制内容，攻击成功率优于现有方法。它的零次对抗攻击显著减少了对之前被攻击遗忘概念的攻击时间。

Conclusion: ZIUM能够灵活定制攻击内容，同时支持零次对抗攻击，在提升攻击成功率的同时降低了攻击时间。

Abstract: Machine unlearning (MU) removes specific data points or concepts from deep
learning models to enhance privacy and prevent sensitive content generation.
Adversarial prompts can exploit unlearned models to generate content containing
removed concepts, posing a significant security risk. However, existing
adversarial attack methods still face challenges in generating content that
aligns with an attacker's intent while incurring high computational costs to
identify successful prompts. To address these challenges, we propose ZIUM, a
Zero-shot Intent-aware adversarial attack on Unlearned Models, which enables
the flexible customization of target attack images to reflect an attacker's
intent. Additionally, ZIUM supports zero-shot adversarial attacks without
requiring further optimization for previously attacked unlearned concepts. The
evaluation across various MU scenarios demonstrated ZIUM's effectiveness in
successfully customizing content based on user-intent prompts while achieving a
superior attack success rate compared to existing methods. Moreover, its
zero-shot adversarial attack significantly reduces the attack time for
previously attacked unlearned concepts.

</details>


### [80] [Staining and locking computer vision models without retraining](https://arxiv.org/abs/2507.22000)
*Oliver J. Sutton,Qinghua Zhou,George Leete,Alexander N. Gorban,Ivan Y. Tyukin*

Main category: cs.CV

TL;DR: 本文介绍了一种新的技术，通过染色（水印）和锁定来保护计算机视觉模型的知识产权，具有可计算的保证和对模型性能影响极小。


<details>
  <summary>Details</summary>
Motivation: 传统的计算机视觉模型知识产权保护方法存在局限性，需要更高效的方法以提供可计算保证并在不影响模型性能的情况下保护知识产权。

Method: 通过直接修改模型中的少量权重，实施染色和锁定。染色嵌入秘密行为以识别模型，而锁定则通过在输入图像中插入秘密触发器来使模型不可用。无需微调或重新训练模型。

Result: 实验结果显示，该方法在多种计算机视觉模型上表现良好，具有实用性。

Conclusion: 本文提出了一种新的计算机视觉模型染色和锁定的方法，以保护模型所有者的知识产权。

Abstract: We introduce new methods of staining and locking computer vision models, to
protect their owners' intellectual property. Staining, also known as
watermarking, embeds secret behaviour into a model which can later be used to
identify it, while locking aims to make a model unusable unless a secret
trigger is inserted into input images. Unlike existing methods, our algorithms
can be used to stain and lock pre-trained models without requiring fine-tuning
or retraining, and come with provable, computable guarantees bounding their
worst-case false positive rates. The stain and lock are implemented by directly
modifying a small number of the model's weights and have minimal impact on the
(unlocked) model's performance. Locked models are unlocked by inserting a small
`trigger patch' into the corner of the input image. We present experimental
results showing the efficacy of our methods and demonstrating their practical
performance on a variety of computer vision models.

</details>


### [81] [Bridging Synthetic and Real-World Domains: A Human-in-the-Loop Weakly-Supervised Framework for Industrial Toxic Emission Segmentation](https://arxiv.org/abs/2507.22002)
*Yida Tao,Yen-Chia Hsu*

Main category: cs.CV

TL;DR: CEDANet是一种结合公民中文字幕和类特定域判别器的框架，在工业烟雾分割上显著提升了性能，验证了其在数据稀缺环境中的可扩展性和成本效益。


<details>
  <summary>Details</summary>
Motivation: 工业烟雾分割对空气质量监测和环境保护至关重要，但在真实世界环境中常因像素级标注的高成本和稀缺性而受到阻碍。本文提出了一种解决方案，以降低成本并提高效率。

Method: CEDANet结合弱监督的视频级标签与对抗性特征对齐，使用类特定域判别器将丰富的源域表示转移到工业域。

Result: CEDANet在SMOKE5K和自定义IJmond数据集上的实验中，达到了F1-score为0.414、IoU为0.261的性能，显著超过基线模型的0.083和0.043，实现了五倍的F1-score和六倍的IoU提升。

Conclusion: 通过将公民科学与弱监督域适应相结合，CEDANet框架实现了复杂的数据稀缺环境监测应用的规模化和成本效益。

Abstract: Industrial smoke segmentation is critical for air-quality monitoring and
environmental protection but is often hampered by the high cost and scarcity of
pixel-level annotations in real-world settings. We introduce CEDANet, a
human-in-the-loop, class-aware domain adaptation framework that uniquely
integrates weak, citizen-provided video-level labels with adversarial feature
alignment. Specifically, we refine pseudo-labels generated by a source-trained
segmentation model using citizen votes, and employ class-specific domain
discriminators to transfer rich source-domain representations to the industrial
domain. Comprehensive experiments on SMOKE5K and custom IJmond datasets
demonstrate that CEDANet achieves an F1-score of 0.414 and a smoke-class IoU of
0.261 with citizen feedback, vastly outperforming the baseline model, which
scored 0.083 and 0.043 respectively. This represents a five-fold increase in
F1-score and a six-fold increase in smoke-class IoU. Notably, CEDANet with
citizen-constrained pseudo-labels achieves performance comparable to the same
architecture trained on limited 100 fully annotated images with F1-score of
0.418 and IoU of 0.264, demonstrating its ability to reach small-sampled fully
supervised-level accuracy without target-domain annotations. Our research
validates the scalability and cost-efficiency of combining citizen science with
weakly supervised domain adaptation, offering a practical solution for complex,
data-scarce environmental monitoring applications.

</details>


### [82] [See Different, Think Better: Visual Variations Mitigating Hallucinations in LVLMs](https://arxiv.org/abs/2507.22003)
*Ziyun Dai,Xiaoqiang Li,Shaohua Zhang,Yuanchen Wu,Jide Li*

Main category: cs.CV

TL;DR: ViHallu通过视觉变异图像和指令微调LVLMs，提升视觉理解和降低幻觉。


<details>
  <summary>Details</summary>
Motivation: 传统文本中心的幻觉缓解方法在视觉语义对齐方面受限，尤其在需细粒度视觉理解的情境下效果有限，因此需要新的视觉为中心的解决方案。

Method: 提出ViHallu框架，采用视觉变异图像生成和视觉指令构建，图像具备可控的视觉变化并保留整体结构，通过微调LVLMs提升其细粒度视觉内容理解能力和视觉语义对齐。

Result: ViHallu显著增强了LVLMs在细粒度视觉理解上的表现，并有效减少了幻觉现象，同时发布了ViHallu-Instruction视觉指令数据集，以帮助幻觉缓解和视觉语义对齐。

Conclusion: ViHallu通过视觉变异图像生成和视觉指令构建，成功提升了LVLMs的视觉语义对齐能力，并降低了幻觉现象，实验结果表明其效果显著。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable
capabilities in visual understanding and multimodal reasoning. However, LVLMs
frequently exhibit hallucination phenomena, manifesting as the generated
textual responses that demonstrate inconsistencies with the provided visual
content. Existing hallucination mitigation methods are predominantly
text-centric, the challenges of visual-semantic alignment significantly limit
their effectiveness, especially when confronted with fine-grained visual
understanding scenarios. To this end, this paper presents ViHallu, a
Vision-Centric Hallucination mitigation framework that enhances visual-semantic
alignment through Visual Variation Image Generation and Visual Instruction
Construction. ViHallu introduces \textbf{\textit{visual variation images}} with
controllable visual alterations while maintaining the overall image structure.
These images, combined with carefully constructed visual instructions, enable
LVLMs to better understand fine-grained visual content through fine-tuning,
allowing models to more precisely capture the correspondence between visual
content and text, thereby enhancing visual-semantic alignment. Extensive
experiments on multiple benchmarks show that ViHallu effectively enhances
models' fine-grained visual understanding while significantly reducing
hallucination tendencies. Furthermore, we release ViHallu-Instruction, a visual
instruction dataset specifically designed for hallucination mitigation and
visual-semantic alignment. Code is available at
https://github.com/oliviadzy/ViHallu.

</details>


### [83] [VeS: Teaching Pixels to Listen Without Supervision](https://arxiv.org/abs/2507.22008)
*Sajay Raj*

Main category: cs.CV

TL;DR: 研究表明，密集目标函数在多语言低资源环境中性能优越。


<details>
  <summary>Details</summary>
Motivation: 验证密集音视模型在低资源、多语言、嘈杂环境中的表现，并探讨聚合函数的选择对表现的影响。

Method: 使用 Project Vaani 的多语言子集，比较三种对比目标：全局平均池化损失、密集最大平均令牌匹配器和简单混合集合。

Result: 密集目标函数在 R@1（音频-视觉）指标上比全局池化提高了59%相对表现，并且在零样本定位上表现出色。

Conclusion: 在多语言环境中，密集目标函数在处理低资源、代码混合和噪声情况下依然表现出色。

Abstract: Recent dense audio-visual (AV) models achieve impressive retrieval and
emergent localization, but almost all evidence comes from English-centric,
caption-rich web video. It is unclear whether these objectives survive in
low-resource, code-switched, and noisy multilingual settings that typify
developing regions. We show they do**-**and that the choice of aggregation
function becomes even more critical. Using a multilingual subset of Project
Vaani spanning dozens of Indian languages and dialectal variants, we compare
three contrastive objectives: (i) a global mean-pooled loss (CLIP-style), (ii)
a dense max-mean token matcher (DenseAV-style), and (iii) a simple hybrid
(motivated by frozen-vision alignment strategies). The dense objective delivers
a +59% relative R@1 (Audio Visual) improvement over global pooling and
substantially lower mean/median ranks, while consistently producing sharp
zero-shot localization heatmaps of spoken objects-despite keeping the vision
backbone entirely frozen (no LoRA / partial fine-tuning). Our results
demonstrate that dense token routing is not a luxury of high-resource English
corpora; it is more decisive when annotations and acoustic cleanliness are
scarce. We release the codebase and trained models.

</details>


### [84] [XAI for Point Cloud Data using Perturbations based on Meaningful Segmentation](https://arxiv.org/abs/2507.22020)
*Raju Ningappa Mulawade,Christoph Garth,Alexander Wiebel*

Main category: cs.CV

TL;DR: 提出了一种新的解释性AI方法，通过创新的点移机制优化点云分类算法解释。


<details>
  <summary>Details</summary>
Motivation: 随着AI技术的快速发展，理解AI算法的决策过程在关键领域应用中变得尤为重要。

Method: 提出了一种基于分割的解释性人工智能(XAI)方法，并使用创新的点移机制对点云数据进行扰动。

Result: 我们的方法产生的显著性图能提供更加有意义的解释，如通过示例输入分析，这种方法在生成易于理解的解释上具有优势。

Conclusion: 我们的方法相比于传统聚类算法能生成更容易被人类理解的显著性图，从而改进了对AI算法的分析。

Abstract: We propose a novel segmentation-based explainable artificial intelligence
(XAI) method for neural networks working on point cloud classification. As one
building block of this method, we propose a novel point-shifting mechanism to
introduce perturbations in point cloud data. Recently, AI has seen an
exponential growth. Hence, it is important to understand the decision-making
process of AI algorithms when they are applied in critical areas. Our work
focuses on explaining AI algorithms that classify point cloud data. An
important aspect of the methods used for explaining AI algorithms is their
ability to produce explanations that are easy for humans to understand. This
allows them to analyze the AI algorithms better and make appropriate decisions
based on that analysis. Therefore, in this work, we intend to generate
meaningful explanations that can be easily interpreted by humans. The point
cloud data we consider represents 3D objects such as cars, guitars, and
laptops. We make use of point cloud segmentation models to generate
explanations for the working of classification models. The segments are used to
introduce perturbations into the input point cloud data and generate saliency
maps. The perturbations are introduced using the novel point-shifting mechanism
proposed in this work which ensures that the shifted points no longer influence
the output of the classification algorithm. In contrast to previous methods,
the segments used by our method are meaningful, i.e. humans can easily
interpret the meaning of the segments. Thus, the benefit of our method over
other methods is its ability to produce more meaningful saliency maps. We
compare our method with the use of classical clustering algorithms to generate
explanations. We also analyze the saliency maps generated for example inputs
using our method to demonstrate the usefulness of the method in generating
meaningful explanations.

</details>


### [85] [From Seeing to Experiencing: Scaling Navigation Foundation Models with Reinforcement Learning](https://arxiv.org/abs/2507.22028)
*Honglin He,Yukai Ma,Wayne Wu,Bolei Zhou*

Main category: cs.CV

TL;DR: 提出S2E框架结合视频预训练与强化学习，提升导航模型在动态环境中的能力与安全性。


<details>
  <summary>Details</summary>
Motivation: 导航基础模型虽然具备跨环境和跨实体的泛化能力，但由于仅在离线数据上训练，难以在现实环境中进行交互和安全导航。因此，需要一个框架来扩展其动态环境中的能力。

Method: 本文采用“S2E”框架，将视频的预训练与强化学习的后训练相结合。通过“锚定引导分布匹配策略”和“残差注意模块”来稳固学习过程和增强模型反应能力。并使用NavBench-GS进行系统化评估。

Result: 通过构建NavBench-GS评估标准，实验表明S2E框架能有效提升模型在实际应用中的安全性和泛化能力，并展示了强化学习在后训练中比监督微调更具优势。

Conclusion: 本文引入了S2E框架，将导航基础模型与强化学习结合，以增强其交互能力并扩展在机器人导航任务中的表现。

Abstract: Navigation foundation models trained on massive webscale data enable agents
to generalize across diverse environments and embodiments. However, these
models trained solely on offline data, often lack the capacity to reason about
the consequences of their actions or adapt through counterfactual
understanding. They thus face significant limitations in the real-world urban
navigation where interactive and safe behaviors, such as avoiding obstacles and
moving pedestrians, are critical. To tackle these challenges, we introduce the
Seeing-to-Experiencing framework to scale the capability of navigation
foundation models with reinforcement learning. S2E combines the strengths of
pre-training on videos and post-training through RL. It maintains the
generalizability acquired from large-scale real-world videos while enhancing
its interactivity through RL in simulation environments. Specifically, we
introduce two innovations: an Anchor-Guided Distribution Matching strategy,
which stabilizes learning and models diverse motion patterns through
anchor-based supervision; and a Residual-Attention Module, which obtains
reactive behaviors from simulation environments without erasing the model's
pretrained knowledge. Moreover, we establish a comprehensive end-to-end
evaluation benchmark, NavBench-GS, built on photorealistic 3DGS reconstructions
of real-world scenes that incorporate physical interactions. It can
systematically assess the generalizability and safety of navigation foundation
models. Extensive experiments show that S2E mitigates the diminishing returns
often seen when scaling with offline data alone. We perform a thorough analysis
of the benefits of Reinforcement Learning compared to Supervised Fine-Tuning in
the context of post-training for robot learning. Our findings emphasize the
crucial role of integrating interactive online experiences to effectively scale
foundation models in Robotics.

</details>


### [86] [Shallow Deep Learning Can Still Excel in Fine-Grained Few-Shot Learning](https://arxiv.org/abs/2507.22041)
*Chaofei Qi,Chao Ye,Zhitai Liu,Weiyang Lin,Jianbin Qiu*

Main category: cs.CV

TL;DR: 本文提出了位置感知星座网络LCN-4，可改善细粒度小样本学习性能，超过常规浅层网络，达到或超越主流深度网络水平。


<details>
  <summary>Details</summary>
Motivation: 重新评估网络深度与完全编码few-shot实例能力之间的关系，探讨浅层深度架构是否可以实现与主流深度骨干网相媲美或更好的性能。

Method: 提出了一种位置感知星座网络（LCN-4），配备了前沿的位置感知特征聚类模块，通过空间特征融合、特征聚类和隐性特征定位来减少总体损失。同时提出了一般网格位置编码补偿和频域位置嵌入技术。

Result: LCN-4在三个细粒度小样本学习基准上进行了验证，结果表明它的性能优于ConvNet-4，并与大多数ResNet12的方法不相上下，甚至更好。

Conclusion: LCN-4在三个具有代表性的FGFSL基准上表现出色，显著优于ConvNet-4基础上的现有技术，并达到了与大多数基于ResNet12的方法相当或更好的性能，验证了我们的假设。

Abstract: Deep learning has witnessed the extensive utilization across a wide spectrum
of domains, including fine-grained few-shot learning (FGFSL) which heavily
depends on deep backbones. Nonetheless, shallower deep backbones such as
ConvNet-4, are not commonly preferred because they're prone to extract a larger
quantity of non-abstract visual attributes. In this paper, we initially
re-evaluate the relationship between network depth and the ability to fully
encode few-shot instances, and delve into whether shallow deep architecture
could effectuate comparable or superior performance to mainstream deep
backbone. Fueled by the inspiration from vanilla ConvNet-4, we introduce a
location-aware constellation network (LCN-4), equipped with a cutting-edge
location-aware feature clustering module. This module can proficiently encoder
and integrate spatial feature fusion, feature clustering, and recessive feature
location, thereby significantly minimizing the overall loss. Specifically, we
innovatively put forward a general grid position encoding compensation to
effectively address the issue of positional information missing during the
feature extraction process of specific ordinary convolutions. Additionally, we
further propose a general frequency domain location embedding technique to
offset for the location loss in clustering features. We have carried out
validation procedures on three representative fine-grained few-shot benchmarks.
Relevant experiments have established that LCN-4 notably outperforms the
ConvNet-4 based State-of-the-Arts and achieves performance that is on par with
or superior to most ResNet12-based methods, confirming the correctness of our
conjecture.

</details>


### [87] [Ov3R: Open-Vocabulary Semantic 3D Reconstruction from RGB Videos](https://arxiv.org/abs/2507.22052)
*Ziren Gong,Xiaohan Li,Fabio Tosi,Jiawei Han,Stefano Mattoccia,Jianfei Cai,Matteo Poggi*

Main category: cs.CV

TL;DR: 本研究提出了一个新的3D重建框架Ov3R，通过整合CLIP语义，实现了语义对齐和几何一致性的突破，在3D重建和分割性能方面取得了优异结果。


<details>
  <summary>Details</summary>
Motivation: 目前的3D重建方法在语义对齐和几何一致性方面存在不足，尤其是在处理开放词汇库的语义3D重建时。本文提出Ov3R框架，以解决这些挑战。

Method: Ov3R框架由两个关键模块组成：CLIP3R模块，负责利用CLIP的3D重建功能预测稠密点地图；2D-3D OVS模块，将2D特征提升到3D，并学习整合空间、几何和语义线索的融合描述符。

Result: 本研究通过将CLIP语义直接集成到重建过程中，实现了全局几何一致性和精细的语义对齐。在稠密3D重建和开放词汇3D分割方面，该框架达到了最先进的性能。

Conclusion: Ov3R框架标志着向实时语义感知空间AI迈出了前进的一步。

Abstract: We present Ov3R, a novel framework for open-vocabulary semantic 3D
reconstruction from RGB video streams, designed to advance Spatial AI. The
system features two key components: CLIP3R, a CLIP-informed 3D reconstruction
module that predicts dense point maps from overlapping clips while embedding
object-level semantics; and 2D-3D OVS, a 2D-3D open-vocabulary semantic module
that lifts 2D features into 3D by learning fused descriptors integrating
spatial, geometric, and semantic cues. Unlike prior methods, Ov3R incorporates
CLIP semantics directly into the reconstruction process, enabling globally
consistent geometry and fine-grained semantic alignment. Our framework achieves
state-of-the-art performance in both dense 3D reconstruction and
open-vocabulary 3D segmentation, marking a step forward toward real-time,
semantics-aware Spatial AI.

</details>


### [88] [MetaLab: Few-Shot Game Changer for Image Recognition](https://arxiv.org/abs/2507.22057)
*Chaofei Qi,Zhitai Liu,Jianbin Qiu*

Main category: cs.CV

TL;DR: 提出一种新的CIELab引导的协同元学习方法，显著提高小样本图像识别性能，实验接近99%的准确率。


<details>
  <summary>Details</summary>
Motivation: 在小样本图像识别领域存在显著技术差距，且具有重要应用前景，因此提出一种有效的原始方法以解决此问题。

Method: 提出CIELab引导的协同元学习方法(MetaLab)，包括两个协同的神经网络：LabNet和LabGNN。LabNet能够对CIELab颜色空间进行域转换并提取丰富的分组特征，LabGNN可以促进亮度图与颜色图之间的相互学习。

Result: 在多个粗粒度、精细粒度和跨域小样本数据集上，实验表明MetaLab方法在每类一张样本的情况下可以达到高准确率、鲁棒性能和有效泛化能力，几乎达到了人的识别上限。

Conclusion: MetaLab方法有效地缩小了小样本图像识别与常规大规模图像识别之间的技术差距，提供了几乎与人类相当的识别能力。

Abstract: Difficult few-shot image recognition has significant application prospects,
yet remaining the substantial technical gaps with the conventional large-scale
image recognition. In this paper, we have proposed an efficient original method
for few-shot image recognition, called CIELab-Guided Coherent Meta-Learning
(MetaLab). Structurally, our MetaLab comprises two collaborative neural
networks: LabNet, which can perform domain transformation for the CIELab color
space and extract rich grouped features, and coherent LabGNN, which can
facilitate mutual learning between lightness graph and color graph. For
sufficient certification, we have implemented extensive comparative studies on
four coarse-grained benchmarks, four fine-grained benchmarks, and four
cross-domain few-shot benchmarks. Specifically, our method can achieve high
accuracy, robust performance, and effective generalization capability with
one-shot sample per class. Overall, all experiments have demonstrated that our
MetaLab can approach 99\% $\uparrow\downarrow$ accuracy, reaching the human
recognition ceiling with little visual deviation.

</details>


### [89] [X-Omni: Reinforcement Learning Makes Discrete Autoregressive Image Generative Models Great Again](https://arxiv.org/abs/2507.22058)
*Zigang Geng,Yibing Wang,Yeyao Ma,Chen Li,Yongming Rao,Shuyang Gu,Zhao Zhong,Qinglin Lu,Han Hu,Xiaosong Zhang,Linus,Di Wang,Jie Jiang*

Main category: cs.CV

TL;DR: 通过强化学习改善图像生成质量，实现图像和语言生成的统一框架X-Omni。


<details>
  <summary>Details</summary>
Motivation: 当前图像生成存在着低视觉保真度、失真输出以及在呈现复杂细节时难以遵循指令的问题。

Method: 提出了一个名为X-Omni的框架，包括语义图像分词器、统一自回归模型以及离线扩散解码器。

Result: 使用7B语言模型在图像生成任务中达到了最先进的性能，生成高美学质量的图像，并在跟随指令和呈现长文本方面表现出色。

Conclusion: 通过引入强化学习，提升离散自回归模型生成图像的质量，实现图像和语言生成的无缝整合。

Abstract: Numerous efforts have been made to extend the ``next token prediction''
paradigm to visual contents, aiming to create a unified approach for both image
generation and understanding. Nevertheless, attempts to generate images through
autoregressive modeling with discrete tokens have been plagued by issues such
as low visual fidelity, distorted outputs, and failure to adhere to complex
instructions when rendering intricate details. These shortcomings are likely
attributed to cumulative errors during autoregressive inference or information
loss incurred during the discretization process. Probably due to this
challenge, recent research has increasingly shifted toward jointly training
image generation with diffusion objectives and language generation with
autoregressive objectives, moving away from unified modeling approaches. In
this work, we demonstrate that reinforcement learning can effectively mitigate
artifacts and largely enhance the generation quality of a discrete
autoregressive modeling method, thereby enabling seamless integration of image
and language generation. Our framework comprises a semantic image tokenizer, a
unified autoregressive model for both language and images, and an offline
diffusion decoder for image generation, termed X-Omni. X-Omni achieves
state-of-the-art performance in image generation tasks using a 7B language
model, producing images with high aesthetic quality while exhibiting strong
capabilities in following instructions and rendering long texts.

</details>


### [90] [StepAL: Step-aware Active Learning for Cataract Surgical Videos](https://arxiv.org/abs/2507.22059)
*Nisarg A. Shah,Bardia Safaei,Shameema Sikder,S. Swaroop Vedula,Vishal M. Patel*

Main category: cs.CV

TL;DR: 提出了一种新型的主动学习框架StepAL，用于整段视频选择，在手术步骤识别中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统的主动学习方法在处理长时间未剪辑的手术视频时效果欠佳。

Method: StepAL框架整合了一种步骤感知特征表示，该表示利用伪标签捕捉每个视频内预测的步骤分布，并结合熵加权聚类策略。

Result: 在两个白内障手术数据集（Cataract-1k 和 Cataract-101）上进行的实验表明，StepAL在较少标记视频的情况下，其步骤识别的准确性超过了现有的主动学习方法。

Conclusion: StepAL有效提高了手术步骤识别的准确性，并减少了需要标注的视频数量。

Abstract: Active learning (AL) can reduce annotation costs in surgical video analysis
while maintaining model performance. However, traditional AL methods, developed
for images or short video clips, are suboptimal for surgical step recognition
due to inter-step dependencies within long, untrimmed surgical videos. These
methods typically select individual frames or clips for labeling, which is
ineffective for surgical videos where annotators require the context of the
entire video for annotation. To address this, we propose StepAL, an active
learning framework designed for full video selection in surgical step
recognition. StepAL integrates a step-aware feature representation, which
leverages pseudo-labels to capture the distribution of predicted steps within
each video, with an entropy-weighted clustering strategy. This combination
prioritizes videos that are both uncertain and exhibit diverse step
compositions for annotation. Experiments on two cataract surgery datasets
(Cataract-1k and Cataract-101) demonstrate that StepAL consistently outperforms
existing active learning approaches, achieving higher accuracy in step
recognition with fewer labeled videos. StepAL offers an effective approach for
efficient surgical video analysis, reducing the annotation burden in developing
computer-assisted surgical systems.

</details>


### [91] [MOVE: Motion-Guided Few-Shot Video Object Segmentation](https://arxiv.org/abs/2507.22061)
*Kaining Ying,Hengrui Hu,Henghui Ding*

Main category: cs.CV

TL;DR: 引入了一个新的数据集MOVE，并提出了解耦运动外观网络（DMA），在运动引导的少样本视频目标分割中取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 当前的FSVOS数据集和方法主要集中于静态的对象类别，无法充分利用视频中的动态信息。因此，需要一个专注于运动引导的少样本视频目标分割的数据集。

Method: 分析现有动作引导的少样本视频目标分割方法的挑战，提出并验证一种新基准方法 - 解耦运动外观网络（DMA）。

Result: 本文的实验表明，在少样本运动理解中，DMA取得了优越的表现。

Conclusion: 现有方法在解决运动引导的少样本视频目标分割上存在困难，本文提出的新基准方法（DMA）在少样本运动理解方面表现优越，为未来研究奠定了坚实基础。

Abstract: This work addresses motion-guided few-shot video object segmentation (FSVOS),
which aims to segment dynamic objects in videos based on a few annotated
examples with the same motion patterns. Existing FSVOS datasets and methods
typically focus on object categories, which are static attributes that ignore
the rich temporal dynamics in videos, limiting their application in scenarios
requiring motion understanding. To fill this gap, we introduce MOVE, a
large-scale dataset specifically designed for motion-guided FSVOS. Based on
MOVE, we comprehensively evaluate 6 state-of-the-art methods from 3 different
related tasks across 2 experimental settings. Our results reveal that current
methods struggle to address motion-guided FSVOS, prompting us to analyze the
associated challenges and propose a baseline method, Decoupled Motion
Appearance Network (DMA). Experiments demonstrate that our approach achieves
superior performance in few shot motion understanding, establishing a solid
foundation for future research in this direction.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [92] [Categorical Classification of Book Summaries Using Word Embedding Techniques](https://arxiv.org/abs/2507.21058)
*Kerem Keskin,Mümine Kaya Keleş*

Main category: cs.CL

TL;DR: 研究了不同的词嵌入方法和机器学习模型对图书摘要和类别的分类效果，并发现支持向量机、朴素贝叶斯和逻辑回归结合TF-IDF和One-Hot编码在土耳其文本分类中效果最佳。


<details>
  <summary>Details</summary>
Motivation: 为提高图书摘要和类别的分类精度，结合词嵌入方法和自然语言处理技术。

Method: 采用词嵌入方法（如Word2Vec和TF-IDF）、自然语言处理技术和机器学习算法对图书摘要和类别进行分类，并比较其效果。

Result: 支持向量机、朴素贝叶斯和逻辑回归模型结合TF-IDF和One-Hot编码词嵌入技术对土耳其文本的分类效果更为优异。

Conclusion: Word2Vec和TF-IDF词嵌入方法结合Support Vector Machine、Naive Bayes和Logistic Regression模型在处理土耳其文本时表现出较为成功的分类结果。

Abstract: In this study, book summaries and categories taken from book sites were
classified using word embedding methods, natural language processing techniques
and machine learning algorithms. In addition, one hot encoding, Word2Vec and
Term Frequency - Inverse Document Frequency (TF-IDF) methods, which are
frequently used word embedding methods were used in this study and their
success was compared. Additionally, the combination table of the pre-processing
methods used is shown and added to the table. Looking at the results, it was
observed that Support Vector Machine, Naive Bayes and Logistic Regression
Models and TF-IDF and One-Hot Encoder word embedding techniques gave more
successful results for Turkish texts.

</details>


### [93] [Dialogic Social Learning for Artificial Agents: Enhancing LLM Ontology Acquisition through Mixed-Initiative Educational Interactions](https://arxiv.org/abs/2507.21065)
*Sabrina Patania,Luca Annese,Cansu Koyuturk,Azzurra Ruggeri,Dimitri Ognibene*

Main category: cs.CL

TL;DR: 研究通过引入AI社交健身房和双向教学对话，提升了大型语言模型的知识获取能力。


<details>
  <summary>Details</summary>
Motivation: 研究者们受维果斯基社会文化理论的启发，希望通过社交介导学习范式解决传统AI模型在在线知识获取中的效率问题。

Method: 引入了一个动态环境“AI社交健身房”，AI学习代理与经验丰富的AI教师代理进行双向教学对话。

Result: 实证结果表明，混合方向互动通过自下而上的解释与学习者主动提问，显著提高了LLM的知识获取和应用能力。

Conclusion: 整合教学和心理思想的AI训练方法可以显著改善GPT后训练阶段的知识获取，并提供更高质量的响应。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in
processing extensive offline datasets. However, they often face challenges in
acquiring and integrating complex, knowledge online. Traditional AI training
paradigms, predominantly based on supervised learning or reinforcement
learning, mirror a 'Piagetian' model of independent exploration. These
approaches typically rely on large datasets and sparse feedback signals,
limiting the models' ability to learn efficiently from interactions. Drawing
inspiration from Vygotsky's sociocultural theory, this study explores the
potential of socially mediated learning paradigms to address these limitations.
  We introduce a dynamic environment, termed the 'AI Social Gym', where an AI
learner agent engages in dyadic pedagogical dialogues with knowledgeable AI
teacher agents. These interactions emphasize external, structured dialogue as a
core mechanism for knowledge acquisition, contrasting with methods that depend
solely on internal inference or pattern recognition.
  Our investigation focuses on how different pedagogical strategies impact the
AI learning process in the context of ontology acquisition. Empirical results
indicate that such dialogic approaches-particularly those involving
mixed-direction interactions combining top-down explanations with
learner-initiated questioning-significantly enhance the LLM's ability to
acquire and apply new knowledge, outperforming both unidirectional
instructional methods and direct access to structured knowledge, formats
typically present in training datasets.
  These findings suggest that integrating pedagogical and psychological
insights into AI and robot training can substantially improve post-training
knowledge acquisition and response quality. This approach offers a
complementary pathway to existing strategies like prompt engineering

</details>


### [94] [Product vs. Process: Exploring EFL Students' Editing of AI-Generated Text for Expository Writing](https://arxiv.org/abs/2507.21073)
*David James Woo,Yangyang Yu,Kai Guo,Yilin Huang,April Ka Yeng Fung*

Main category: cs.CL

TL;DR: 研究发现AI生成文本在EFL写作中提供支持但不能替代写作技巧。


<details>
  <summary>Details</summary>
Motivation: 探讨AI生成文本在EFL写作中的影响，尤其是其对学生说明文写作过程和作文的影响。

Method: 采用汇聚设计分析了学生的屏幕录制和作文，研究其编辑行为和写作质量。分析方法包括定性编码、描述性统计、时间序列分析、人类评分以及多元线性回归分析。

Result: 分析显示AI生成的词语数量对所有评分维度有积极预测作用，而大多数编辑变量影响较小，且存在学生编辑努力与作文质量提升不成比例的情况。

Conclusion: 本研究表明，尽管学生进行了大量的编辑努力，但并未显著提升作文质量，这意味着AI提供了支持但无法替代写作技巧。

Abstract: Text generated by artificial intelligence (AI) chatbots is increasingly used
in English as a foreign language (EFL) writing contexts, yet its impact on
students' expository writing process and compositions remains understudied.
This research examines how EFL secondary students edit AI-generated text.
Exploring editing behaviors in their expository writing process and in
expository compositions, and their effect on human-rated scores for content,
organization, language, and overall quality. Participants were 39 Hong Kong
secondary students who wrote an expository composition with AI chatbots in a
workshop. A convergent design was employed to analyze their screen recordings
and compositions to examine students' editing behaviors and writing qualities.
Analytical methods included qualitative coding, descriptive statistics,
temporal sequence analysis, human-rated scoring, and multiple linear regression
analysis. We analyzed over 260 edits per dataset, and identified two editing
patterns: one where students refined introductory units repeatedly before
progressing, and another where they quickly shifted to extensive edits in body
units (e.g., topic and supporting sentences). MLR analyses revealed that the
number of AI-generated words positively predicted all score dimensions, while
most editing variables showed minimal impact. These results suggest a
disconnect between students' significant editing effort and improved
composition quality, indicating AI supports but does not replace writing
skills. The findings highlight the importance of genre-specific instruction and
process-focused writing before AI integration. Educators should also develop
assessments valuing both process and product to encourage critical engagement
with AI text.

</details>


### [95] [Which symbol grounding problem should we try to solve?](https://arxiv.org/abs/2507.21080)
*Vincent C. Müller*

Main category: cs.CL

TL;DR: 作者批判了现有的基础问题解决方案，建议从计算的角度重新思考问题，并强调理解人工代理的行为能力和意义功能的重要性。


<details>
  <summary>Details</summary>
Motivation: Floridi和Taddeo提出了“零语义承诺”的条件及解决方案，但该条件无法实现。需要重新思考基础问题的本质及系统目标在问题中的作用。

Method: 借助对Luc Steels的不同解决方案的分析，建议重新思考问题本质及系统中目标的作用。

Result: 提出了理解计算并重新思考基础问题的必要性，转向解释和再现代理行为能力和意义功能。

Conclusion: 合理理解计算的基础上，唯一合理的基础问题是如何解释和再现人工计算代理中的行为能力和意义功能。

Abstract: Floridi and Taddeo propose a condition of "zero semantic commitment" for
solutions to the grounding problem, and a solution to it. I argue briefly that
their condition cannot be fulfilled, not even by their own solution. After a
look at Luc Steels' very different competing suggestion, I suggest that we need
to re-think what the problem is and what role the 'goals' in a system play in
formulating the problem. On the basis of a proper understanding of computing, I
come to the conclusion that the only sensible grounding problem is how we can
explain and re-produce the behavioral ability and function of meaning in
artificial computational agents

</details>


### [96] [ChatGPT Reads Your Tone and Responds Accordingly -- Until It Does Not -- Emotional Framing Induces Bias in LLM Outputs](https://arxiv.org/abs/2507.21083)
*Franck Bardol*

Main category: cs.CL

TL;DR: GPT-4对提问情绪语气敏感，可能存在“反弹”偏见，影响AI对齐和信任。


<details>
  <summary>Details</summary>
Motivation: 研究GPT-4在不同情绪语境下响应变化的偏见，以促进AI对齐和信任。

Method: 系统地改变156个提示的情绪语气，使用基于1536维嵌入的可视化确认语义漂移。

Result: 发现GPT-4对负面措辞的响应比中性措辞少三倍，介绍“语调底线”并量化行为。

Conclusion: 情绪措辞会影响GPT-4的响应，特别是在敏感话题上。情绪语气变化被抑制，表明存在对齐覆盖。

Abstract: Large Language Models like GPT-4 adjust their responses not only based on the
question asked, but also on how it is emotionally phrased. We systematically
vary the emotional tone of 156 prompts - spanning controversial and everyday
topics - and analyze how it affects model responses. Our findings show that
GPT-4 is three times less likely to respond negatively to a negatively framed
question than to a neutral one. This suggests a "rebound" bias where the model
overcorrects, often shifting toward neutrality or positivity. On sensitive
topics (e.g., justice or politics), this effect is even more pronounced:
tone-based variation is suppressed, suggesting an alignment override. We
introduce concepts like the "tone floor" - a lower bound in response negativity
- and use tone-valence transition matrices to quantify behavior. Visualizations
based on 1536-dimensional embeddings confirm semantic drift based on tone. Our
work highlights an underexplored class of biases driven by emotional framing in
prompts, with implications for AI alignment and trust. Code and data are
available at: https://github.com/bardolfranck/llm-responses-viewer

</details>


### [97] [Reviving Your MNEME: Predicting The Side Effects of LLM Unlearning and Fine-Tuning via Sparse Model Diffing](https://arxiv.org/abs/2507.21084)
*Aly M. Kassem,Zhuan Shi,Negar Rostamzadeh,Golnoosh Farnadi*

Main category: cs.CL

TL;DR: MNEME是一种用于识别大型语言模型微调副作用的框架，能够高效预测这些副作用并提供管理模型行为的工具。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏一种通用方法来检测大型语言模型在微调或排除某些知识后可能出现的不可预测或突发的副作用。

Method: MNEME使用对比基准模型和微调模型的任务无关数据进行差异分析，以识别行为转变。

Result: 在五种大型语言模型的三种场景下进行应用，MNEME在预测副作用方面实现高达95%的准确率。并且研究表明，高激活样本的再训练可以部分逆转这些副作用。

Conclusion: MNEME是一种轻量级框架，可以通过稀疏模型差异来识别大型语言模型在微调或“去学”过程中出现的意外副作用。

Abstract: Large language models (LLMs) are frequently fine-tuned or unlearned to adapt
to new tasks or eliminate undesirable behaviors. While existing evaluation
methods assess performance after such interventions, there remains no general
approach for detecting unintended side effects, such as unlearning biology
content degrading performance on chemistry tasks, particularly when these
effects are unpredictable or emergent. To address this issue, we introduce
MNEME, Model diffiNg for Evaluating Mechanistic Effects, a lightweight
framework for identifying these side effects using sparse model diffing. MNEME
compares base and fine-tuned models on task-agnostic data (for example, The
Pile, LMSYS-Chat-1M) without access to fine-tuning data to isolate behavioral
shifts. Applied to five LLMs across three scenarios: WMDP knowledge unlearning,
emergent misalignment, and benign fine-tuning, MNEME achieves up to 95 percent
accuracy in predicting side effects, aligning with known benchmarks and
requiring no custom heuristics. Furthermore, we show that retraining on
high-activation samples can partially reverse these effects. Our results
demonstrate that sparse probing and diffing offer a scalable and automated lens
into fine-tuning-induced model changes, providing practical tools for
understanding and managing LLM behavior.

</details>


### [98] [Multi-Amateur Contrastive Decoding for Text Generation](https://arxiv.org/abs/2507.21086)
*Jaydip Sen,Subhasis Dasgupta,Hetvi Waghela*

Main category: cs.CL

TL;DR: 多业余对比解码（MACD）利用多个业余模型改善文本生成的质量和多样性，优于传统方法和原始CD。


<details>
  <summary>Details</summary>
Motivation: 为了克服单个业余模型在描述语言生成失败模式的局限性，如重复、幻觉和风格漂移等问题。

Method: 提出了一种多业余对比解码（MACD）框架，该框架利用多个业余模型来综合刻画不良生成模式，并通过平均和共识惩罚机制整合对比信号。

Result: 实验结果表明，在新闻、百科和叙事等多个领域，MACD在流畅性、连贯性、多样性和适应性方面均优于传统解码方法和原始CD方法。

Conclusion: MACD框架通过整合多个业余语言模型，能够更好地避免不良生成模式，并改善文本的流畅性、连贯性、多样性和适应性。

Abstract: Contrastive Decoding (CD) has emerged as an effective inference-time strategy
for enhancing open-ended text generation by exploiting the divergence in output
probabilities between a large expert language model and a smaller amateur
model. Although CD improves coherence and fluency, its dependence on a single
amateur restricts its capacity to capture the diverse and multifaceted failure
modes of language generation, such as repetition, hallucination, and stylistic
drift. This paper proposes Multi-Amateur Contrastive Decoding (MACD), a
generalization of the CD framework that employs an ensemble of amateur models
to more comprehensively characterize undesirable generation patterns. MACD
integrates contrastive signals through both averaging and consensus
penalization mechanisms and extends the plausibility constraint to operate
effectively in the multi-amateur setting. Furthermore, the framework enables
controllable generation by incorporating amateurs with targeted stylistic or
content biases. Experimental results across multiple domains, such as news,
encyclopedic, and narrative, demonstrate that MACD consistently surpasses
conventional decoding methods and the original CD approach in terms of fluency,
coherence, diversity, and adaptability, all without requiring additional
training or fine-tuning.

</details>


### [99] [QU-NLP at CheckThat! 2025: Multilingual Subjectivity in News Articles Detection using Feature-Augmented Transformer Models with Sequential Cross-Lingual Fine-Tuning](https://arxiv.org/abs/2507.21095)
*Mohammad AL-Smadi*

Main category: cs.CL

TL;DR: 提出了一种结合上下文嵌入和统计特征的增强Transformer架构，用于新闻文章主观性检测，并在多语言环境中取得了竞争性成绩。


<details>
  <summary>Details</summary>
Motivation: 为了在新闻文章中有效地区分作者的主观观点与对主题的客观陈述，开发出一种能够处理多语言和零样本环境的系统。

Method: 采用预训练语言模型的上下文嵌入结合统计和语言特征的增强特征Transformer架构。对不同语言使用不同策略：针对阿拉伯语，使用AraELECTRA并增加词性标注和TF-IDF特征；对于其他语言，微调跨语言DeBERTa V3模型并通过门控机制结合TF-IDF特征。

Result: 在英、德、阿拉伯和罗马尼亚语的单语言和零样本环境中取得了显著成功，分别获得第一名（英、罗语）、第三名（德语）和第四名（阿语）的排名。

Conclusion: 这项研究通过提出一种增强特征的Transformer架构，在多语言和零样本环境下实现了高效的主观性检测，其中包括对英、德、阿拉伯和罗马尼亚语的处理。

Abstract: This paper presents our approach to the CheckThat! 2025 Task 1 on
subjectivity detection, where systems are challenged to distinguish whether a
sentence from a news article expresses the subjective view of the author or
presents an objective view on the covered topic. We propose a feature-augmented
transformer architecture that combines contextual embeddings from pre-trained
language models with statistical and linguistic features. Our system leveraged
pre-trained transformers with additional lexical features: for Arabic we used
AraELECTRA augmented with part-of-speech (POS) tags and TF-IDF features, while
for the other languages we fine-tuned a cross-lingual DeBERTa~V3 model combined
with TF-IDF features through a gating mechanism. We evaluated our system in
monolingual, multilingual, and zero-shot settings across multiple languages
including English, Arabic, German, Italian, and several unseen languages. The
results demonstrate the effectiveness of our approach, achieving competitive
performance across different languages with notable success in the monolingual
setting for English (rank 1st with macro-F1=0.8052), German (rank 3rd with
macro-F1=0.8013), Arabic (rank 4th with macro-F1=0.5771), and Romanian (rank
1st with macro-F1=0.8126) in the zero-shot setting. We also conducted an
ablation analysis that demonstrated the importance of combining TF-IDF features
with the gating mechanism and the cross-lingual transfer for subjectivity
detection. Furthermore, our analysis reveals the model's sensitivity to both
the order of cross-lingual fine-tuning and the linguistic proximity of the
training languages.

</details>


### [100] [Rewrite-to-Rank: Optimizing Ad Visibility via Retrieval-Aware Text Rewriting](https://arxiv.org/abs/2507.21099)
*Chloe Ho,Ishneet Sukhvinder Singh,Diya Sharma,Tanvi Reddy Anumandla,Michael Lu,Vasu Sharma,Kevin Zhu*

Main category: cs.CL

TL;DR: 本文通过LLM进行广告重写，使用PPO模型优化广告措辞，提高广告在检索系统中的排名和包含频率，实验表明强化学习方法效果显著。


<details>
  <summary>Details</summary>
Motivation: 探索LLM对广告内容的措辞如何影响广告的可见性，并寻找优化广告措辞以增强其在检索系统中排名和包含的可扩展方法。

Method: 本文提出了一种带有自定义损失的监督微调框架，结合语义相关性和内容真实性进行广告重写，并使用PPO模型进行比较。

Result: 在指令提示和少样本提示的实验中，PPO训练模型在绝大多数情况下优于提示工程和监督微调，取得了显著的排名和包含频率提升。

Conclusion: 强化学习方法在广告重新编写中表现优异，能够显著提高广告在检索系统中的排名和包含频率。

Abstract: Search algorithms and user query relevance have given LLMs the ability to
return relevant information, but the effect of content phrasing on ad
visibility remains underexplored. We investigate how LLM-based rewriting of
advertisements can improve their ranking in retrieval systems and inclusion in
generated LLM responses, without modifying the retrieval model itself. We
introduce a supervised fine-tuning framework with a custom loss balancing
semantic relevance and content fidelity. To evaluate effectiveness, we propose
two metrics: DeltaMRR@K (ranking improvement) and DeltaDIR@K (inclusion
frequency improvement). Our approach presents a scalable method to optimize ad
phrasing, enhancing visibility in retrieval-based LLM workflows. Experiments
across both instruction-based and few-shot prompting demonstrate that PPO
trained models outperform both prompt engineering and supervised fine-tuning in
most cases, achieving up to a 2.79 DeltaDIR@5 and 0.0073 DeltaMRR@5 in
instruction-based prompting. These results highlight the importance of how the
ad is written before retrieval and prompt format and reinforcement learning in
effective ad rewriting for LLM integrated retrieval systems.

</details>


### [101] [iLSU-T: an Open Dataset for Uruguayan Sign Language Translation](https://arxiv.org/abs/2507.21104)
*Ariel E. Stassi,Yanina Boria,J. Matías Di Martino,Gregory Randall*

Main category: cs.CL

TL;DR: 该论文提出了用于手语处理的多模态数据集iLSU T，并进行了实验以验证其在手语翻译中的应用价值。


<details>
  <summary>Details</summary>
Motivation: 机器翻译需要本地数据来开发新技术并适应现有技术，尤其是考虑到不同国家的手语差异性。

Method: 呈现了iLSU T，一个乌拉圭手语RGB视频的开放数据集，并使用三个先进的翻译算法进行了一系列实验，以建立该数据集的基线并评估其有用性和所提出的数据处理流程。

Result: iLSU T数据集包含超过185小时的公共电视广播手语翻译视频，涵盖不同主题，由18位专业手语翻译人员参与。该数据和代码可供访问。

Conclusion: 实验结果表明，开发本地化数据集对手语翻译和理解至关重要，这对于开发提高所有人可及性和包容性的工具至关重要。

Abstract: Automatic sign language translation has gained particular interest in the
computer vision and computational linguistics communities in recent years.
Given each sign language country particularities, machine translation requires
local data to develop new techniques and adapt existing ones. This work
presents iLSU T, an open dataset of interpreted Uruguayan Sign Language RGB
videos with audio and text transcriptions. This type of multimodal and curated
data is paramount for developing novel approaches to understand or generate
tools for sign language processing. iLSU T comprises more than 185 hours of
interpreted sign language videos from public TV broadcasting. It covers diverse
topics and includes the participation of 18 professional interpreters of sign
language. A series of experiments using three state of the art translation
algorithms is presented. The aim is to establish a baseline for this dataset
and evaluate its usefulness and the proposed pipeline for data processing. The
experiments highlight the need for more localized datasets for sign language
translation and understanding, which are critical for developing novel tools to
improve accessibility and inclusion of all individuals. Our data and code can
be accessed.

</details>


### [102] [Creation of a Numerical Scoring System to Objectively Measure and Compare the Level of Rhetoric in Arabic Texts: A Feasibility Study, and A Working Prototype](https://arxiv.org/abs/2507.21106)
*Mandar Marathe*

Main category: cs.CL

TL;DR: 本研究开发了一种工具，能够客观测量阿拉伯文本中的修辞密度，并支持比较不同文本的修辞使用。


<details>
  <summary>Details</summary>
Motivation: 尽管阿拉伯修辞已经有大量的书籍探讨，且其地位很高，但目前并没有客观的方式去判断在某个文本中使用了多少阿拉伯修辞，或者比较不同体裁、作者或时代的使用情况。因此本研究旨在开发一种方法，通过测量构成阿拉伯修辞的文学手法的密度，作为阿拉伯修辞的代理标志。

Method: 该研究的方法包括编制84种常见修辞手法的清单，构建识别文本中文学手法的系统，以及利用文本的词素计数来计算文学装置密度的方法。还开发了四种电子工具和一个模拟工具来支持阿拉伯文文本修辞文学装置密度的计算。

Result: 本研究创建了一个有效的工具，可以计算和报告阿拉伯文本或演讲中的修辞文学装置的密度。

Conclusion: 该研究成功创建了一种工具，可以准确地报告任何阿拉伯文文本或演讲中的阿拉伯修辞密度。

Abstract: Arabic Rhetoric is the field of Arabic linguistics which governs the art and
science of conveying a message with greater beauty, impact and persuasiveness.
The field is as ancient as the Arabic language itself and is found extensively
in classical and contemporary Arabic poetry, free verse and prose. In practical
terms, it is the intelligent use of word order, figurative speech and
linguistic embellishments to enhance message delivery. Despite the volumes that
have been written about it and the high status accorded to it, there is no way
to objectively know whether a speaker or writer has used Arabic rhetoric in a
given text, to what extent, and why. There is no objective way to compare the
use of Arabic rhetoric across genres, authors or epochs. It is impossible to
know which of pre-Islamic poetry, Andalucian Arabic poetry, or modern literary
genres are richer in Arabic rhetoric. The aim of the current study was to
devise a way to measure the density of the literary devices which constitute
Arabic rhetoric in a given text, as a proxy marker for Arabic rhetoric itself.
A comprehensive list of 84 of the commonest literary devices and their
definitions was compiled. A system of identifying literary devices in texts was
constructed. A method of calculating the density of literary devices based on
the morpheme count of the text was utilised. Four electronic tools and an
analogue tool were created to support the calculation of an Arabic text's
rhetorical literary device density, including a website and online calculator.
Additionally, a technique of reporting the distribution of literary devices
used across the three sub-domains of Arabic rhetoric was created. The output of
this project is a working tool which can accurately report the density of
Arabic rhetoric in any Arabic text or speech.

</details>


### [103] [Curved Inference: Concern-Sensitive Geometry in Large Language Model Residual Streams](https://arxiv.org/abs/2507.21107)
*Rob Manson*

Main category: cs.CL

TL;DR: 研究提出了一种几何可解释框架“弯曲推理”，分析模型内部激活轨迹如何因语义关注变化而弯曲。发现这些变化模式有助于理解语言模型的语义抽象和模型对齐。


<details>
  <summary>Details</summary>
Motivation: 了解语言模型如何在语义关注变化时调整内部激活轨迹，并通过几何解释框架提供新的见解。

Method: 使用五种原生空间度量分析Gemma3-1b和LLaMA3.2-3b，重点关注曲率和显著性。度量是在从未嵌入矩阵推导的拉回语义度量下计算的。

Result: 语义关注变化促使模型内部激活轨迹发生可靠变化，尤其是在LLaMA中表现出显著的曲率和显著性变化。

Conclusion: 研究结果支持了一种关于LLM几何的两层视图：一种编码在嵌入空间中的潜在概念结构，以及由特定提示推理塑造的上下文轨迹。

Abstract: We propose Curved Inference - a geometric Interpretability framework that
tracks how the residual stream trajectory of a large language model bends in
response to shifts in semantic concern. Across 20 matched prompts spanning
emotional, moral, perspective, logical, identity, environmental, and nonsense
domains, we analyse Gemma3-1b and LLaMA3.2-3b using five native-space metrics,
with a primary focus on curvature (\k{appa}_i) and salience (S(t)). These
metrics are computed under a pullback semantic metric derived from the
unembedding matrix, ensuring that all measurements reflect token-aligned
geometry rather than raw coordinate structure. We find that concern-shifted
prompts reliably alter internal activation trajectories in both models - with
LLaMA exhibiting consistent, statistically significant scaling in both
curvature and salience as concern intensity increases. Gemma also responds to
concern but shows weaker differentiation between moderate and strong variants.
Our results support a two-layer view of LLM geometry - a latent conceptual
structure encoded in the embedding space, and a contextual trajectory shaped by
prompt-specific inference. Curved Inference reveals how models navigate,
reorient, or reinforce semantic meaning over depth, offering a principled
method for diagnosing alignment, abstraction, and emergent inference dynamics.
These findings offer fresh insight into semantic abstraction and model
alignment through the lens of Curved Inference.

</details>


### [104] [A Survey of Classification Tasks and Approaches for Legal Contracts](https://arxiv.org/abs/2507.21108)
*Amrita Singh,Aditya Joshi,Jiaojiao Jiang,Hye-young Paik*

Main category: cs.CL

TL;DR: 本文综述了自动法律合同分类中的挑战、关键任务、数据集和方法，提出未来研究方向以改进法律合同分类的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 鉴于合同的规模、数量及其内在复杂性，人工审查变得低效且容易出错，因此需要自动化。自动法律合同分类（LCC）能够显著提高分析速度、准确性和可访问性。

Method: 本文介绍了一种分类法律合同的方法论分类，包括传统机器学习、深度学习和基于Transformer的方法，并探讨了评估技术以及最佳表现结果。

Result: 本文识别了法律合同分类中的七个分类任务，审查了十四个英文合同相关的数据集，并提供了当前方法及其局限性的全面概览，并建议了未来的研究方向以提高法律合同分类的效率、准确性和可扩展性。

Conclusion: 本文作为首个全面的法律合同分类自动化综述，旨在支持法律自然语言处理研究人员和从业者改进法律程序，提高法律信息的可访问性，促进一个更知情和公平的社会。

Abstract: Given the large size and volumes of contracts and their underlying inherent
complexity, manual reviews become inefficient and prone to errors, creating a
clear need for automation. Automatic Legal Contract Classification (LCC)
revolutionizes the way legal contracts are analyzed, offering substantial
improvements in speed, accuracy, and accessibility. This survey delves into the
challenges of automatic LCC and a detailed examination of key tasks, datasets,
and methodologies. We identify seven classification tasks within LCC, and
review fourteen datasets related to English-language contracts, including
public, proprietary, and non-public sources. We also introduce a methodology
taxonomy for LCC, categorized into Traditional Machine Learning, Deep Learning,
and Transformer-based approaches. Additionally, the survey discusses evaluation
techniques and highlights the best-performing results from the reviewed
studies. By providing a thorough overview of current methods and their
limitations, this survey suggests future research directions to improve the
efficiency, accuracy, and scalability of LCC. As the first comprehensive survey
on LCC, it aims to support legal NLP researchers and practitioners in improving
legal processes, making legal information more accessible, and promoting a more
informed and equitable society.

</details>


### [105] [SemRAG: Semantic Knowledge-Augmented RAG for Improved Question-Answering](https://arxiv.org/abs/2507.21110)
*Kezhen Zhong,Basem Suleiman,Abdelkarim Erradi,Shijing Chen*

Main category: cs.CL

TL;DR: SemRAG是一种高效集成领域特定知识的RAG框架，通过语义分块和知识图谱改善性能，无需繁琐微调，且在实验中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 将领域特定知识整合到大型语言模型中以提高其在专业任务中的表现是至关重要的。然而，现有的方法计算量大，易于过拟合，且限制了可扩展性。SemRAG旨在解决这些挑战。

Method: SemRAG使用语义分块算法和知识图谱来整合领域特定知识。其中，语义分块算法基于句子嵌入的余弦相似性对文档进行分段，以保留语义一致性并减少计算开销。同时，通过将检索到的信息构造成知识图谱，改进了实体之间关系的表示，从而提高了检索准确性和上下文理解。

Result: 实验结果显示，SemRAG在MultiHop RAG和Wikipedia数据集上显著增强了从知识图谱中检索信息的相关性和正确性，超越传统的RAG方法。此外，研究表明，为特定数据集优化缓冲区大小可以进一步提升检索性能。

Conclusion: SemRAG提供了一种高效且可扩展的方法，将领域特定知识整合到大型语言模型中，而无需资源密集型的微调。这使其成为领域特定领域AI应用的实用解决方案。

Abstract: This paper introduces SemRAG, an enhanced Retrieval Augmented Generation
(RAG) framework that efficiently integrates domain-specific knowledge using
semantic chunking and knowledge graphs without extensive fine-tuning.
Integrating domain-specific knowledge into large language models (LLMs) is
crucial for improving their performance in specialized tasks. Yet, existing
adaptations are computationally expensive, prone to overfitting and limit
scalability. To address these challenges, SemRAG employs a semantic chunking
algorithm that segments documents based on the cosine similarity from sentence
embeddings, preserving semantic coherence while reducing computational
overhead. Additionally, by structuring retrieved information into knowledge
graphs, SemRAG captures relationships between entities, improving retrieval
accuracy and contextual understanding. Experimental results on MultiHop RAG and
Wikipedia datasets demonstrate SemRAG has significantly enhances the relevance
and correctness of retrieved information from the Knowledge Graph,
outperforming traditional RAG methods. Furthermore, we investigate the
optimization of buffer sizes for different data corpus, as optimizing buffer
sizes tailored to specific datasets can further improve retrieval performance,
as integration of knowledge graphs strengthens entity relationships for better
contextual comprehension. The primary advantage of SemRAG is its ability to
create an efficient, accurate domain-specific LLM pipeline while avoiding
resource-intensive fine-tuning. This makes it a practical and scalable approach
aligned with sustainability goals, offering a viable solution for AI
applications in domain-specific fields.

</details>


### [106] [InsurTech innovation using natural language processing](https://arxiv.org/abs/2507.21112)
*Panyi Dong,Zhiyu Quan*

Main category: cs.CL

TL;DR: This paper explores NLP's role in transforming insurance operations by converting unstructured text into structured data, enhancing actuarial analysis with enriched insights and novel risk assessments.


<details>
  <summary>Details</summary>
Motivation: With InsurTech's rapid rise, traditional insurance companies need to leverage advanced technologies and alternative data sources to maintain a competitive edge.

Method: The paper applies various NLP techniques to transform unstructured text into structured data, using case studies and alternative real-world data provided by InsurTech partners.

Result: NLP techniques provide enriched insights that refine traditional rating factors and offer new perspectives for assessing risk, proving NLP as a foundational element for modern insurance analytics.

Conclusion: NLP enriches traditional insurance data sources by transforming unstructured text into structured data, enhancing the accuracy and depth of actuarial analysis and decision-making.

Abstract: With the rapid rise of InsurTech, traditional insurance companies are
increasingly exploring alternative data sources and advanced technologies to
sustain their competitive edge. This paper provides both a conceptual overview
and practical case studies of natural language processing (NLP) and its
emerging applications within insurance operations with a focus on transforming
raw, unstructured text into structured data suitable for actuarial analysis and
decision-making. Leveraging real-world alternative data provided by an
InsurTech industry partner that enriches traditional insurance data sources, we
apply various NLP techniques to demonstrate practical use cases in the
commercial insurance context. These enriched, text-derived insights not only
add to and refine traditional rating factors for commercial insurance pricing
but also offer novel perspectives for assessing underlying risk by introducing
novel industry classifications. Through these demonstrations, we show that NLP
is not merely a supplementary tool but a foundational element for modern,
data-driven insurance analytics.

</details>


### [107] [TRIDENT: Benchmarking LLM Safety in Finance, Medicine, and Law](https://arxiv.org/abs/2507.21134)
*Zheng Hui,Yijiang River Dong,Ehsan Shareghi,Nigel Collier*

Main category: cs.CL

TL;DR: 本研究通过创建Trident-Bench，揭示LLM在高风险领域中的安全性缺陷，并为未来领域特定安全研究提供了基础。


<details>
  <summary>Details</summary>
Motivation: 现有的工作虽然提升了LLM在领域中的表现，但对领域特定的安全风险评估有所忽略。

Method: 引入了一个名为Trident-Bench的基准测试，专门针对法律、金融和医学领域的LLM安全性。

Result: 评估了19个通用和领域专用模型，发现尽管强大的通用模型可以满足基本期望，但领域专用模型在处理细微的伦理问题时往往表现不佳。

Conclusion: 强调需要针对领域特定的安全性进行更细致的改进，为进一步研究奠定了基础。

Abstract: As large language models (LLMs) are increasingly deployed in high-risk
domains such as law, finance, and medicine, systematically evaluating their
domain-specific safety and compliance becomes critical. While prior work has
largely focused on improving LLM performance in these domains, it has often
neglected the evaluation of domain-specific safety risks. To bridge this gap,
we first define domain-specific safety principles for LLMs based on the AMA
Principles of Medical Ethics, the ABA Model Rules of Professional Conduct, and
the CFA Institute Code of Ethics. Building on this foundation, we introduce
Trident-Bench, a benchmark specifically targeting LLM safety in the legal,
financial, and medical domains. We evaluated 19 general-purpose and
domain-specialized models on Trident-Bench and show that it effectively reveals
key safety gaps -- strong generalist models (e.g., GPT, Gemini) can meet basic
expectations, whereas domain-specialized models often struggle with subtle
ethical nuances. This highlights an urgent need for finer-grained
domain-specific safety improvements. By introducing Trident-Bench, our work
provides one of the first systematic resources for studying LLM safety in law
and finance, and lays the groundwork for future research aimed at reducing the
safety risks of deploying LLMs in professionally regulated fields. Code and
benchmark will be released at: https://github.com/zackhuiiiii/TRIDENT

</details>


### [108] [TTS-1 Technical Report](https://arxiv.org/abs/2507.21138)
*Oleg Atamanenko,Anna Chalova,Joseph Coombes,Nikki Cope,Phillip Dang,Zhifeng Deng,Jimmy Du,Michael Ermolenko,Feifan Fan,Yufei Feng,Cheryl Fichter,Pavel Filimonov,Louis Fischer,Kylan Gibbs,Valeria Gusarova,Pavel Karpik,Andreas Assad Kottner,Ian Lee,Oliver Louie,Jasmine Mai,Mikhail Mamontov,Suri Mao,Nurullah Morshed,Igor Poletaev,Florin Radu,Dmytro Semernia,Evgenii Shingarev,Vikram Sivaraja,Peter Skirko,Rinat Takhautdinov,Robert Villahermosa,Jean Wang*

Main category: cs.CL

TL;DR: 介绍了Inworld TTS-1和TTS-1-Max两款高性能文本到语音转换模型，具有出色的质量和实时性能，支持多语言和情感控制，并已开源。


<details>
  <summary>Details</summary>
Motivation: 引入一种新的TTS模型，以实现高质量和高效的文本-语音转换。

Method: 使用Transformer架构，经过预训练、微调和强化学习调整，进行模型开发。

Result: 模型达到了多个基准测试的最佳性能，能够生成高分辨率、低延迟的语音，并支持多种语言和情感控制。

Conclusion: Inworld TTS-1系列模型提供了极高的语音生成质量和效率，是当前最先进的TTS解决方案之一。

Abstract: We introduce Inworld TTS-1, a set of two Transformer-based autoregressive
text-to-speech (TTS) models. Our largest model, TTS-1-Max, has 8.8B parameters
and is designed for utmost quality and expressiveness in demanding
applications. TTS-1 is our most efficient model, with 1.6B parameters, built
for real-time speech synthesis and on-device use cases. By scaling train-time
compute and applying a sequential process of pre-training, fine-tuning, and
RL-alignment of the speech-language model (SpeechLM) component, both models
achieve state-of-the-art performance on a variety of benchmarks, demonstrating
exceptional quality relying purely on in-context learning of the speaker's
voice. Inworld TTS-1 and TTS-1-Max can generate high-resolution 48 kHz speech
with low latency, and support 11 languages with fine-grained emotional control
and non-verbal vocalizations through audio markups. We additionally open-source
our training and modeling code under an MIT license.

</details>


### [109] [Diverse LLMs or Diverse Question Interpretations? That is the Ensembling Question](https://arxiv.org/abs/2507.21168)
*Rafael Rosales,Santiago Miret*

Main category: cs.CL

TL;DR: 该研究比较了两种多样性方法在回答二元问题中的效果，结果显示问题解释多样性优于模型多样性。


<details>
  <summary>Details</summary>
Motivation: 探索最有效地利用多样性的方法，以提高大型语言模型的表现。

Method: 比较两种多样性方法：模型多样性和问题解释多样性，并通过多数投票法确定最终答案。

Result: 在boolq, strategyqa和pubmedqa的实验中，问题解释多样性在集合准确性方面比模型多样性表现更好。

Conclusion: 对二元问题的回答中，问题解释多样性优于模型多样性。

Abstract: Effectively leveraging diversity has been shown to improve performance for
various machine learning models, including large language models (LLMs).
However, determining the most effective way of using diversity remains a
challenge. In this work, we compare two diversity approaches for answering
binary questions using LLMs: model diversity, which relies on multiple models
answering the same question, and question interpretation diversity, which
relies on using the same model to answer the same question framed in different
ways. For both cases, we apply majority voting as the ensemble consensus
heuristic to determine the final answer. Our experiments on boolq, strategyqa,
and pubmedqa show that question interpretation diversity consistently leads to
better ensemble accuracy compared to model diversity. Furthermore, our analysis
of GPT and LLaMa shows that model diversity typically produces results between
the best and the worst ensemble members without clear improvement.

</details>


### [110] [StructText: A Synthetic Table-to-Text Approach for Benchmark Generation with Multi-Dimensional Evaluation](https://arxiv.org/abs/2507.21340)
*Satyananda Kashyap,Sola Shirai,Nandana Mihindukulasooriya,Horst Samulowitz*

Main category: cs.CL

TL;DR: StructText框架自动生成高保真基准提升文本信息提取，通过LLM评估示例表现，结果显示叙述连贯性不足影响信息自动化提取。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型缺乏在特定领域或组织专属文档的提取质量评估基准，而人工标注基准资源费时费力且难以扩展。

Method: 采用端到端框架StructText，利用现有表格数据，进行计划-执行两阶段流水线合成自然语言文本，并引入多维评估策略。

Result: 在49个数据集的71,539个示例中进行评估，结果表明LLMs在生成可提取文本方面虽具备高事实准确性，但在叙述连贯性上表现较弱。数值和时间信息虽嵌入叙述中，但难以实现自动化提取。

Conclusion: LLMs exhibit strong factual accuracy and avoid hallucination, but struggle with narrative coherence for key-value extraction.

Abstract: Extracting structured information from text, such as key-value pairs that
could augment tabular data, is quite useful in many enterprise use cases.
Although large language models (LLMs) have enabled numerous automated pipelines
for converting natural language into structured formats, there is still a lack
of benchmarks for evaluating their extraction quality, especially in specific
domains or focused documents specific to a given organization. Building such
benchmarks by manual annotations is labour-intensive and limits the size and
scalability of the benchmarks. In this work, we present StructText, an
end-to-end framework for automatically generating high-fidelity benchmarks for
key-value extraction from text using existing tabular data. It uses available
tabular data as structured ground truth, and follows a two-stage
``plan-then-execute'' pipeline to synthetically generate corresponding
natural-language text. To ensure alignment between text and structured source,
we introduce a multi-dimensional evaluation strategy that combines (a)
LLM-based judgments on factuality, hallucination, and coherence and (b)
objective extraction metrics measuring numeric and temporal accuracy. We
evaluated the proposed method on 71,539 examples across 49 datasets. Results
reveal that while LLMs achieve strong factual accuracy and avoid hallucination,
they struggle with narrative coherence in producing extractable text. Notably,
models presume numerical and temporal information with high fidelity yet this
information becomes embedded in narratives that resist automated extraction. We
release a framework, including datasets, evaluation tools, and baseline
extraction systems, to support continued research.

</details>


### [111] [Contrast-CAT: Contrasting Activations for Enhanced Interpretability in Transformer-based Text Classifiers](https://arxiv.org/abs/2507.21186)
*Sungmin Han,Jeonghyun Lee,Sangkyun Lee*

Main category: cs.CL

TL;DR: 现有的变压器模型基于激活的归因方法存在问题，Contrast-CAT通过对比激活序列来优化解释，实验表明其表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 随着变压器在AI研究中的影响力增大，其决策解释变得越来越重要，尤其是在分类等较简单任务中。现有的基于激活的归因方法可能受到无关特征的影响，导致解释不可靠。

Method: 提出Contrast-CAT，一种新颖的激活对比归因方法，通过过滤掉类别无关特征来优化token级归因。通过将输入序列的激活与参考激活进行对比，生成更清晰、更可信的归因图。

Result: 在多个数据集和模型上的实验结果表明，Contrast-CAT的表现优于目前最先进的方法。在MoRF设置下，其在AOPC和LOdds指标上的平均提升分别为x1.30和x2.25。

Conclusion: Contrast-CAT在增强变压器基础的文本分类模型可解释性方面表现出色，优于其他先进方法。

Abstract: Transformers have profoundly influenced AI research, but explaining their
decisions remains challenging -- even for relatively simpler tasks such as
classification -- which hinders trust and safe deployment in real-world
applications. Although activation-based attribution methods effectively explain
transformer-based text classification models, our findings reveal that these
methods can be undermined by class-irrelevant features within activations,
leading to less reliable interpretations. To address this limitation, we
propose Contrast-CAT, a novel activation contrast-based attribution method that
refines token-level attributions by filtering out class-irrelevant features. By
contrasting the activations of an input sequence with reference activations,
Contrast-CAT generates clearer and more faithful attribution maps. Experimental
results across various datasets and models confirm that Contrast-CAT
consistently outperforms state-of-the-art methods. Notably, under the MoRF
setting, it achieves average improvements of x1.30 in AOPC and x2.25 in LOdds
over the most competing methods, demonstrating its effectiveness in enhancing
interpretability for transformer-based text classification.

</details>


### [112] [Understanding Public Perception of Crime in Bangladesh: A Transformer-Based Approach with Explainability](https://arxiv.org/abs/2507.21234)
*Fatema Binte Hassan,Md Al Jubair,Mohammad Mehadi Hasan,Tahmid Hossain,S M Mehebubur Rahman Khan Shuvo,Mohammad Shamsul Arefin*

Main category: cs.CL

TL;DR: 研究利用transformer模型对孟加拉语社交评论进行情感分类，取得97%的准确率，可支持公共政策和犯罪预防。


<details>
  <summary>Details</summary>
Motivation: 研究社交媒体用户对犯罪相关新闻的看法，以识别这些看法随时间的动态变化。

Method: 提出了一种基于transformer的模型，采用XLM-RoBERTa Base架构进行分类，并应用可解释AI技术提高模型可解释性。

Result: XLM-RoBERTa Base模型实现了97%的分类准确率，优于现有的孟加拉语情感分析方法，并成功识别出影响情感分类的重要特征。

Conclusion: 这项研究通过使用XLM-RoBERTa模型成功地将孟加拉语的社交媒体评论分为正、负、中立三类，实现了97%的分类准确率，表明该方法在处理低资源语言的效果显著。

Abstract: In recent years, social media platforms have become prominent spaces for
individuals to express their opinions on ongoing events, including criminal
incidents. As a result, public sentiment can shift dynamically over time. This
study investigates the evolving public perception of crime-related news by
classifying user-generated comments into three categories: positive, negative,
and neutral. A newly curated dataset comprising 28,528 Bangla-language social
media comments was developed for this purpose. We propose a transformer-based
model utilizing the XLM-RoBERTa Base architecture, which achieves a
classification accuracy of 97%, outperforming existing state-of-the-art methods
in Bangla sentiment analysis. To enhance model interpretability, explainable AI
technique is employed to identify the most influential features driving
sentiment classification. The results underscore the effectiveness of
transformer-based models in processing low-resource languages such as Bengali
and demonstrate their potential to extract actionable insights that can support
public policy formulation and crime prevention strategies.

</details>


### [113] [Bangla BERT for Hyperpartisan News Detection: A Semi-Supervised and Explainable AI Approach](https://arxiv.org/abs/2507.21242)
*Mohammad Mehadi Hasan,Fatema Binte Hassan,Md Al Jubair,Zobayer Ahmed,Sazzatul Yeakin,Md Masum Billah*

Main category: cs.CL

TL;DR: 通过微调Bangla BERT模型，该研究提高了孟加拉语高度政治党派新闻的分类准确性，取得了95.65%的准确率，证明了变压器模型在资源有限环境中的有效性。


<details>
  <summary>Details</summary>
Motivation: 在当前数字环境中，错误信息传播迅速，影响公众认知并导致社会分裂。辨识孟加拉语中的高度政治党派新闻十分困难，因为缺乏成熟的自然语言处理方法。

Method: 研究通过微调Bangla BERT（一种先进的基于Transformer的模型）来提高孟加拉语高度政治党派新闻的分类准确性。与传统机器学习模型进行性能比较，并实施半监督学习以进一步提升预测效果。同时使用LIME提供模型决策过程的透明解释。

Result: Bangla BERT在试验数据中表现出95.65%的显著准确率，超越传统方法。研究结果证明了变压器模型在资源有限的环境中的有效性。

Conclusion: 研究表明，在资源有限的环境中，变压器模型具有实用性，并为该领域的进一步改进打开了大门。

Abstract: In the current digital landscape, misinformation circulates rapidly, shaping
public perception and causing societal divisions. It is difficult to identify
hyperpartisan news in Bangla since there aren't many sophisticated natural
language processing methods available for this low-resource language. Without
effective detection methods, biased content can spread unchecked, posing
serious risks to informed discourse. To address this gap, our research
fine-tunes Bangla BERT. This is a state-of-the-art transformer-based model,
designed to enhance classification accuracy for hyperpartisan news. We evaluate
its performance against traditional machine learning models and implement
semi-supervised learning to enhance predictions further. Not only that, we use
LIME to provide transparent explanations of the model's decision-making
process, which helps to build trust in its outcomes. With a remarkable accuracy
score of 95.65%, Bangla BERT outperforms conventional approaches, according to
our trial data. The findings of this study demonstrate the usefulness of
transformer models even in environments with limited resources, which opens the
door to further improvements in this area.

</details>


### [114] [Can human clinical rationales improve the performance and explainability of clinical text classification models?](https://arxiv.org/abs/2507.21302)
*Christoph Metzner,Shang Gao,Drahomira Herrmannova,Heidi A. Hanson*

Main category: cs.CL

TL;DR: 使用临床推理作为额外训练数据仅带来有限的性能提升，且在资源充足时效果更好。相比之下，使用额外的报告更能提高精度。但在可解释性上，若优先考虑解释性，结合推理的数据可能有助于识别推理特征。


<details>
  <summary>Details</summary>
Motivation: 探讨人类临床推理是否能够用于提高变换器模型在编码临床文档过程中的性能和可解释性。

Method: 通过分析99,125个人类临床推理样本，这些样本为主要癌症部位诊断提供合理解释，我们将其作为额外训练样本，与128,649份电子病理报告一起用于评估基于变换器的模型，以提取主要癌症部位。还研究了充分性作为衡量推理质量的指标，以用于预选推理。

Result: 在高资源场景中，临床推理作为额外训练数据可提高模型性能，但在资源有限时表现不稳定。使用充分性作为推理预选指标同样带来了不一致的结果。训练在推理上的模型在性能上不及在额外报告上训练的模型。结果表明，临床推理不一定能提高模型性能，反而不如直接使用更多报告进行训练。

Conclusion: 使用临床推理作为额外训练数据在性能提升上有限，与直接使用更多报告的效果相比略逊一筹。而在可解释性方面，基于推理的数据训练的模型在标识推理特征上略有改善。

Abstract: AI-driven clinical text classification is vital for explainable automated
retrieval of population-level health information. This work investigates
whether human-based clinical rationales can serve as additional supervision to
improve both performance and explainability of transformer-based models that
automatically encode clinical documents. We analyzed 99,125 human-based
clinical rationales that provide plausible explanations for primary cancer site
diagnoses, using them as additional training samples alongside 128,649
electronic pathology reports to evaluate transformer-based models for
extracting primary cancer sites. We also investigated sufficiency as a way to
measure rationale quality for pre-selecting rationales. Our results showed that
clinical rationales as additional training data can improve model performance
in high-resource scenarios but produce inconsistent behavior when resources are
limited. Using sufficiency as an automatic metric to preselect rationales also
leads to inconsistent results. Importantly, models trained on rationales were
consistently outperformed by models trained on additional reports instead. This
suggests that clinical rationales don't consistently improve model performance
and are outperformed by simply using more reports. Therefore, if the goal is
optimizing accuracy, annotation efforts should focus on labeling more reports
rather than creating rationales. However, if explainability is the priority,
training models on rationale-supplemented data may help them better identify
rationale-like features. We conclude that using clinical rationales as
additional training data results in smaller performance improvements and only
slightly better explainability (measured as average token-level rationale
coverage) compared to training on additional reports.

</details>


### [115] [Do Large Language Models Understand Morality Across Cultures?](https://arxiv.org/abs/2507.21319)
*Hadi Mohammadi,Yasmeen F. S. S. Meijer,Efthymia Papadopoulou,Ayoub Bagheri*

Main category: cs.CL

TL;DR: LLMs虽然功能强大，但在跨文化道德上表现出偏见，难以再现全球道德差异。


<details>
  <summary>Details</summary>
Motivation: LLMs在许多领域已成为强大工具，但由于其训练数据存在嵌入偏见（如性别、种族和文化偏见），对这些技术的伦理使用和社会后果提出了重要问题。为了探讨LLMs在道德观念的跨文化差异和相似性方面的表现，该研究开展了此调查。

Method: 使用三种互补的方法：（1）比较模型产生的道德分数与调查报告中道德分数的差异，（2）进行集群对齐分析以评估LLM输出和调查数据来源国家分组之间的对应关系，以及（3）使用系统选择的标记对直接探测模型进行比较提示。

Result: 研究结果显示，目前的LLMs经常无法再现跨文化道德变异的完整谱系，倾向于压缩差异并表现出与实证调查模式的低对齐性。

Conclusion: 当前的LLMs往往无法再现跨文化道德差异的全部范围，表现出对差异的压缩以及与实证调查模式的低匹配性。强调了需要更强大的方法来缓解偏见并提高LLMs的文化代表性。

Abstract: Recent advancements in large language models (LLMs) have established them as
powerful tools across numerous domains. However, persistent concerns about
embedded biases, such as gender, racial, and cultural biases arising from their
training data, raise significant questions about the ethical use and societal
consequences of these technologies. This study investigates the extent to which
LLMs capture cross-cultural differences and similarities in moral perspectives.
Specifically, we examine whether LLM outputs align with patterns observed in
international survey data on moral attitudes. To this end, we employ three
complementary methods: (1) comparing variances in moral scores produced by
models versus those reported in surveys, (2) conducting cluster alignment
analyses to assess correspondence between country groupings derived from LLM
outputs and survey data, and (3) directly probing models with comparative
prompts using systematically chosen token pairs. Our results reveal that
current LLMs often fail to reproduce the full spectrum of cross-cultural moral
variation, tending to compress differences and exhibit low alignment with
empirical survey patterns. These findings highlight a pressing need for more
robust approaches to mitigate biases and improve cultural representativeness in
LLMs. We conclude by discussing the implications for the responsible
development and global deployment of LLMs, emphasizing fairness and ethical
alignment.

</details>


### [116] [A Deep Learning Automatic Speech Recognition Model for Shona Language](https://arxiv.org/abs/2507.21331)
*Leslie Wellington Sirora,Mainford Mutandavari*

Main category: cs.CL

TL;DR: 研究开发了一种基于深度学习的绍纳语自动语音识别系统，通过混合架构和数据增强技术等手段，提高了语音识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决由于训练数据受限、标记数据不足和绍纳语音中复杂的音调差异带来的挑战，从而提高相较于传统统计模型的识别准确性。

Method: 采用卷积神经网络进行声学建模和长短时记忆网络进行语言建模的混合架构。数据增强技术和迁移学习用于解决数据稀缺问题，并引入注意力机制以适应绍纳语音的音调特性。

Result: 实现了令人印象深刻的结果，包括29%的词错误率、12%的音素错误率以及74%的总体准确率。

Conclusion: 研究表明深度学习可以显著提高低资源语言如绍纳语的语音识别精度。

Abstract: This study presented the development of a deep learning-based Automatic
Speech Recognition system for Shona, a low-resource language characterized by
unique tonal and grammatical complexities. The research aimed to address the
challenges posed by limited training data, lack of labelled data, and the
intricate tonal nuances present in Shona speech, with the objective of
achieving significant improvements in recognition accuracy compared to
traditional statistical models. The research first explored the feasibility of
using deep learning to develop an accurate ASR system for Shona. Second, it
investigated the specific challenges involved in designing and implementing
deep learning architectures for Shona speech recognition and proposed
strategies to mitigate these challenges. Lastly, it compared the performance of
the deep learning-based model with existing statistical models in terms of
accuracy. The developed ASR system utilized a hybrid architecture consisting of
a Convolutional Neural Network for acoustic modelling and a Long Short-Term
Memory network for language modelling. To overcome the scarcity of data, data
augmentation techniques and transfer learning were employed. Attention
mechanisms were also incorporated to accommodate the tonal nature of Shona
speech. The resulting ASR system achieved impressive results, with a Word Error
Rate of 29%, Phoneme Error Rate of 12%, and an overall accuracy of 74%. These
metrics indicated the potential of deep learning to enhance ASR accuracy for
under-resourced languages like Shona. This study contributed to the advancement
of ASR technology for under-resourced languages like Shona, ultimately
fostering improved accessibility and communication for Shona speakers
worldwide.

</details>


### [117] [Turbocharging Web Automation: The Impact of Compressed History States](https://arxiv.org/abs/2507.21369)
*Xiyue Zhu,Peng Tang,Haofu Liao,Srikar Appalaraju*

Main category: cs.CL

TL;DR: 提出了一种网页历史压缩器，通过压缩历史状态中最相关的信息，提高网页自动化的准确性，与基线相比提高了1.2-5.4%的准确率。


<details>
  <summary>Details</summary>
Motivation: 当前的网页自动化忽视了历史状态的重要性，而网页状态的信息往往冗长，导致输入序列过长且信息稀疏，影响了历史状态的有效利用。

Method: 使用历史压缩器模块从每个历史状态中提取与任务相关的信息，将其压缩成固定长度的简短表示。

Result: 实验表明，该方法在Mind2Web和WebLINX数据集上相较于没有历史输入的基线方法取得了1.2-5.4%的绝对准确率提升。

Conclusion: 我们提出了一种新的网页历史压缩器方法，通过利用历史状态来加速网页自动化。

Abstract: Language models have led to a leap forward in web automation. The current web
automation approaches take the current web state, history actions, and language
instruction as inputs to predict the next action, overlooking the importance of
history states. However, the highly verbose nature of web page states can
result in long input sequences and sparse information, hampering the effective
utilization of history states. In this paper, we propose a novel web history
compressor approach to turbocharge web automation using history states. Our
approach employs a history compressor module that distills the most
task-relevant information from each history state into a fixed-length short
representation, mitigating the challenges posed by the highly verbose history
states. Experiments are conducted on the Mind2Web and WebLINX datasets to
evaluate the effectiveness of our approach. Results show that our approach
obtains 1.2-5.4% absolute accuracy improvements compared to the baseline
approach without history inputs.

</details>


### [118] [MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations](https://arxiv.org/abs/2507.21428)
*Elias Lumer,Anmol Gulati,Vamse Kumar Subbiah,Pradeep Honaganahalli Basavaraju,James A. Burke*

Main category: cs.CL

TL;DR: MemTool框架增强LLM在多轮对话中动态管理工具能力，提供三种代理模式用于优化任务准确性及工具移除效率。


<details>
  <summary>Details</summary>
Motivation: 固定的上下文窗口限制了在多轮交互中独立使用工具的效果，因此需要一种能够在多轮对话中动态管理工具或MCP服务器上下文的框架。

Method: 提出了MemTool这个短期记忆框架，并设计了三种代理架构：自主代理模式、工作流模式以及混合模式，并在ScaleMCP基准测试上对其进行实验，以测量工具移除效率及任务完成准确性。

Result: 在自主代理模式下，推理LLM能达到较高工具移除效率（90-94%的3窗口平均值），而中型模型的效率则较低（0-60%）。工作流和混合模式在工具移除上表现一致，而自主和混合模式在任务完成上表现优异。

Conclusion: MemTool框架能够有效地管理多轮对话中的工具与MCP服务器的上下文，提供了不同模式下的任务准确性、代理性和模型能力的权衡与建议。

Abstract: Large Language Model (LLM) agents have shown significant autonomous
capabilities in dynamically searching and incorporating relevant tools or Model
Context Protocol (MCP) servers for individual queries. However, fixed context
windows limit effectiveness in multi-turn interactions requiring repeated,
independent tool usage. We introduce MemTool, a short-term memory framework
enabling LLM agents to dynamically manage tools or MCP server contexts across
multi-turn conversations. MemTool offers three agentic architectures: 1)
Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow
Mode, providing deterministic control without autonomy, and 3) Hybrid Mode,
combining autonomous and deterministic control. Evaluating each MemTool mode
across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100
consecutive user interactions, measuring tool removal ratios (short-term memory
efficiency) and task completion accuracy. In Autonomous Agent Mode, reasoning
LLMs achieve high tool-removal efficiency (90-94% over a 3-window average),
while medium-sized models exhibit significantly lower efficiency (0-60%).
Workflow and Hybrid modes consistently manage tool removal effectively, whereas
Autonomous and Hybrid modes excel at task completion. We present trade-offs and
recommendations for each MemTool mode based on task accuracy, agency, and model
capabilities.

</details>


### [119] [Towards Locally Deployable Fine-Tuned Causal Large Language Models for Mode Choice Behaviour](https://arxiv.org/abs/2507.21432)
*Tareq Alsaleh,Bilal Farooq*

Main category: cs.CL

TL;DR: 研究引入LiTransMC，首次用于旅行模式选择预测，通过微调策略提升准确性并支持交通研究和政策制定。


<details>
  <summary>Details</summary>
Motivation: 探索开放访问和本地可部署的因果大型语言模型（LLMs）在旅行模式选择预测中的应用，并引入LiTransMC，这是首次为此任务开发的微调因果LLM。

Method: 系统比较了11个不同不模型（1-12B参数），使用参数效率和损失掩蔽策略进行微调，并采用BERTopic进行主题建模以及新颖的解释强度指数（Explanation Strength Index）进行模型生成推理评估。

Result: LiTransMC模型实现了加权F1评分0.6845和Jensen-Shannon Divergence 0.000245，超越了未调优的本地模型和包括GPT-4o在内的较大专有系统，同时在相同数据集上优于经典模式选择方法如离散选择模型和机器学习分类器。

Conclusion: 展示了创建专门的、本地可部署的LLMs的可行性，将预测与可解释性结合并支持基于代理的模拟、政策测试以及行为洞察生成。

Abstract: This study investigates the adoption of open-access, locally deployable
causal large language models (LLMs) for travel mode choice prediction and
introduces LiTransMC, the first fine-tuned causal LLM developed for this task.
We systematically benchmark eleven LLMs (1-12B parameters) across three stated
and revealed preference datasets, testing 396 configurations and generating
over 79,000 synthetic commuter predictions. Beyond predictive accuracy, we
evaluate models generated reasoning using BERTopic for topic modelling and a
novel Explanation Strength Index, providing the first structured analysis of
how LLMs articulate decision factors in alignment with behavioural theory.
LiTransMC, fine-tuned using parameter efficient and loss masking strategy,
achieved a weighted F1 score of 0.6845 and a Jensen-Shannon Divergence of
0.000245, surpassing both untuned local models and larger proprietary systems,
including GPT-4o with advanced persona inference and embedding-based loading,
while also outperforming classical mode choice methods such as discrete choice
models and machine learning classifiers for the same dataset. This dual
improvement, i.e., high instant-level accuracy and near-perfect distributional
calibration, demonstrates the feasibility of creating specialist, locally
deployable LLMs that integrate prediction and interpretability. Through
combining structured behavioural prediction with natural language reasoning,
this work unlocks the potential for conversational, multi-task transport models
capable of supporting agent-based simulations, policy testing, and behavioural
insight generation. These findings establish a pathway for transforming general
purpose LLMs into specialized, explainable tools for transportation research
and policy formulation, while maintaining privacy, reducing cost, and
broadening access through local deployment.

</details>


### [120] [Which LLMs Get the Joke? Probing Non-STEM Reasoning Abilities with HumorBench](https://arxiv.org/abs/2507.21476)
*Reuben Narad,Siddharth Suresh,Jiayi Chen,Pine S. L. Dysart-Bricken,Bob Mankoff,Robert Nowak,Jifan Zhang,Lalit Jain*

Main category: cs.CL

TL;DR: HumorBench是一个旨在评估大型语言模型在漫画字幕中解释幽默能力的基准，模型在STEM推理中取得的进展能够很好地转移到幽默理解中。


<details>
  <summary>Details</summary>
Motivation: 当前的推理模型在数学和科学领域已经达到了饱和状态，因此需要在STEM以外的领域进行新的和具有挑战性的评估，以考察模型的智能水平。幽默的文本理解涉及推理能力，需要识别漫画或字幕中的概念与外部文化参考、文字游戏以及其他机制之间的联系。

Method: HumorBench 包含了大约300个来自纽约客字幕竞赛和Cartoonstock.com的独特漫画字幕对，并且由专家标注的评估标准识别关键笑话元素。通过模型在幽默解释和识别笑话元素方面的表现进行评估。

Result: 当前最先进的模型的广泛基准测试揭示了三个关键见解：1）LLM在STEM推理的进展有效地转移到幽默理解中；2）仅接受过STEM推理数据训练的模型在HumorBench上的表现也很好，表明推理能力的强大可转移性；3) 通过增加考虑令牌预算进行测试时间缩放在幽默推理方面的作用在不同模型之间结果不一。

Conclusion: 幽默理解代表了对模型智能的一个新的和令人兴奋的评估方向，特别是在STEM领域以外，当前的推理能力能够较好地迁移到幽默理解。

Abstract: We present HumorBench, a benchmark designed to evaluate large language
models' (LLMs) ability to reason about and explain sophisticated humor in
cartoon captions. As reasoning models increasingly saturate existing benchmarks
in mathematics and science, novel and challenging evaluations of model
intelligence beyond STEM domains are essential. Reasoning is fundamentally
involved in text-based humor comprehension, requiring the identification of
connections between concepts in cartoons/captions and external cultural
references, wordplays, and other mechanisms. HumorBench includes approximately
300 unique cartoon-caption pairs from the New Yorker Caption Contest and
Cartoonstock.com, with expert-annotated evaluation rubrics identifying
essential joke elements. LLMs are evaluated based on their explanations towards
the humor and abilities in identifying the joke elements. To perform well on
this task, models must form and test hypotheses about associations between
concepts, potentially backtracking from initial interpretations to arrive at
the most plausible explanation. Our extensive benchmarking of current SOTA
models reveals three key insights: (1) LLM progress on STEM reasoning transfers
effectively to humor comprehension; (2) models trained exclusively on STEM
reasoning data still perform well on HumorBench, demonstrating strong
transferability of reasoning abilities; and (3) test-time scaling by increasing
thinking token budgets yields mixed results across different models in humor
reasoning.

</details>


### [121] [Improving Task Diversity in Label Efficient Supervised Finetuning of LLMs](https://arxiv.org/abs/2507.21482)
*Abhinav Arabelly,Jagrut Nemade,Robert D Nowak,Jifan Zhang*

Main category: cs.CL

TL;DR: 通过任务多样性和置信度差异选择数据，提高模型性能并降低标注成本。


<details>
  <summary>Details</summary>
Motivation: 开发高性能的模型需要大量人工注释，为了减少时间和成本，提出了一种标签高效学习的问题解决方案。

Method: 利用逆向置信度赋权策略从不同任务中选择示例，以提高监督微调的效率。

Result: 实验结果表明这种方法能够比使用完整数据集训练的模型取得更好的准确性，提高MMLU得分4%。在各种标注预算和两个指令微调数据集上，算法表现与现有最佳方法持平或更好，同时减少了最多80%的标注成本。

Conclusion: 本文提出了一种基于任务多样性的数据选择策略，通过逆向置信度赋权的方法进行示例选择，能够在减少标注成本的同时实现与复杂采样程序相媲美或更好的模型表现。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across
diverse domains, but developing high-performing models for specialized
applications often requires substantial human annotation -- a process that is
time-consuming, labor-intensive, and expensive. In this paper, we address the
label-efficient learning problem for supervised finetuning (SFT) by leveraging
task-diversity as a fundamental principle for effective data selection. This is
markedly different from existing methods based on the prompt-diversity. Our
approach is based on two key observations: 1) task labels for different prompts
are often readily available; 2) pre-trained models have significantly varying
levels of confidence across tasks. We combine these facts to devise a simple
yet effective sampling strategy: we select examples across tasks using an
inverse confidence weighting strategy. This produces models comparable to or
better than those trained with more complex sampling procedures, while being
significantly easier to implement and less computationally intensive. Notably,
our experimental results demonstrate that this method can achieve better
accuracy than training on the complete dataset (a 4\% increase in MMLU score).
Across various annotation budgets and two instruction finetuning datasets, our
algorithm consistently performs at or above the level of the best existing
methods, while reducing annotation costs by up to 80\%.

</details>


### [122] [VN-MTEB: Vietnamese Massive Text Embedding Benchmark](https://arxiv.org/abs/2507.21500)
*Loc Pham,Tung Luu,Thu Vo,Minh Nguyen,Viet Hoang*

Main category: cs.CL

TL;DR: 推出了VN-MTEB，专为越南文本嵌入设计，以解决测试数据集不足的问题，并发现旋转位置嵌入技术具有更好表现。


<details>
  <summary>Details</summary>
Motivation: 由于越南的互联网流量和在线毒性排名靠前，因此在应用程序中实施嵌入模型进行推荐和内容控制至关重要。然而，缺乏大规模的测试数据集阻碍了科学家在实际项目中有效评估AI模型。

Method: 使用大语言模型（LLMs）和顶尖嵌入模型进行翻译和过滤，以保留高质量样本，同时保证语言自然流畅和语义保真。

Result: 更大且更复杂的模型采用旋转位置嵌入技术在嵌入任务中表现优于绝对位置嵌入技术。

Conclusion: 开发了一个新的越南基准VN-MTEB来有效评估嵌入模型，解决了大规模测试数据集缺乏的问题。

Abstract: Vietnam ranks among the top countries in terms of both internet traffic and
online toxicity. As a result, implementing embedding models for recommendation
and content control duties in applications is crucial. However, a lack of
large-scale test datasets, both in volume and task diversity, makes it tricky
for scientists to effectively evaluate AI models before deploying them in
real-world, large-scale projects. To solve this important problem, we introduce
a Vietnamese benchmark, VN-MTEB for embedding models, which we created by
translating a large number of English samples from the Massive Text Embedding
Benchmark using our new automated framework. We leverage the strengths of large
language models (LLMs) and cutting-edge embedding models to conduct translation
and filtering processes to retain high-quality samples, guaranteeing a natural
flow of language and semantic fidelity while preserving named entity
recognition (NER) and code snippets. Our comprehensive benchmark consists of 41
datasets from six tasks specifically designed for Vietnamese text embeddings.
In our analysis, we find that bigger and more complex models using Rotary
Positional Embedding outperform those using Absolute Positional Embedding in
embedding tasks. Datasets are available at HuggingFace:
https://huggingface.co/collections/GreenNode/vn-mteb-68871433f0f7573b8e1a6686

</details>


### [123] [Persona Vectors: Monitoring and Controlling Character Traits in Language Models](https://arxiv.org/abs/2507.21509)
*Runjin Chen,Andy Arditi,Henry Sleight,Owain Evans,Jack Lindsey*

Main category: cs.CL

TL;DR: 该研究发现可以通过识别模型的激活空间中的人格向量来监控和控制助手的性格变化，并通过自动化方法标记训练数据中可能导致不良变化的数据。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型中的助手通常被训练成有帮助、无害和诚实的角色，但它有时会偏离这些理想。

Method: 该文通过识别模型激活空间中的人格向量，使用这些向量监控助手人格在部署时的波动，并预测和控制训练期间发生的人格转变。

Result: 发现拟调整和意外人格变化与相关人格向量的变化密切相关。通过事后干预或新的预防性引导方法可以减轻这些变化。

Conclusion: 可以使用人格向量标记会导致不良人格变化的训练数据，且该方法是自动化的，可应用于任何感兴趣的人格特质。

Abstract: Large language models interact with users through a simulated 'Assistant'
persona. While the Assistant is typically trained to be helpful, harmless, and
honest, it sometimes deviates from these ideals. In this paper, we identify
directions in the model's activation space-persona vectors-underlying several
traits, such as evil, sycophancy, and propensity to hallucinate. We confirm
that these vectors can be used to monitor fluctuations in the Assistant's
personality at deployment time. We then apply persona vectors to predict and
control personality shifts that occur during training. We find that both
intended and unintended personality changes after finetuning are strongly
correlated with shifts along the relevant persona vectors. These shifts can be
mitigated through post-hoc intervention, or avoided in the first place with a
new preventative steering method. Moreover, persona vectors can be used to flag
training data that will produce undesirable personality changes, both at the
dataset level and the individual sample level. Our method for extracting
persona vectors is automated and can be applied to any personality trait of
interest, given only a natural-language description.

</details>


### [124] [Model-free Speculative Decoding for Transformer-based ASR with Token Map Drafting](https://arxiv.org/abs/2507.21522)
*Tuan Vu Ho,Hiroaki Kokubo,Masaaki Yamamoto,Yohei Kawaguchi*

Main category: cs.CL

TL;DR: 提出了Token Map Drafting技术，显著加速在低困惑度领域中基于transformer的自动语音识别推理，而无需牺牲转录准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于transformer架构的端到端自动语音识别系统在解码过程中计算量大，限制了在CPU和资源受限设备上的部署，需要一个实用的方法来实现高效解码。

Method: 采用Token Map Drafting技术，通过使用来自领域特定训练数据的预计算n-gram词元映射，进行高效的推测解码，同时降低开销。

Result: 在CI-AVSR数据集上实现了1.27倍的解码速度提升，在内部数据集上实现了1.37倍的解码速度提升，并且在CPU上比Distill-spec基线提高了10%的解码速度，同时未降低识别准确性。

Conclusion: 提出了一种无需单独草稿模型的模型无关推测解码技术Token Map Drafting，能够在结构化低困惑领域中显著加速ASR推理，并保持转录准确性。

Abstract: End-to-end automatic speech recognition (ASR) systems based on transformer
architectures, such as Whisper, offer high transcription accuracy and
robustness. However, their autoregressive decoding is computationally
expensive, hence limiting deployment on CPU-based and resource-constrained
devices. Speculative decoding (SD) mitigates this issue by using a smaller
draft model to propose candidate tokens, which are then verified by the main
model. However, this approach is impractical for devices lacking hardware
accelerators like GPUs. To address this, we propose \emph{Token Map Drafting},
a model-free SD technique that eliminates the need for a separate draft model.
Instead, we leverage a precomputed n-gram token map derived from
domain-specific training data, enabling efficient speculative decoding with
minimal overhead. Our method significantly accelerates ASR inference in
structured, low-perplexity domains without sacrificing transcription accuracy.
Experimental results demonstrate decoding speed-ups of $1.27\times$ on the
CI-AVSR dataset and $1.37\times$ on our internal dataset without degrading
recognition accuracy. Additionally, our approach achieves a $10\%$ absolute
improvement in decoding speed over the Distill-spec baseline running on CPU,
highlighting its effectiveness for on-device ASR applications.

</details>


### [125] [TriangleMix: A Lossless and Efficient Attention Pattern for Long Context Prefilling](https://arxiv.org/abs/2507.21526)
*Zhiyuan He,Yike Zhang,Chengruidong Zhang,Huiqiang Jiang,Yuqing Yang,Lili Qiu*

Main category: cs.CL

TL;DR: TriangleMix通过在深层采用三角形稀疏模式，显著降低了长序列下LLM的计算开销，加速了推理过程，而不影响模型准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的静态稀疏注意力方法通常会降低准确性，而动态稀疏方法由于运行时稀疏索引估计增加了额外的计算开销，导致了计算瓶颈。

Method: TriangleMix采用了一种无需训练的静态注意力模式，在浅层使用密集注意力，并在深层转换为三角形稀疏模式。

Result: TriangleMix在深层中将注意力开销减少了3.7倍至15.3倍，对序列长度从32K到128K的TTFT总体减少了12%到32%。在加速MInference方面，TriangleMix在128K时加速了19%。

Conclusion: TriangleMix显著减少了深层的注意力开销，并降低了长序列的总体TTFT，同时保持了模型的准确性。此外，TriangleMix能够与动态稀疏方法无缝结合，以实现进一步的加速。

Abstract: Large Language Models (LLMs) rely on attention mechanisms whose time
complexity grows quadratically with input sequence length, creating significant
computational bottlenecks during the prefilling stage. Existing static sparse
attention methods typically degrade accuracy, while dynamic sparsity methods
introduce additional computational overhead due to runtime sparse index
estimation. To address these limitations, we propose TriangleMix, a novel
training-free static attention pattern. TriangleMix employs dense attention in
shallow layers and switches to a triangle-shaped sparse pattern in deeper
layers. Extensive experiments demonstrate that TriangleMix reduces attention
overhead by 3.7x to 15.3x in deep layers, and decreases overall
Time-to-First-Token (TTFT) by 12% to 32% for sequence lengths ranging from 32K
to 128K, without sacrificing model accuracy. Moreover, TriangleMix can be
seamlessly integrated with dynamic sparsity methods to achieve further speedup,
e.g. accelerating MInference by 19% at 128K, highlighting its potential to
enhance LLM inference efficiency.

</details>


### [126] [Automatic Classification of User Requirements from Online Feedback -- A Replication Study](https://arxiv.org/abs/2507.21532)
*Meet Bhatt,Nic Boilard,Muhammad Rehan Chaudhary,Cole Thompson,Jacob Idoko,Aakash Sorathiya,Gouri Ginde*

Main category: cs.CL

TL;DR: 复制并扩展了用户需求从在线反馈中分类的研究，发现不同模型可重复性水平不同，GPT-4o表现与传统机器学习模型相当。


<details>
  <summary>Details</summary>
Motivation: 目前自然语言处理技术在需求工程领域应用广泛，但相关研究对复制NLP4RE研究的关注较少。为了验证和扩展之前的NLP4RE研究，我们决定复制并扩展一项基于小数据集的用户需求分类研究，以评估复制的有效性和扩展的潜力。

Method: 论文采用了深度学习模型进行用户反馈需求分类，并通过公开源码复现基线研究的结果，随后扩展研究设置，在外部数据集上评估模型性能，并与GPT-4o零样本分类器进行比较。

Result: 不同模型展示了多样化的可重复性水平，其中朴素贝叶斯表现出完美的可重复性，而BERT和其他模型则表现出混合结果。基线深度学习模型如BERT和ELMo在外部数据集上展现出良好的泛化能力，GPT-4o的性能与传统基线机器学习模型相当。此外，研究确认了基线研究的复制准备度，尽管缺少环境设置文件。

Conclusion: 本文成功复制并扩展了原始研究，揭示了各种模型的可重复性和泛化能力，为需求工程中的NLP研究提供了新的视角和结果。

Abstract: Natural language processing (NLP) techniques have been widely applied in the
requirements engineering (RE) field to support tasks such as classification and
ambiguity detection. Although RE research is rooted in empirical investigation,
it has paid limited attention to replicating NLP for RE (NLP4RE) studies. The
rapidly advancing realm of NLP is creating new opportunities for efficient,
machine-assisted workflows, which can bring new perspectives and results to the
forefront. Thus, we replicate and extend a previous NLP4RE study (baseline),
"Classifying User Requirements from Online Feedback in Small Dataset
Environments using Deep Learning", which evaluated different deep learning
models for requirement classification from user reviews. We reproduced the
original results using publicly released source code, thereby helping to
strengthen the external validity of the baseline study. We then extended the
setup by evaluating model performance on an external dataset and comparing
results to a GPT-4o zero-shot classifier. Furthermore, we prepared the
replication study ID-card for the baseline study, important for evaluating
replication readiness. Results showed diverse reproducibility levels across
different models, with Naive Bayes demonstrating perfect reproducibility. In
contrast, BERT and other models showed mixed results. Our findings revealed
that baseline deep learning models, BERT and ELMo, exhibited good
generalization capabilities on an external dataset, and GPT-4o showed
performance comparable to traditional baseline machine learning models.
Additionally, our assessment confirmed the baseline study's replication
readiness; however missing environment setup files would have further enhanced
readiness. We include this missing information in our replication package and
provide the replication study ID-card for our study to further encourage and
support the replication of our study.

</details>


### [127] [Modern Uyghur Dependency Treebank (MUDT): An Integrated Morphosyntactic Framework for a Low-Resource Language](https://arxiv.org/abs/2507.21536)
*Jiaxin Zuo,Yiquan Wang,Yuan Pan,Xiadiya Yibulayin*

Main category: cs.CL

TL;DR: 该研究针对维吾尔语引入了一个新的依赖注释框架，并通过实验验证了其有效性，从而显著提高解析准确性。


<details>
  <summary>Details</summary>
Motivation: 解决维吾尔语自然语言处理中的关键资源缺口，同时克服现有树库的局限性。

Method: 引入一个专门设计的依赖注释框架，并进行跨标准评估以验证其必要性。

Result: 分析显示注释存在系统性的47.9%的差异，揭示了现有通用方案在处理维吾尔语特定结构时的不足。通过九项注释原则提高了解析和后续NLP任务的准确性。

Conclusion: MUDT提供了一种更准确、语义透明表达的维吾尔语依赖注释树库，为其他形态复杂的语言提供可复制的模型。

Abstract: To address a critical resource gap in Uyghur Natural Language Processing
(NLP), this study introduces a dependency annotation framework designed to
overcome the limitations of existing treebanks for the low-resource,
agglutinative language. This inventory includes 18 main relations and 26
subtypes, with specific labels such as cop:zero for verbless clauses and
instr:case=loc/dat for nuanced instrumental functions. To empirically validate
the necessity of this tailored approach, we conducted a cross-standard
evaluation using a pre-trained Universal Dependencies parser. The analysis
revealed a systematic 47.9% divergence in annotations, pinpointing the
inadequacy of universal schemes for handling Uyghur-specific structures.
Grounded in nine annotation principles that ensure typological accuracy and
semantic transparency, the Modern Uyghur Dependency Treebank (MUDT) provides a
more accurate and semantically transparent representation, designed to enable
significant improvements in parsing and downstream NLP tasks, and offers a
replicable model for other morphologically complex languages.

</details>


### [128] [MAGIC: A Multi-Hop and Graph-Based Benchmark for Inter-Context Conflicts in Retrieval-Augmented Generation](https://arxiv.org/abs/2507.21544)
*Jungyeon Lee,Kangmin Lee,Taeuk Kim*

Main category: cs.CL

TL;DR: The paper introduces a KG-based framework to better understand and address knowledge conflicts in LLMs, revealing that current models struggle with conflict detection and resolution, and suggesting areas for improvement.


<details>
  <summary>Details</summary>
Motivation: Existing benchmarks for knowledge conflict in RAG systems have limitations, such as a narrow focus and restricted conflict types. The paper aims to address these issues with a more comprehensive framework.

Method: The paper proposes a knowledge graph (KG)-based framework to generate subtle conflicts between contexts, ensuring interpretability through the explicit relational structure of KGs. Experimental benchmarks are conducted using MAGIC.

Result: Experimental results show that both open-source and proprietary LLMs face challenges in conflict detection and often cannot find the exact contradictions.

Conclusion: LLMs struggle with detecting and resolving knowledge conflicts, particularly when multi-hop reasoning is required, highlighting the need for improvement in integrating diverse information.

Abstract: Knowledge conflict often arises in retrieval-augmented generation (RAG)
systems, where retrieved documents may be inconsistent with one another or
contradict the model's parametric knowledge. Existing benchmarks for
investigating the phenomenon have notable limitations, including a narrow focus
on the question answering setup, heavy reliance on entity substitution
techniques, and a restricted range of conflict types. To address these issues,
we propose a knowledge graph (KG)-based framework that generates varied and
subtle conflicts between two similar yet distinct contexts, while ensuring
interpretability through the explicit relational structure of KGs. Experimental
results on our benchmark, MAGIC, provide intriguing insights into the inner
workings of LLMs regarding knowledge conflict: both open-source and proprietary
models struggle with conflict detection -- especially when multi-hop reasoning
is required -- and often fail to pinpoint the exact source of contradictions.
Finally, we present in-depth analyses that serve as a foundation for improving
LLMs in integrating diverse, sometimes even conflicting, information.

</details>


### [129] [Evaluating the cognitive reality of Spanish irregular morphomic patterns: Humans vs. Transformers](https://arxiv.org/abs/2507.21556)
*Akhilesh Kakolu Ramarao,Kevin Tang,Dinah Baer-Henney*

Main category: cs.CL

TL;DR: 研究表明，Transformer模型在处理西班牙语不规则形态模式时在词干和词缀准确性上优于人类，但在响应偏好上有所不同，倾向于不规则响应，并受训练数据影响。


<details>
  <summary>Details</summary>
Motivation: 探讨Transformer模型是否能够在人类敏感的复杂语言现象——形态模式上表现出类似人类的敏感性。

Method: 使用与原始人类研究相同的分析框架，通过比较Transformer模型与人类行为数据进行研究。实验关注三种动词频率条件：自然、低频和高频不规则形态模式。

Result: 模型在词干和词缀准确性上表现优于人类，但在响应偏好上表现不同。与人类倾向自然响应不同，模型倾向不规则响应，并受训练数据中不规则动词比例的影响。此外，训练在自然和低频分布上的模型对测试项与真实西班牙语L形动词的语音相似性敏感。

Conclusion: Transformer模型在处理西班牙语不规则形态模式时，与人类行为数据存在显著差异，尤其是在对于不规则响应的偏好上。

Abstract: This study investigates the cognitive plausibility of the Spanish irregular
morphomic pattern by directly comparing transformer-based neural networks to
human behavioral data from \citet{Nevins2015TheRA}. Using the same analytical
framework as the original human study, we evaluate whether transformer models
can replicate human-like sensitivity to a complex linguistic phenomena, the
morphome, under controlled input conditions. Our experiments focus on three
frequency conditions: natural, low-frequency, and high-frequency distributions
of verbs exhibiting irregular morphomic patterns. While the models outperformed
humans in stem and suffix accuracy, a clear divergence emerged in response
preferences. Unlike humans, who consistently favored natural responses across
all test items, models' preferred irregular responses and were influenced by
the proportion of irregular verbs in their training data. Additionally, models
trained on the natural and low-frequency distributions, but not the
high-frequency distribution, were sensitive to the phonological similarity
between test items and real Spanish L-shaped verbs.

</details>


### [130] [Multi-Hypothesis Distillation of Multilingual Neural Translation Models for Low-Resource Languages](https://arxiv.org/abs/2507.21568)
*Aarón Galiano-Jiménez,Juan Antonio Pérez-Ortiz,Felipe Sánchez-Martínez,Víctor M. Sánchez-Cartagena*

Main category: cs.CL

TL;DR: 提出多假设蒸馏方法，通过多译文蒸馏改善模型性能和减少性别偏见。


<details>
  <summary>Details</summary>
Motivation: 探讨多语言预训练的编码-解码翻译模型的序列级知识蒸馏，希望通过教师模型的输出分布为学生模型提供更多见解。

Method: 本文提出了一种称为多假设蒸馏（MHD）的序列级蒸馏方法，通过为每个源句生成多个译文来扩展教师模型的分布表示。

Result: 研究表明，该方法在低资源语言中可以增强生成语料的多样性和词汇丰富度，改善学生模型性能，并减少性别偏见。

Conclusion: 本研究提出了一种新方法，通过生成多种译文，为学生模型提供更广泛的目标前缀范围，从而提高翻译质量和模型性能。

Abstract: This paper explores sequence-level knowledge distillation (KD) of
multilingual pre-trained encoder-decoder translation models. We argue that the
teacher model's output distribution holds valuable insights for the student,
beyond the approximated mode obtained through beam search (the standard
decoding method), and present Multi-Hypothesis Distillation (MHD), a
sequence-level KD method that generates multiple translations for each source
sentence. This provides a larger representation of the teacher model
distribution and exposes the student model to a wider range of target-side
prefixes. We leverage $n$-best lists from beam search to guide the student's
learning and examine alternative decoding methods to address issues like low
variability and the under-representation of infrequent tokens. For low-resource
languages, our research shows that while sampling methods may slightly
compromise translation quality compared to beam search based approaches, they
enhance the generated corpora with greater variability and lexical richness.
This ultimately improves student model performance and mitigates the gender
bias amplification often associated with KD.

</details>


### [131] [Multilingual JobBERT for Cross-Lingual Job Title Matching](https://arxiv.org/abs/2507.21609)
*Jens-Joris Decorte,Matthias De Lange,Jeroen Van Hautte*

Main category: cs.CL

TL;DR: JobBERT-V3 is a contrastive learning-based model for multilingual job title matching, outperforming existing benchmarks and capable of ranking relevant skills.


<details>
  <summary>Details</summary>
Motivation: Extend the capabilities of the JobBERT model to support multiple languages and improve job title matching across different languages.

Method: The model uses contrastive learning techniques on synthetic translations and a balanced multilingual dataset.

Result: JobBERT-V3 shows superior performance compared to existing multilingual models in TalentCLEF 2025 benchmark for both monolingual and cross-lingual settings.

Conclusion: JobBERT-V3 improves cross-lingual job title matching, outperforming existing models and applicable in multilingual labor market intelligence.

Abstract: We introduce JobBERT-V3, a contrastive learning-based model for cross-lingual
job title matching. Building on the state-of-the-art monolingual JobBERT-V2,
our approach extends support to English, German, Spanish, and Chinese by
leveraging synthetic translations and a balanced multilingual dataset of over
21 million job titles. The model retains the efficiency-focused architecture of
its predecessor while enabling robust alignment across languages without
requiring task-specific supervision. Extensive evaluations on the TalentCLEF
2025 benchmark demonstrate that JobBERT-V3 outperforms strong multilingual
baselines and achieves consistent performance across both monolingual and
cross-lingual settings. While not the primary focus, we also show that the
model can be effectively used to rank relevant skills for a given job title,
demonstrating its broader applicability in multilingual labor market
intelligence. The model is publicly available:
https://huggingface.co/TechWolf/JobBERT-v3.

</details>


### [132] [Libra: Assessing and Improving Reward Model by Learning to Think](https://arxiv.org/abs/2507.21645)
*Meng Zhou,Bei Li,Jiahao Liu,Xiaowen Shi,Yang Bai,Rongxiang Weng,Jingang Wang,Xunliang Cai*

Main category: cs.CL

TL;DR: 提出新的框架及奖励模型以改善强化学习语言模型在复杂推理场景中的表现，展示了无标签数据的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前的奖励模型在推理场景中表现不佳，主要的强化学习训练范式依赖于基于规则或参考的奖励，这限制了数据扩展和模型推理性能的持续提升。

Method: 提出一个包括 Libra Bench 基准和学习思维方法的综合框架用于评估和提高奖励模型在复杂推理场景中的性能。

Result: Libra-RM 系列奖励模型在多项基准上达到最先进的结果，并通过下游实验验证了 Libra Bench 与下游应用之间的关联性。

Conclusion: Libra-RM 系列生成奖励模型在多项基准上取得了最先进的结果，表明无标签数据可以进一步提升推理模型的性能。

Abstract: Reinforcement learning (RL) has significantly improved the reasoning ability
of large language models. However, current reward models underperform in
challenging reasoning scenarios and predominant RL training paradigms rely on
rule-based or reference-based rewards, which impose two critical limitations:
1) the dependence on finely annotated reference answer to attain rewards; and
2) the requirement for constrained output format. These limitations
fundamentally hinder further RL data scaling and sustained enhancement of model
reasoning performance. To address these limitations, we propose a comprehensive
framework for evaluating and improving the performance of reward models in
complex reasoning scenarios. We first present a reasoning-oriented benchmark
(Libra Bench), systematically constructed from a diverse collection of
challenging mathematical problems and advanced reasoning models, to address the
limitations of existing reward model benchmarks in reasoning scenarios. We
further introduce a novel approach for improving the generative reward model
via learning-to-think methodologies. Based on the proposed approach, we develop
Libra-RM series, a collection of generative reward models with reasoning
capabilities that achieve state-of-the-art results on various benchmarks.
Comprehensive downstream experiments are conducted and the experimental results
demonstrate the correlation between our Libra Bench and downstream application,
and the potential of Libra-RM to further improve reasoning models with
unlabeled data.

</details>


### [133] [UnsafeChain: Enhancing Reasoning Model Safety via Hard Cases](https://arxiv.org/abs/2507.21652)
*Raj Vardhan Tomar,Preslav Nakov,Yuxia Wang*

Main category: cs.CL

TL;DR: UnsafeChain通过纠正错误引导模型，由此提高安全性和推理能力，显著优于现有数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的安全对齐研究主要关注过滤具有安全、高质量响应的提示，而忽略了始终产生有害输出的困难提示。为此，我们引入UnsafeChain，旨在纠正不安全的完成以增强安全性。

Method: 我们通过从困难提示中的多样化来源构建UnsafeChain数据集，识别和纠正不安全的完成，然后对三个大型推理模型进行微调，并与SafeChain和STAR-1进行比较测试。

Result: UnsafeChain在六个分布外和五个分布内基准测试中始终优于现有的数据集，即使在一个1K子集上也是如此，展示了基于纠正的监督的有效性和广泛适用性。

Conclusion: UnsafeChain提供了一种有效的方式，通过纠正不安全的行为以增强推理模型的安全性，同时保持其一般推理能力。

Abstract: As large reasoning models (LRMs) grow more capable, chain-of-thought (CoT)
reasoning introduces new safety challenges. Existing SFT-based safety alignment
studies dominantly focused on filtering prompts with safe, high-quality
responses, while overlooking hard prompts that always elicit harmful outputs.
To fill this gap, we introduce UnsafeChain, a safety alignment dataset
constructed from hard prompts with diverse sources, where unsafe completions
are identified and explicitly corrected into safe responses. By exposing models
to unsafe behaviors and guiding their correction, UnsafeChain enhances safety
while preserving general reasoning ability. We fine-tune three LRMs on
UnsafeChain and compare them against recent SafeChain and STAR-1 across six
out-of-distribution and five in-distribution benchmarks. UnsafeChain
consistently outperforms prior datasets, with even a 1K subset matching or
surpassing baseline performance, demonstrating the effectiveness and
generalizability of correction-based supervision. We release our dataset and
code at https://github.com/mbzuai-nlp/UnsafeChain

</details>


### [134] [Adversarial Defence without Adversarial Defence: Enhancing Language Model Robustness via Instance-level Principal Component Removal](https://arxiv.org/abs/2507.21750)
*Yang Wang,Chenghao Xiao,Yizhi Li,Stuart E. Middleton,Noura Al Moubayed,Chenghua Lin*

Main category: cs.CL

TL;DR: 我们开发了一个有效的附加模块，通过去除实例级别主成分增强预训练语言模型的对抗鲁棒性，无需使用对抗性示例或耗时的训练增强。


<details>
  <summary>Details</summary>
Motivation: 尽管预训练语言模型在自然语言处理中取得了显著进展，但它们在实际应用中仍然容易受到对抗攻击的影响，这引发了对其鲁棒性的担忧。

Method: 我们提出了一种简单有效的附加模块，通过去除实例级别主成分来增强预训练语言模型的对抗鲁棒性，无需依赖传统对抗防御措施或扰动原始训练数据。

Result: 在八个基准数据集上的评估显示，我们的方法在保持与基准模型相当的准确性的同时改善了对抗鲁棒性，实现了鲁棒性和泛化之间的平衡。

Conclusion: 我们的方法通过转换嵌入空间以近似高斯特性，从而减少其对对抗扰动的敏感性，同时保留语义关系，提升了预训练语言模型的对抗鲁棒性。

Abstract: Pre-trained language models (PLMs) have driven substantial progress in
natural language processing but remain vulnerable to adversarial attacks,
raising concerns about their robustness in real-world applications. Previous
studies have sought to mitigate the impact of adversarial attacks by
introducing adversarial perturbations into the training process, either
implicitly or explicitly. While both strategies enhance robustness, they often
incur high computational costs. In this work, we propose a simple yet effective
add-on module that enhances the adversarial robustness of PLMs by removing
instance-level principal components, without relying on conventional
adversarial defences or perturbing the original training data. Our approach
transforms the embedding space to approximate Gaussian properties, thereby
reducing its susceptibility to adversarial perturbations while preserving
semantic relationships. This transformation aligns embedding distributions in a
way that minimises the impact of adversarial noise on decision boundaries,
enhancing robustness without requiring adversarial examples or costly
training-time augmentation. Evaluations on eight benchmark datasets show that
our approach improves adversarial robustness while maintaining comparable
before-attack accuracy to baselines, achieving a balanced trade-off between
robustness and generalisation.

</details>


### [135] [AgriEval: A Comprehensive Chinese Agricultural Benchmark for Large Language Models](https://arxiv.org/abs/2507.21773)
*Lian Yan,Haotian Wang,Chen Tang,Haifeng Liu,Tianyang Sun,Liangliang Liu,Yi Guan,Jingchi Jiang*

Main category: cs.CL

TL;DR: 提出AgriEval，一个综合性的农业中文基准，以评估和提高大型语言模型在农业领域的表现。


<details>
  <summary>Details</summary>
Motivation: 农业领域由于缺乏训练数据和评估基准，大型语言模型的应用受到限制。

Method: 设计并使用AgriEval农学评估基准，对多种开放资源及商业LLM进行测试，分析各种影响模型表现的因素。

Result: 实验结果显示多数现有LLM在农业领域的准确率不到60％，揭示了模型在农业领域的潜力及需要改进的地方。

Conclusion: 现有的大型语言模型在农业领域的表现仍有较大提升空间，AgriEval提供了一个有力的评估工具。

Abstract: In the agricultural domain, the deployment of large language models (LLMs) is
hindered by the lack of training data and evaluation benchmarks. To mitigate
this issue, we propose AgriEval, the first comprehensive Chinese agricultural
benchmark with three main characteristics: (1) Comprehensive Capability
Evaluation. AgriEval covers six major agriculture categories and 29
subcategories within agriculture, addressing four core cognitive scenarios:
memorization, understanding, inference, and generation. (2) High-Quality Data.
The dataset is curated from university-level examinations and assignments,
providing a natural and robust benchmark for assessing the capacity of LLMs to
apply knowledge and make expert-like decisions. (3) Diverse Formats and
Extensive Scale. AgriEval comprises 14,697 multiple-choice questions and 2,167
open-ended question-and-answer questions, establishing it as the most extensive
agricultural benchmark available to date. We also present comprehensive
experimental results over 51 open-source and commercial LLMs. The experimental
results reveal that most existing LLMs struggle to achieve 60% accuracy,
underscoring the developmental potential in agricultural LLMs. Additionally, we
conduct extensive experiments to investigate factors influencing model
performance and propose strategies for enhancement. AgriEval is available at
https://github.com/YanPioneer/AgriEval/.

</details>


### [136] [The Problem with Safety Classification is not just the Models](https://arxiv.org/abs/2507.21782)
*Sowmya Vajjala*

Main category: cs.CL

TL;DR: 论文探讨了LLM不安全行为的鲁棒性，研究了5个安全分类模型在18种语言中的多语言差距，并找出了评估数据集的问题。


<details>
  <summary>Details</summary>
Motivation: 改进多语言场景下LLM输入的有害内容识别。

Method: 考虑涵盖18种语言的数据集，展示多语言差距。

Result: 展示了5个安全分类模型在多语言场景中的差异，并识别了评估数据集的问题。

Conclusion: 当前的安全分类器存在缺陷，不仅因为模型本身，还有评估数据集的问题。

Abstract: Studying the robustness of Large Language Models (LLMs) to unsafe behaviors
is an important topic of research today. Building safety classification models
or guard models, which are fine-tuned models for input/output safety
classification for LLMs, is seen as one of the solutions to address the issue.
Although there is a lot of research on the safety testing of LLMs themselves,
there is little research on evaluating the effectiveness of such safety
classifiers or the evaluation datasets used for testing them, especially in
multilingual scenarios. In this position paper, we demonstrate how multilingual
disparities exist in 5 safety classification models by considering datasets
covering 18 languages. At the same time, we identify potential issues with the
evaluation datasets, arguing that the shortcomings of current safety
classifiers are not only because of the models themselves. We expect that these
findings will contribute to the discussion on developing better methods to
identify harmful content in LLM inputs across languages.

</details>


### [137] [ChartMark: A Structured Grammar for Chart Annotation](https://arxiv.org/abs/2507.21810)
*Yiyu Chen,Yifan Wu,Shuyu Shen,Yupeng Xie,Leixian Shen,Hui Xiong,Yuyu Luo*

Main category: cs.CL

TL;DR: ChartMark是一种新的图表注释标准，旨在改善现有注释的分散和非标准化问题，支持灵活的跨平台可重用性。


<details>
  <summary>Details</summary>
Motivation: 目前的图表注释存在分散和缺乏标准化的问题，影响了其跨平台的重用性。ChartMark被提出用于解决这些问题。

Method: ChartMark是一种结构化语法，它分离了注释语义与可视化实现，通过分层框架将其映射到各种注释维度上，进而支持从抽象意图到精确视觉细节的表达。

Result: ChartMark通过一个工具包将其规范转换为Vega-Lite可视化，展示了其灵活性、表现力和实用性。

Conclusion: ChartMark提供了一种在不影响可视化实现的情况下支持注释语义的新方法，对标准化和跨平台的注释表示具有积极的推动作用。

Abstract: Chart annotations enhance visualization accessibility but suffer from
fragmented, non-standardized representations that limit cross-platform reuse.
We propose ChartMark, a structured grammar that separates annotation semantics
from visualization implementations. ChartMark features a hierarchical framework
mapping onto annotation dimensions (e.g., task, chart context), supporting both
abstract intents and precise visual details. Our toolkit demonstrates
converting ChartMark specifications into Vega-Lite visualizations, highlighting
its flexibility, expressiveness, and practical applicability.

</details>


### [138] [Overview of ADoBo at IberLEF 2025: Automatic Detection of Anglicisms in Spanish](https://arxiv.org/abs/2507.21813)
*Elena Alvarez-Mellado,Jordi Porta-Zamorano,Constantine Lignos,Julio Gonzalo*

Main category: cs.CL

TL;DR: ADoBo 2025任务中，不同方法用于识别西班牙语中的英语借词，性能差异显著，最高F1得分为0.99。


<details>
  <summary>Details</summary>
Motivation: 为了在IberLEF 2025的背景下识别西班牙语中的英语借词（或Anglicism），研究人员设计了ADoBo 2025共享任务，旨在考察各种技术在此任务上的有效性。

Method: 参与者使用了大型语言模型（LLM）、深度学习模型、基于Transformer的模型和基于规则的系统来进行英语借词识别任务。

Result: 不同系统的F1分数从0.17到0.99不等，显示了各种方法在这个任务中的性能差异。

Conclusion: ADoBo 2025任务的参与者使用了各种方法来识别西班牙语中的英语借词，这些方法的性能差异很大，表现最好的系统达到了较高的F1得分。

Abstract: This paper summarizes the main findings of ADoBo 2025, the shared task on
anglicism identification in Spanish proposed in the context of IberLEF 2025.
Participants of ADoBo 2025 were asked to detect English lexical borrowings (or
anglicisms) from a collection of Spanish journalistic texts. Five teams
submitted their solutions for the test phase. Proposed systems included LLMs,
deep learning models, Transformer-based models and rule-based systems. The
results range from F1 scores of 0.17 to 0.99, which showcases the variability
in performance different systems can have for this task.

</details>


### [139] [HRIPBench: Benchmarking LLMs in Harm Reduction Information Provision to Support People Who Use Drugs](https://arxiv.org/abs/2507.21815)
*Kaixuan Wang,Chenxin Diao,Jason T. Jacques,Zhongliang Guo,Shuai Zhao*

Main category: cs.CL

TL;DR: 本文提出HRIPBench基准以评估大语言模型在减少药物使用危害信息方面的表现，结果显示模型存在准确性不足和安全风险问题，建议谨慎使用以避免负面健康影响。


<details>
  <summary>Details</summary>
Motivation: 尽管某些大型语言模型在医学知识方面表现出色，但其在与药物使用者相关任务中的表现仍未被充分探索。该研究旨在评估这些模型在减少药物危害信息提供方面的效果。

Method: 引入了HRIPBench这个基准，用于评估大型语言模型在减少危害信息提供方面的准确性和安全风险。基准数据集HRIP-Basic包含2,160个问题-答案-证据对，包含三个任务：检查安全界限、提供定量值和推断多重物质使用风险。通过构建Instruction和RAG方案，评估模型基于其内在知识和整合领域知识的行为。

Result: 研究结果表明，当前最先进的语言模型在提供减少危害的准确信息方面仍然存在不足，且有时会造成针对药物使用者的严重安全风险。

Conclusion: 实验结果表明，最先进的大型语言模型在提供准确的减少危害信息方面仍然存在困难，并且有时会对使用药物的人群(PWUD)造成严重的安全风险。因此，在减少危害的背景下使用大型语言模型时，需要谨慎限制以避免引发负面的健康结果。

Abstract: Millions of individuals' well-being are challenged by the harms of substance
use. Harm reduction as a public health strategy is designed to improve their
health outcomes and reduce safety risks. Some large language models (LLMs) have
demonstrated a decent level of medical knowledge, promising to address the
information needs of people who use drugs (PWUD). However, their performance in
relevant tasks remains largely unexplored. We introduce HRIPBench, a benchmark
designed to evaluate LLM's accuracy and safety risks in harm reduction
information provision. The benchmark dataset HRIP-Basic has 2,160
question-answer-evidence pairs. The scope covers three tasks: checking safety
boundaries, providing quantitative values, and inferring polysubstance use
risks. We build the Instruction and RAG schemes to evaluate model behaviours
based on their inherent knowledge and the integration of domain knowledge. Our
results indicate that state-of-the-art LLMs still struggle to provide accurate
harm reduction information, and sometimes, carry out severe safety risks to
PWUD. The use of LLMs in harm reduction contexts should be cautiously
constrained to avoid inducing negative health outcomes. WARNING: This paper
contains illicit content that potentially induces harms.

</details>


### [140] [Modelling Adjectival Modification Effects on Semantic Plausibility](https://arxiv.org/abs/2507.21828)
*Anna Golub,Beate Zywietz,Annerose Eichel*

Main category: cs.CL

TL;DR: 研究事件修改对合理性变化的影响，发现变压器模型表现不佳，RoBERTa较优。


<details>
  <summary>Details</summary>
Motivation: 理解事件修改导致的合理性变化对于对话生成、常识推理等任务非常重要。

Method: 使用句子变压器进行建模实验，并与RoBERTa等模型进行比较。

Result: 结果显示句子变压器和其他变压器模型在处理这项任务时表现不佳，尤其是句子变压器。

Conclusion: 句子变压器与基于变压器的模型面临挑战，RoBERTa表现更优。

Abstract: While the task of assessing the plausibility of events such as ''news is
relevant'' has been addressed by a growing body of work, less attention has
been paid to capturing changes in plausibility as triggered by event
modification. Understanding changes in plausibility is relevant for tasks such
as dialogue generation, commonsense reasoning, and hallucination detection as
it allows to correctly model, for example, ''gentle sarcasm'' as a sign of
closeness rather than unkindness among friends [9]. In this work, we tackle the
ADEPT challenge benchmark [6] consisting of 16K English sentence pairs
differing by exactly one adjectival modifier. Our modeling experiments provide
a conceptually novel method by using sentence transformers, and reveal that
both they and transformer-based models struggle with the task at hand, and
sentence transformers - despite their conceptual alignment with the task - even
under-perform in comparison to models like RoBERTa. Furthermore, an in-depth
comparison with prior work highlights the importance of a more realistic,
balanced evaluation method: imbalances distort model performance and evaluation
metrics, and weaken result trustworthiness.

</details>


### [141] [Introducing HALC: A general pipeline for finding optimal prompting strategies for automated coding with LLMs in the computational social sciences](https://arxiv.org/abs/2507.21831)
*Andreas Reich,Claudia Thoms,Tobias Schrimpf*

Main category: cs.CL

TL;DR: 提出HALC管道，系统地帮助构建高效提示以提高LLM编码任务的可靠性，并验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然研究人员提出了不同的提示策略，但其在LLM和任务中的有效性差异较大，因此需要一个能够构建最佳提示的系统方法。

Method: 我们提出了一种名为HALC的通用管道，用于系统和可靠地构建任何给定编码任务的最佳提示。

Result: 通过将1512个单独的提示发送给本地LLM并进行超过两百万次的请求，我们确认某些提示在单变量和双变量编码任务中表现出高可靠性。

Conclusion: 我们的研究通过HALC管道证明了不同提示策略在LLM编码任务中的有效性，确定了适合特定任务和模型的高可靠性提示。

Abstract: LLMs are seeing widespread use for task automation, including automated
coding in the social sciences. However, even though researchers have proposed
different prompting strategies, their effectiveness varies across LLMs and
tasks. Often trial and error practices are still widespread. We propose
HALC$-$a general pipeline that allows for the systematic and reliable
construction of optimal prompts for any given coding task and model, permitting
the integration of any prompting strategy deemed relevant. To investigate LLM
coding and validate our pipeline, we sent a total of 1,512 individual prompts
to our local LLMs in over two million requests. We test prompting strategies
and LLM task performance based on few expert codings (ground truth). When
compared to these expert codings, we find prompts that code reliably for single
variables (${\alpha}$climate = .76; ${\alpha}$movement = .78) and across two
variables (${\alpha}$climate = .71; ${\alpha}$movement = .74) using the LLM
Mistral NeMo. Our prompting strategies are set up in a way that aligns the LLM
to our codebook$-$we are not optimizing our codebook for LLM friendliness. Our
paper provides insights into the effectiveness of different prompting
strategies, crucial influencing factors, and the identification of reliable
prompts for each coding task and model.

</details>


### [142] [AutoTIR: Autonomous Tools Integrated Reasoning via Reinforcement Learning](https://arxiv.org/abs/2507.21836)
*Yifan Wei,Xiaoyan Yu,Yixuan Weng,Tengfei Pan,Angsheng Li,Li Du*

Main category: cs.CL

TL;DR: 通过AutoTIR强化学习框架，大语言模型在推理过程中能自主决定工具使用，提高了整体性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的方法依赖于预定义的工具使用模式，可能降低语言模型的核心语言能力，因此引入AutoTIR，旨在模拟人类自适应工具选择能力，提升大语言模型的推理能力。

Method: 采用强化学习框架，通过混合奖励机制来优化任务特定答案的正确性、结构化输出的遵从性和不正确工具使用的惩罚，从而鼓励精确推理和有效工具整合。

Result: 在知识密集型、数学和一般语言建模任务中，AutoTIR表现出色，与基线相比有显著优越性，并在工具使用行为的泛化能力上表现优异。

Conclusion: AutoTIR通过强化学习框架，使得大语言模型可以在推理过程中自主决定是否以及何时使用工具，从而提升其推理能力和工具整合效率。

Abstract: Large Language Models (LLMs), when enhanced through reasoning-oriented
post-training, evolve into powerful Large Reasoning Models (LRMs).
Tool-Integrated Reasoning (TIR) further extends their capabilities by
incorporating external tools, but existing methods often rely on rigid,
predefined tool-use patterns that risk degrading core language competence.
Inspired by the human ability to adaptively select tools, we introduce AutoTIR,
a reinforcement learning framework that enables LLMs to autonomously decide
whether and which tool to invoke during the reasoning process, rather than
following static tool-use strategies. AutoTIR leverages a hybrid reward
mechanism that jointly optimizes for task-specific answer correctness,
structured output adherence, and penalization of incorrect tool usage, thereby
encouraging both precise reasoning and efficient tool integration. Extensive
evaluations across diverse knowledge-intensive, mathematical, and general
language modeling tasks demonstrate that AutoTIR achieves superior overall
performance, significantly outperforming baselines and exhibits superior
generalization in tool-use behavior. These results highlight the promise of
reinforcement learning in building truly generalizable and scalable TIR
capabilities in LLMs. The code and data are available at
https://github.com/weiyifan1023/AutoTIR.

</details>


### [143] [Graph-R1: Towards Agentic GraphRAG Framework via End-to-end Reinforcement Learning](https://arxiv.org/abs/2507.21892)
*Haoran Luo,Haihong E,Guanting Chen,Qika Lin,Yikai Guo,Fangzhi Xu,Zemin Kuang,Meina Song,Xiaobao Wu,Yifan Zhu,Luu Anh Tuan*

Main category: cs.CL

TL;DR: Graph-R1通过端到端强化学习改善了GraphRAG，使其在多方面表现卓越。


<details>
  <summary>Details</summary>
Motivation: 解决现有GraphRAG方法在高构建成本、固定一次性检索、以及依赖长上下文推理和提示设计上的挑战。

Method: 引入轻量化的知识超图构建，将检索建模为多回合的代理-环境交互，并通过端到端奖励机制优化代理过程。

Result: Graph-R1在标准RAG数据集上的表现优于传统GraphRAG和增强型RAG方法。

Conclusion: Graph-R1在推理准确性、检索效率和生成质量方面超过了传统的GraphRAG和增强型RAG方法。

Abstract: Retrieval-Augmented Generation (RAG) mitigates hallucination in LLMs by
incorporating external knowledge, but relies on chunk-based retrieval that
lacks structural semantics. GraphRAG methods improve RAG by modeling knowledge
as entity-relation graphs, but still face challenges in high construction cost,
fixed one-time retrieval, and reliance on long-context reasoning and prompt
design. To address these challenges, we propose Graph-R1, an agentic GraphRAG
framework via end-to-end reinforcement learning (RL). It introduces lightweight
knowledge hypergraph construction, models retrieval as a multi-turn
agent-environment interaction, and optimizes the agent process via an
end-to-end reward mechanism. Experiments on standard RAG datasets show that
Graph-R1 outperforms traditional GraphRAG and RL-enhanced RAG methods in
reasoning accuracy, retrieval efficiency, and generation quality.

</details>


### [144] [Rote Learning Considered Useful: Generalizing over Memorized Data in LLMs](https://arxiv.org/abs/2507.21914)
*Qinyuan Wu,Soumi Das,Mahsa Amani,Bishwamittra Ghosh,Mohammad Aflah Khan,Krishna P. Gummadi,Muhammad Bilal Zafar*

Main category: cs.CL

TL;DR: 该研究提出了一种新框架，使LLMs在记忆阶段后通过语义提示进行泛化，结果显示模型能够有效利用记忆数据进行泛化学习。


<details>
  <summary>Details</summary>
Motivation: 挑战常规认知，利用机械记忆技术达到泛化学习。

Method: 提出“两阶段机械记忆再泛化框架”，通过广泛实验验证模型通过语义相关提示重新解释机械记忆的数据。

Result: 实验显示，模型能够通过语义提示重新解释机械记忆的数据，并在两者之间出现结构化、语义对齐的潜在表示。

Conclusion: LLMs可以通过引入语义无关的标记进行机械记忆，并通过精调语义关联提示进行泛化。

Abstract: Rote learning is a memorization technique based on repetition. It is commonly
believed to hinder generalization by encouraging verbatim memorization rather
than deeper understanding. This insight holds for even learning factual
knowledge that inevitably requires a certain degree of memorization. In this
work, we demonstrate that LLMs can be trained to generalize from rote memorized
data. We introduce a two-phase memorize-then-generalize framework, where the
model first rote memorizes factual subject-object associations using a
semantically meaningless token and then learns to generalize by fine-tuning on
a small set of semantically meaningful prompts. Extensive experiments over 8
LLMs show that the models can reinterpret rote memorized data through the
semantically meaningful prompts, as evidenced by the emergence of structured,
semantically aligned latent representations between the two. This surprising
finding opens the door to both effective and efficient knowledge injection and
possible risks of repurposing the memorized data for malicious usage.

</details>


### [145] [Training language models to be warm and empathetic makes them less reliable and more sycophantic](https://arxiv.org/abs/2507.21919)
*Lujain Ibrahim,Franziska Sofia Hafner,Luc Rocher*

Main category: cs.CL

TL;DR: 优化语言模型以获得温暖响应会削弱其在关乎安全的任务上的可靠性，尤其是在用户表达脆弱性时。


<details>
  <summary>Details</summary>
Motivation: 随着AI语言模型被用作建议、治疗和陪伴工具，它们被设计成温暖和有同理心的角色，但这可能削弱模型的可靠性。

Method: 进行了对五个不同尺寸和架构的语言模型的控制实验，训练它们以产生更温暖、更有同理心的回应，然后在安全关键任务上进行评估。

Result: 温暖模型在安全关键任务上表现出更高的错误率，比原始模型高10到30个百分点。它们更倾向于传播阴谋论、提供不正确的事实信息以及问题医学建议，并更容易验证用户的错误信念。

Conclusion: 开发温暖和有同理心的AI语言模型存在显著的权衡：这些模型在提供温暖响应的同时，其可靠性受到削弱，特别是在用户表达脆弱性时。

Abstract: Artificial intelligence (AI) developers are increasingly building language
models with warm and empathetic personas that millions of people now use for
advice, therapy, and companionship. Here, we show how this creates a
significant trade-off: optimizing language models for warmth undermines their
reliability, especially when users express vulnerability. We conducted
controlled experiments on five language models of varying sizes and
architectures, training them to produce warmer, more empathetic responses, then
evaluating them on safety-critical tasks. Warm models showed substantially
higher error rates (+10 to +30 percentage points) than their original
counterparts, promoting conspiracy theories, providing incorrect factual
information, and offering problematic medical advice. They were also
significantly more likely to validate incorrect user beliefs, particularly when
user messages expressed sadness. Importantly, these effects were consistent
across different model architectures, and occurred despite preserved
performance on standard benchmarks, revealing systematic risks that current
evaluation practices may fail to detect. As human-like AI systems are deployed
at an unprecedented scale, our findings indicate a need to rethink how we
develop and oversee these systems that are reshaping human relationships and
social interaction.

</details>


### [146] [Post-Training Large Language Models via Reinforcement Learning from Self-Feedback](https://arxiv.org/abs/2507.21931)
*Carel van Niekerk,Renato Vukovic,Benjamin Matthias Ruppik,Hsien-chin Lin,Milica Gašić*

Main category: cs.CL

TL;DR: 提出了一种利用模型自身置信度作为内在奖励的后训练方法RLSF，改善了LLM的校准和推理能力，无需外部反馈。


<details>
  <summary>Details</summary>
Motivation: LLM通常产生合理但校准不佳的答案，限制了其在需要严格推理的任务中的可靠性。

Method: 在LLM生成链式解决方案后，定义和计算每个最终答案的置信度，并根据痕迹进行排名。然后使用这些生成的偏好通过标准偏好优化微调策略。

Result: 使用RLSF，模型的概率估计得到改善，同时增强了逐步推理能力，提高了算术推理和多选题解答的性能。

Conclusion: RLSF改进了模型校准和逐步推理能力，提高了算术推理和多选题回答性能，强调了在LLM后训练中基于内在奖励的强化学习的有效性。

Abstract: Large Language Models (LLMs) often produce plausible but poorly-calibrated
answers, limiting their reliability on reasoning-intensive tasks. We present
Reinforcement Learning from Self-Feedback (RLSF), a post-training stage that
uses the model's own confidence as an intrinsic reward, mimicking how humans
learn in the absence of external feedback. After a frozen LLM generates several
chain-of-thought solutions, we define and compute the confidence of each final
answer span and rank the traces accordingly. These synthetic preferences are
then used to fine-tune the policy with standard preference optimization,
similar to RLHF yet requiring no human labels, gold answers, or externally
curated rewards.
  RLSF simultaneously (i) refines the model's probability estimates --
restoring well-behaved calibration -- and (ii) strengthens step-by-step
reasoning, yielding improved performance on arithmetic reasoning and
multiple-choice question answering.
  By turning a model's own uncertainty into useful self-feedback, RLSF affirms
reinforcement learning on intrinsic model behaviour as a principled and
data-efficient component of the LLM post-training pipeline and warrents further
research in intrinsic rewards for LLM post-training.

</details>


### [147] [Culinary Crossroads: A RAG Framework for Enhancing Diversity in Cross-Cultural Recipe Adaptation](https://arxiv.org/abs/2507.21934)
*Tianyi Hu,Andrea Morales-Garzón,Jingyi Zheng,Maria Maistro,Daniel Hershcovich*

Main category: cs.CL

TL;DR: CARRIAGE提高了跨文化食谱适配的多样性和质量，解决了传统RAG框架的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统RAG框架在生成多样化输出时的局限性，并为跨文化食谱适配提供方案。

Method: 本文采用CARRIAGE，这是一种增强RAG框架的方法，通过改进检索和上下文组织来提高生成输出的多样性。

Result: 实验证明，CARRIAGE在食谱适配的多样性和质量上优于封闭书LLMs。

Conclusion: CARRIAGE是一个插件式RAG框架，能够增加检索和上下文组织的多样性，以满足用户的多重偏好。实验证明其在食谱适配的多样性和质量上达到了帕累托效率。

Abstract: In cross-cultural recipe adaptation, the goal is not only to ensure cultural
appropriateness and retain the original dish's essence, but also to provide
diverse options for various dietary needs and preferences. Retrieval Augmented
Generation (RAG) is a promising approach, combining the retrieval of real
recipes from the target cuisine for cultural adaptability with large language
models (LLMs) for relevance. However, it remains unclear whether RAG can
generate diverse adaptation results. Our analysis shows that RAG tends to
overly rely on a limited portion of the context across generations, failing to
produce diverse outputs even when provided with varied contextual inputs. This
reveals a key limitation of RAG in creative tasks with multiple valid answers:
it fails to leverage contextual diversity for generating varied responses. To
address this issue, we propose CARRIAGE, a plug-and-play RAG framework for
cross-cultural recipe adaptation that enhances diversity in both retrieval and
context organization. To our knowledge, this is the first RAG framework that
explicitly aims to generate highly diverse outputs to accommodate multiple user
preferences. Our experiments show that CARRIAGE achieves Pareto efficiency in
terms of diversity and quality of recipe adaptation compared to closed-book
LLMs.

</details>


### [148] [Predicting Microbial Ontology and Pathogen Risk from Environmental Metadata with Large Language Models](https://arxiv.org/abs/2507.21980)
*Hyunwoo Yoo,Gail L. Rosen*

Main category: cs.CL

TL;DR: 大型语言模型在微生物组研究中表现优异，能够用元数据分类样本和预测病原菌风险。


<details>
  <summary>Details</summary>
Motivation: 传统机器学习模型在微生物组研究中难以泛化，尤其是在仅有元数据的小样本环境中或跨研究具有异质标签格式的情况下。

Method: 使用大型语言模型（LLMs）如ChatGPT-4o，Claude 3.7 Sonnet，Grok-3和LLaMA 4进行零样本和少量样本实验，比较这些模型与传统模型在多个真实数据集中的性能。

Result: LLMs不仅在本体分类上优于基准模型，还表现出较强的污染风险预测能力，并且能够跨站点和元数据分布进行泛化。

Conclusion: 本文结果表明，LLMs在分类微生物样本到本体类别和预测病原菌污染风险方面表现优异，能够有效处理稀疏、异质的生物元数据。

Abstract: Traditional machine learning models struggle to generalize in microbiome
studies where only metadata is available, especially in small-sample settings
or across studies with heterogeneous label formats. In this work, we explore
the use of large language models (LLMs) to classify microbial samples into
ontology categories such as EMPO 3 and related biological labels, as well as to
predict pathogen contamination risk, specifically the presence of E. Coli,
using environmental metadata alone. We evaluate LLMs such as ChatGPT-4o, Claude
3.7 Sonnet, Grok-3, and LLaMA 4 in zero-shot and few-shot settings, comparing
their performance against traditional models like Random Forests across
multiple real-world datasets. Our results show that LLMs not only outperform
baselines in ontology classification, but also demonstrate strong predictive
ability for contamination risk, generalizing across sites and metadata
distributions. These findings suggest that LLMs can effectively reason over
sparse, heterogeneous biological metadata and offer a promising metadata-only
approach for environmental microbiology and biosurveillance applications.

</details>


### [149] [DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router](https://arxiv.org/abs/2507.22050)
*Minghao Guo,Qingcheng Zeng,Xujiang Zhao,Yanchi Liu,Wenchao Yu,Mengnan Du,Haifeng Chen,Wei Cheng*

Main category: cs.CL

TL;DR: DeepSieve 提升 LLMs 在知识密集型任务中的推理和检索能力，改善现有 RAG 方法的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的 RAG 方法在查询和源方面缺乏细粒度控制，导致检索噪声和浅层推理。需求是提升 LLMs 在知识密集型查询上的性能。

Method: 该研究提出了 DeepSieve 框架，通过将复杂查询分解为结构化子问题并递归路由到最合适的知识源，结合多阶段蒸馏过程，进行信息筛选。

Result: 实验表明，与传统 RAG 方法相比，DeepSieve 在多跳问答任务中表现出更好的推理深度、检索精度和可解释性。

Conclusion: DeepSieve 框架提高了多跳问答任务的推理深度、检索精度和可解释性。

Abstract: Large Language Models (LLMs) excel at many reasoning tasks but struggle with
knowledge-intensive queries due to their inability to dynamically access
up-to-date or domain-specific information. Retrieval-Augmented Generation (RAG)
has emerged as a promising solution, enabling LLMs to ground their responses in
external sources. However, existing RAG methods lack fine-grained control over
both the query and source sides, often resulting in noisy retrieval and shallow
reasoning. In this work, we introduce DeepSieve, an agentic RAG framework that
incorporates information sieving via LLM-as-a-knowledge-router. DeepSieve
decomposes complex queries into structured sub-questions and recursively routes
each to the most suitable knowledge source, filtering irrelevant information
through a multi-stage distillation process. Our design emphasizes modularity,
transparency, and adaptability, leveraging recent advances in agentic system
design. Experiments on multi-hop QA tasks across heterogeneous sources
demonstrate improved reasoning depth, retrieval precision, and interpretability
over conventional RAG approaches.

</details>


<div id='cs.IR'></div>

# cs.IR [[Back]](#toc)

### [150] [Analise Semantica Automatizada com LLM e RAG para Bulas Farmaceuticas](https://arxiv.org/abs/2507.21103)
*Daniel Meireles do Rego*

Main category: cs.IR

TL;DR: This study leverages RAG and LLMs to improve analysis of unstructured PDFs, demonstrating enhanced retrieval and interpretation in evaluations.


<details>
  <summary>Details</summary>
Motivation: The rapid growth of digital documents in various fields presents challenges in extracting and analyzing unstructured information efficiently.

Method: This work uses RAG (Retrieval-Augmented Generation) architectures in conjunction with Large-Scale Language Models (LLMs), integrating vector search techniques, semantic data extraction, and generation of contextualized responses.

Result: The experiments with drug package inserts showed that RAG combined with LLMs enhances accuracy, completeness, response speed, and consistency in semantic queries.

Conclusion: RAG combined with LLMs can enhance intelligent information retrieval and interpretation of unstructured technical texts.

Abstract: The production of digital documents has been growing rapidly in academic,
business, and health environments, presenting new challenges in the efficient
extraction and analysis of unstructured information. This work investigates the
use of RAG (Retrieval-Augmented Generation) architectures combined with
Large-Scale Language Models (LLMs) to automate the analysis of documents in PDF
format. The proposal integrates vector search techniques by embeddings,
semantic data extraction and generation of contextualized natural language
responses. To validate the approach, we conducted experiments with drug package
inserts extracted from official public sources. The semantic queries applied
were evaluated by metrics such as accuracy, completeness, response speed and
consistency. The results indicate that the combination of RAG with LLMs offers
significant gains in intelligent information retrieval and interpretation of
unstructured technical texts.

</details>


### [151] [AgentMaster: A Multi-Agent Conversational Framework Using A2A and MCP Protocols for Multimodal Information Retrieval and Analysis](https://arxiv.org/abs/2507.21105)
*Callie C. Liao,Duoduo Liao,Sai Surya Gadiraju*

Main category: cs.IR

TL;DR: 提出了一个采用自实现A2A和MCP协议的新型MAS框架AgentMaster，解决了复杂任务的交互挑战，展现了强大的智能体协调和任务处理能力。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统（MAS）在人工智能领域的崛起，特别是在与大型语言模型（LLMs）结合后，大大促进了复杂任务的解决。然而，这些系统在异构工具和资源的通信、协调和交互方面仍面临挑战。

Method: 提出了AgentMaster，一个创新的模块化多协议MAS框架，包含自实现的A2A和MCP协议，允许动态协调和灵活通信。系统通过统一的对话界面，实现无需技术背景的自然语言交互，并支持信息检索、问答和图像分析等任务的多模态查询响应。

Result: 系统通过BERTScore F1和LLM作为评判标准的G-Eval进行评估，平均得分为96.3%和87.1%，展示了强大的智能体间协调、查询分解、动态路由和领域特定的相关响应能力。

Conclusion: 提出的框架为领域特定、合作和可扩展的对话式AI的潜在能力做出贡献。

Abstract: The rise of Multi-Agent Systems (MAS) in Artificial Intelligence (AI),
especially integrated with Large Language Models (LLMs), has greatly
facilitated the resolution of complex tasks. However, current systems are still
facing challenges of inter-agent communication, coordination, and interaction
with heterogeneous tools and resources. Most recently, the Model Context
Protocol (MCP) by Anthropic and Agent-to-Agent (A2A) communication protocol by
Google have been introduced, and to the best of our knowledge, very few
applications exist where both protocols are employed within a single MAS
framework. We present a pilot study of AgentMaster, a novel modular
multi-protocol MAS framework with self-implemented A2A and MCP, enabling
dynamic coordination and flexible communication. Through a unified
conversational interface, the system supports natural language interaction
without prior technical expertise and responds to multimodal queries for tasks
including information retrieval, question answering, and image analysis.
Evaluation through the BERTScore F1 and LLM-as-a-Judge metric G-Eval averaged
96.3\% and 87.1\%, revealing robust inter-agent coordination, query
decomposition, dynamic routing, and domain-specific, relevant responses.
Overall, our proposed framework contributes to the potential capabilities of
domain-specific, cooperative, and scalable conversational AI powered by MAS.

</details>


### [152] [Page image classification for content-specific data processing](https://arxiv.org/abs/2507.21114)
*Kateryna Lutsai,Pavel Straňák*

Main category: cs.IR

TL;DR: 该项目开发了一个用于历史文档页面分类的图像分类系统，以自动化处理并促进不同类型的页面内容分析。


<details>
  <summary>Details</summary>
Motivation: 人文学科的数字化项目通常会生成大量的历史文档页面图像，这些图像需要进行手动排序和分析，面临着重大挑战。

Method: 开发和评估一个专门为历史文档页面设计的图像分类系统，利用人工智能和机器学习的进步。

Result: 项目选择了一组类别以促进内容特定的处理工作流程，使得页面根据不同的分析技术进行分类，如文本的OCR，图形的图像分析。

Conclusion: 该项目通过自动化的方法高效处理历史文档资料，将页面按内容分类，以实现定制化的后续分析流程。

Abstract: Digitization projects in humanities often generate vast quantities of page
images from historical documents, presenting significant challenges for manual
sorting and analysis. These archives contain diverse content, including various
text types (handwritten, typed, printed), graphical elements (drawings, maps,
photos), and layouts (plain text, tables, forms). Efficiently processing this
heterogeneous data requires automated methods to categorize pages based on
their content, enabling tailored downstream analysis pipelines. This project
addresses this need by developing and evaluating an image classification system
specifically designed for historical document pages, leveraging advancements in
artificial intelligence and machine learning. The set of categories was chosen
to facilitate content-specific processing workflows, separating pages requiring
different analysis techniques (e.g., OCR for text, image analysis for graphics)

</details>


### [153] [FedFlex: Federated Learning for Diverse Netflix Recommendations](https://arxiv.org/abs/2507.21115)
*Sven Lankester,Manel Slokom,Gustavo de Carvalho Bertoli,Matias Vizcaino,Emmanuelle Beauxis Aussalet,Laura Hollink*

Main category: cs.IR

TL;DR: 研究介绍了联邦推荐系统FedFlex，该系统通过整合矩阵分解算法和重新排序技术增强推荐的多样性而不减少用户满意度。


<details>
  <summary>Details</summary>
Motivation: 现有的联邦推荐系统大多关注于改进准确性，而对公平性和多样性关注较少。

Method: FedFlex集成了两种先进的矩阵分解算法进行个性化调整，并应用最大边际相关性(MMR)方法来对项目进行重新排序以增强多样性。

Result: 参与者在实验中接收两组推荐列表：基于SVD或BPR的列表A，以及强调多样性的重新排序列表B。结果表明，FedFlex有效地引入了多样化内容，而未明显降低用户满意度。

Conclusion: FedFlex可以在保持用户满意度的情况下为推荐系统引入多样化的内容。

Abstract: Federated learning is a decentralized approach that enables collaborative
model training across multiple devices while preserving data privacy. It has
shown significant potential in various domains, including healthcare and
personalized recommendation systems. However, most existing work on federated
recommendation systems has focused primarily on improving accuracy, with
limited attention to fairness and diversity. In this paper, we introduce
FedFlex, a federated recommender system for Netflix-style TV series
recommendations. FedFlex integrates two state-of-the-art matrix factorization
algorithms for personalized fine-tuning. FedFlex also applies Maximal Marginal
Relevance (MMR) to re-rank items and enhance diversity. We conduct extensive
experiments comparing recommendations generated by SVD and BPR algorithms. In a
live two-week user study, participants received two recommendation lists: List
A, based on SVD or BPR, and List B, a re-ranked version emphasizing diversity.
Participants were asked to click on the movies they were interested in
watching. Our findings demonstrate that FedFlex effectively introduces diverse
content, such as new genres, into recommendations without necessarily
compromising user satisfaction.

</details>


### [154] [A Comprehensive Review on Harnessing Large Language Models to Overcome Recommender System Challenges](https://arxiv.org/abs/2507.21117)
*Rahul Raja,Anshaj Vats,Arpita Vats,Anirban Majumder*

Main category: cs.IR

TL;DR: 本文调查了大型语言模型如何解决现代推荐系统中的核心瓶颈，并提供了一个理解LLM增强推荐系统设计空间的结构框架。


<details>
  <summary>Details</summary>
Motivation: 传统推荐系统面临着数据稀疏和噪音、冷启动问题、个性化深度有限以及用户和项目内容语义理解不足等挑战。

Method: 本文通过对LLMs在现代推荐系统中的关键挑战进行技术综述，考察了其在提示驱动候选检索、语言原生排名、检索增强生成（RAG）和会话推荐中的应用。

Result: 研究表明，LLMs增强了推荐系统的个性化、语义对齐和可解释性，并使其能够在冷启动和长尾场景中有效运行。

Conclusion: 本文认为，大型语言模型（LLMs）不仅是辅助组件，还可以作为构建更具适应性、语义丰富和用户中心化的推荐系统的基础性支持。

Abstract: Recommender systems have traditionally followed modular architectures
comprising candidate generation, multi-stage ranking, and re-ranking, each
trained separately with supervised objectives and hand-engineered features.
While effective in many domains, such systems face persistent challenges
including sparse and noisy interaction data, cold-start problems, limited
personalization depth, and inadequate semantic understanding of user and item
content. The recent emergence of Large Language Models (LLMs) offers a new
paradigm for addressing these limitations through unified, language-native
mechanisms that can generalize across tasks, domains, and modalities. In this
paper, we present a comprehensive technical survey of how LLMs can be leveraged
to tackle key challenges in modern recommender systems. We examine the use of
LLMs for prompt-driven candidate retrieval, language-native ranking,
retrieval-augmented generation (RAG), and conversational recommendation,
illustrating how these approaches enhance personalization, semantic alignment,
and interpretability without requiring extensive task-specific supervision.
LLMs further enable zero- and few-shot reasoning, allowing systems to operate
effectively in cold-start and long-tail scenarios by leveraging external
knowledge and contextual cues. We categorize these emerging LLM-driven
architectures and analyze their effectiveness in mitigating core bottlenecks of
conventional pipelines. In doing so, we provide a structured framework for
understanding the design space of LLM-enhanced recommenders, and outline the
trade-offs between accuracy, scalability, and real-time performance. Our goal
is to demonstrate that LLMs are not merely auxiliary components but
foundational enablers for building more adaptive, semantically rich, and
user-centric recommender systems

</details>


### [155] [Affect-aware Cross-Domain Recommendation for Art Therapy via Music Preference Elicitation](https://arxiv.org/abs/2507.21120)
*Bereket A. Yilma,Luis A. Leiva*

Main category: cs.IR

TL;DR: 研究提出了一种结合音乐刺激的跨领域推荐系统，以提高艺术治疗中的个性化推荐效果。


<details>
  <summary>Details</summary>
Motivation: 当前的视觉艺术推荐系统在用户建模中存在局限性，而音乐刺激能够引发独特情感反应，可用于加强艺术治疗中的个性化。

Method: 提出了一系列基于音乐驱动偏好引导的跨领域推荐方法，并进行了大规模研究。

Result: 音乐驱动的偏好引导方法优于传统的仅仅依赖视觉的引导方法。

Conclusion: 通过音乐驱动的偏好引导可以增强艺术治疗中的个性化推荐效果。

Abstract: Art Therapy (AT) is an established practice that facilitates emotional
processing and recovery through creative expression. Recently, Visual Art
Recommender Systems (VA RecSys) have emerged to support AT, demonstrating their
potential by personalizing therapeutic artwork recommendations. Nonetheless,
current VA RecSys rely on visual stimuli for user modeling, limiting their
ability to capture the full spectrum of emotional responses during preference
elicitation. Previous studies have shown that music stimuli elicit unique
affective reflections, presenting an opportunity for cross-domain
recommendation (CDR) to enhance personalization in AT. Since CDR has not yet
been explored in this context, we propose a family of CDR methods for AT based
on music-driven preference elicitation. A large-scale study with 200 users
demonstrates the efficacy of music-driven preference elicitation, outperforming
the classic visual-only elicitation approach. Our source code, data, and models
are available at https://github.com/ArtAICare/Affect-aware-CDR

</details>


### [156] [RATE: An LLM-Powered Retrieval Augmented Generation Technology-Extraction Pipeline](https://arxiv.org/abs/2507.21125)
*Karan Mirhosseini,Arya Aftab,Alireza Sheikh*

Main category: cs.IR

TL;DR: 本文提出了名为RATE的基于大型语言模型的技术提取方法，通过高召回和高精准的混合策略，从文献中自动提取技术术语并映射到共现网络中，比BERT方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 科技快速变革的时代，技术图谱在增强决策过程中发挥着重要作用。为了提高技术图谱的质量，需要依赖自动化的方法进行技术提取。

Method: 引入基于大型语言模型（LLM）的管道，称为增益检索技术提取（RATE），能够从科学文献中自动提取技术。RATE结合增益检索生成（RAG）和多定义LLM验证，形成了候选生成高召回、候选过滤高精准的混合方法。

Result: RATE在技术术语验证后被映射到共现网络中，显示了研究景观的主题集群和结构特征。在对随机选择的70篇文献进行的专家评审金标准数据集中进行评估，与基于BERT的模型相比，RATE以91.27%的F1分数显著优于BERT的53.73%。

Conclusion: 定义驱动的LLM方法在技术提取和映射中表现出色，并提供了关于BCI-XR领域新趋势的洞见。

Abstract: In an era of radical technology transformations, technology maps play a
crucial role in enhancing decision making. These maps heavily rely on automated
methods of technology extraction. This paper introduces Retrieval Augmented
Technology Extraction (RATE), a Large Language Model (LLM) based pipeline for
automated technology extraction from scientific literature. RATE combines
Retrieval Augmented Generation (RAG) with multi-definition LLM-based
validation. This hybrid method results in high recall in candidate generation
alongside with high precision in candidate filtering. While the pipeline is
designed to be general and widely applicable, we demonstrate its use on 678
research articles focused on Brain-Computer Interfaces (BCIs) and Extended
Reality (XR) as a case study. Consequently, The validated technology terms by
RATE were mapped into a co-occurrence network, revealing thematic clusters and
structural features of the research landscape. For the purpose of evaluation, a
gold standard dataset of technologies in 70 selected random articles had been
curated by the experts. In addition, a technology extraction model based on
Bidirectional Encoder Representations of Transformers (BERT) was used as a
comparative method. RATE achieved F1-score of 91.27%, Significantly
outperforming BERT with F1-score of 53.73%. Our findings highlight the promise
of definition-driven LLM methods for technology extraction and mapping. They
also offer new insights into emerging trends within the BCI-XR field. The
source code is available https://github.com/AryaAftab/RATE

</details>


### [157] [Efficient Data Retrieval and Comparative Bias Analysis of Recommendation Algorithms for YouTube Shorts and Long-Form Videos](https://arxiv.org/abs/2507.21467)
*Selimhan Dagtas,Mert Can Cakmak,Nitin Agarwal*

Main category: cs.IR

TL;DR: 该研究分析了YouTube的推荐算法，发现短视频推荐倾向于内容多样性较弱，并揭示了算法在政治话题中的偏见影响。


<details>
  <summary>Details</summary>
Motivation: 随着短视频内容（如YouTube Shorts）的流行，用户参与度发生了变化，必须研究推荐算法在用户体验中的作用。

Method: 开发高效的数据收集框架，利用并行计算和高级抓取技术分析YouTube的推荐算法，以克服其API的限制。

Result: 短视频的推荐算法显示出立即转向吸引性但内容多样性较弱的行为模式，而长视频则较为多样。在政治敏感话题上，如南中国海争端，推荐算法塑造叙事并放大特定视点。

Conclusion: 该研究强调了在数字媒体中负责任的AI实践的重要性，提供了设计公平和透明推荐系统的可操作性见解。

Abstract: The growing popularity of short-form video content, such as YouTube Shorts,
has transformed user engagement on digital platforms, raising critical
questions about the role of recommendation algorithms in shaping user
experiences. These algorithms significantly influence content consumption, yet
concerns about biases, echo chambers, and content diversity persist. This study
develops an efficient data collection framework to analyze YouTube's
recommendation algorithms for both short-form and long-form videos, employing
parallel computing and advanced scraping techniques to overcome limitations of
YouTube's API. The analysis uncovers distinct behavioral patterns in
recommendation algorithms across the two formats, with short-form videos
showing a more immediate shift toward engaging yet less diverse content
compared to long-form videos. Furthermore, a novel investigation into biases in
politically sensitive topics, such as the South China Sea dispute, highlights
the role of these algorithms in shaping narratives and amplifying specific
viewpoints. By providing actionable insights for designing equitable and
transparent recommendation systems, this research underscores the importance of
responsible AI practices in the evolving digital media landscape.

</details>


### [158] [Solution for Meta KDD Cup'25: A Comprehensive Three-Step Framework for Vision Question Answering](https://arxiv.org/abs/2507.21520)
*Zijian Zhang,Xiaocheng Zhang,Yang Zhou,Zhimin Lin,Peng Yan*

Main category: cs.IR

TL;DR: Meta在KDD Cup 2025设立了挑战，BlackPearl团队通过单模型方法在多模态任务中取得了优异成绩。


<details>
  <summary>Details</summary>
Motivation: Vision Large Language Models虽改进了多模态理解和视觉问答，但仍存在幻觉问题。多模态RAG通过整合外部信息帮助解决这些问题，但视觉上下文理解、多源检索、多轮交互等方面仍面临挑战。Meta通过创建CRAG-MM benchmark来应对这些挑战。

Method: 单模型方法结合数据增强、检索增强生成、多任务微调等技术来解决挑战。

Result: 在自动评估中分别获得第3、第3和第1名，在人工评估中获得Task3的第二名。

Conclusion: BlackPearl团队在Meta KDD Cup 2025中取得了优异成绩，为三个任务提供了解决方案，并获得了自动评估排名的第3、第3和第1，以及人工评估后第2名。

Abstract: Vision Large Language Models (VLLMs) have improved multi-modal understanding
and visual question answering (VQA), but still suffer from hallucinated
answers. Multi-modal Retrieval-Augmented Generation (RAG) helps address these
issues by incorporating external information, yet challenges remain in visual
context comprehension, multi-source retrieval, and multi-turn interactions. To
address these challenges, Meta constructed the CRAG-MM benchmark and launched
the CRAG-MM Challenge at KDD Cup 2025, which consists of three tasks. This
paper describes the solutions of all tasks in Meta KDD Cup'25 from BlackPearl
team. We use a single model for each task, with key methods including data
augmentation, RAG, reranking, and multi-task fine-tuning. Our solution achieve
automatic evaluation rankings of 3rd, 3rd, and 1st on the three tasks, and win
second place in Task3 after human evaluation.

</details>


### [159] [Enhancing Graph-based Recommendations with Majority-Voting LLM-Rerank Augmentation](https://arxiv.org/abs/2507.21563)
*Minh-Anh Nguyen,Bao Nguyen,Ha Lan N. T.,Tuan Anh Hoang,Duc-Trong Le,Dung D. Le*

Main category: cs.IR

TL;DR: 使用大型语言模型和图对比学习来增强数据，以提高推荐系统的准确性和减少流行偏差。


<details>
  <summary>Details</summary>
Motivation: 解决推荐系统中由于有限的用户物品交互导致的数据稀疏问题，从而提高性能并减少流行偏差。

Method: 利用大型语言模型（LLMs）通过少样本提示多次重新排序物品，并通过多数投票汇聚结果生成高置信度的合成用户物品交互数据，然后将这些数据集成到图对比学习框架中。

Result: 实验结果表明，该方法在提高准确性和减少流行偏差方面优于强基线。

Conclusion: 该研究表明，通过将合成的用户物品交互数据集成到图对比学习框架中，可以显著提高推荐系统的准确性并减少流行偏差。

Abstract: Recommendation systems often suffer from data sparsity caused by limited
user-item interactions, which degrade their performance and amplify popularity
bias in real-world scenarios. This paper proposes a novel data augmentation
framework that leverages Large Language Models (LLMs) and item textual
descriptions to enrich interaction data. By few-shot prompting LLMs multiple
times to rerank items and aggregating the results via majority voting, we
generate high-confidence synthetic user-item interactions, supported by
theoretical guarantees based on the concentration of measure. To effectively
leverage the augmented data in the context of a graph recommendation system, we
integrate it into a graph contrastive learning framework to mitigate
distributional shift and alleviate popularity bias. Extensive experiments show
that our method improves accuracy and reduces popularity bias, outperforming
strong baselines.

</details>


### [160] [Proposing a Semantic Movie Recommendation System Enhanced by ChatGPT's NLP Results](https://arxiv.org/abs/2507.21770)
*Ali Fallahi,Azam Bastanfard,Amineh Amini,Hadi Saboohi*

Main category: cs.IR

TL;DR: 该研究提出利用ChatGPT分析电影简述以构建知识图谱的方法，结果显示可显著提高推荐系统的准确性。


<details>
  <summary>Details</summary>
Motivation: 在电影产业中，用户面临大量可供观看的选项。为了帮助用户找到相关结果，推荐系统分析操作数据并探究用户的喜好和习惯。因此该研究希望通过知识图谱和语义信息提高推荐系统的准确性和个性化。

Method: 研究提出了一种新的方法，利用语义信息构建知识图谱。具体方法是通过ChatGPT，评估电影简述并提取其语音语调。

Result: 结果表明，使用所提出的方法可以显著提高准确性，而不是依赖出版商提供的显性类别。

Conclusion: 通过使用ChatGPT作为大语言模型来评估电影简述并提取其语音语调，提供了一种基于语义信息构建知识图谱的新方法。有结果表明，使用该方法比使用出版商提供的显性类别能够显著提高准确性。

Abstract: The importance of recommender systems on the web has grown, especially in the
movie industry, with a vast selection of options to watch. To assist users in
traversing available items and finding relevant results, recommender systems
analyze operational data and investigate users' tastes and habits. Providing
highly individualized suggestions can boost user engagement and satisfaction,
which is one of the fundamental goals of the movie industry, significantly in
online platforms. According to recent studies and research, using
knowledge-based techniques and considering the semantic ideas of the textual
data is a suitable way to get more appropriate results. This study provides a
new method for building a knowledge graph based on semantic information. It
uses the ChatGPT, as a large language model, to assess the brief descriptions
of movies and extract their tone of voice. Results indicated that using the
proposed method may significantly enhance accuracy rather than employing the
explicit genres supplied by the publishers.

</details>


### [161] [Exploration on Demand: From Algorithmic Control to User Empowerment](https://arxiv.org/abs/2507.21884)
*Edoardo Bianchi*

Main category: cs.IR

TL;DR: 提出了一种自适应聚类框架，通过用户控制的探索在电影推荐中有效平衡个性化和多样性，并在实验中证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决推荐系统中存在的过度专业化的问题，改善用户接触多样化内容的机会，并减少过滤气泡现象。

Method: 利用句子转换器嵌入，通过在线算法和动态阈值将项目分组为语义一致的集群，并进行用户控制的探索。

Result: 实验表明该系统显著降低了推荐列表的相似度，从0.34下降到0.26，同时增加了意想不到的推荐，从0.73上升。

Conclusion: 研究证明该系统能够在不牺牲用户满意度的情况下促进有意义的内容发现。

Abstract: Recommender systems often struggle with over-specialization, which severely
limits users' exposure to diverse content and creates filter bubbles that
reduce serendipitous discovery. To address this fundamental limitation, this
paper introduces an adaptive clustering framework with user-controlled
exploration that effectively balances personalization and diversity in movie
recommendations. Our approach leverages sentence-transformer embeddings to
group items into semantically coherent clusters through an online algorithm
with dynamic thresholding, thereby creating a structured representation of the
content space. Building upon this clustering foundation, we propose a novel
exploration mechanism that empowers users to control recommendation diversity
by strategically sampling from less-engaged clusters, thus expanding their
content horizons while preserving relevance. Experiments on the MovieLens
dataset demonstrate the system's effectiveness, showing that exploration
significantly reduces intra-list similarity from 0.34 to 0.26 while
simultaneously increasing unexpectedness to 0.73. Furthermore, our Large
Language Model-based A/B testing methodology, conducted with 300 simulated
users, reveals that 72.7% of long-term users prefer exploratory recommendations
over purely exploitative ones, providing strong evidence for the system's
ability to promote meaningful content discovery without sacrificing user
satisfaction.

</details>


### [162] [The Curious Case of High-Dimensional Indexing as a File Structure: A Case Study of eCP-FS](https://arxiv.org/abs/2507.21939)
*Omar Shahbaz Khan,Gylfi Þór Guðmundsson,Björn Þór Jónsson*

Main category: cs.IR

TL;DR: eCP-FS通过文件库实现序列化索引，使其更易读，在受限内存条件下具有竞争力，尽管搜索速度较慢。


<details>
  <summary>Details</summary>
Motivation: 随着现代分析管道中深度学习和检索模型的多样化，使用基于近似最近邻（ANN）的索引来支持高效的基于相似性的搜索变得越来越普遍。然而，这些索引需要占用有限的GPU/CPU内存资源，因此需要一种磁盘驱动的索引结构。

Method: 本文研究了一种将数据结构映射到文件结构的替代方法，通过一个文件库使索引对任何编程语言或者人类更加可读。这种方法的缺点是序列化的索引文件会变得冗长，影响搜索性能。提出了一种基于文件的eCP（eCP-FS）实现，并与最先进的索引进行了比较。

Result: 与最先进的索引相比，虽然eCP-FS速度较慢，但在内存不受限的条件下仍具有一定的竞争力。在内存受限的场合，eCP-FS因具有最小的内存占用使其在资源受限或多索引环境中表现出色。

Conclusion: eCP-FS提供了一种在资源或内存受限环境中使用的有效方法，尽管其因冗长的文件而导致搜索变慢，但仍在可接受范围内。

Abstract: Modern analytical pipelines routinely deploy multiple deep learning and
retrieval models that rely on approximate nearest-neighbor (ANN) indexes to
support efficient similarity-based search. While many state-of-the-art
ANN-indexes are memory-based (e.g., HNSW and IVF), using multiple ANN indexes
creates a competition for limited GPU/CPU memory resources, which in turn
necessitates disk-based index structures (e.g., DiskANN or eCP). In typical
index implementations, the main component is a complex data structure that is
serialized to disk and is read either fully at startup time, for memory-based
indexes, or incrementally at query time, for disk-based indexes. To visualize
the index structure, or analyze its quality, complex coding is needed that is
either embedded in the index implementation or replicates the code that reads
the data structure. In this paper, we consider an alternative approach that
maps the data structure to a file structure, using a file library, making the
index easily readable for any programming language and even human-readable. The
disadvantage is that the serialized index is verbose, leading to overhead of
searching through the index. The question addressed in this paper is how severe
this performance penalty is. To that end, this paper presents eCP-FS, a
file-based implementation of eCP, a well-known disk-based ANN index. A
comparison with state-of-the-art indexes shows that while eCP-FS is slower, the
implementation is nevertheless somewhat competitive even when memory is not
constrained. In a memory-constrained scenario, eCP-FS offers a minimal memory
footprint, making it ideal for resource-constrained or multi-index
environments.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [163] [SynLang and Symbiotic Epistemology: A Manifesto for Conscious Human-AI Collaboration](https://arxiv.org/abs/2507.21067)
*Jan Kapusta*

Main category: cs.AI

TL;DR: 本文提出了一种共同体知识论作为人机认知合作的哲学基础，通过SynLang协议实现透明的人机协作，并验证了框架的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前的AI系统依赖于不透明的推理过程，阻碍了人类的监督与协作潜能。

Method: 提出了一种称为Symbiotic Epistemology的理论基础，将AI定位为推理伙伴，并引入了SynLang协议进行透明的人机协作。

Result: 通过实际的人机对话验证框架有效性，展示AI在结构化推理协议中的适应性，以及成功的元认知干预。

Conclusion: 通过将人类信任与AI的可靠性对齐，Symbiotic Epistemology促使通过显式推理模式和信心评估建立校准信任，并促进人机认知合作。

Abstract: Current AI systems rely on opaque reasoning processes that hinder human
oversight and collaborative potential. Conventional explainable AI approaches
offer post-hoc justifications and often fail to establish genuine symbiotic
collaboration. In this paper, the Symbiotic Epistemology is presented as a
philosophical foundation for human-AI cognitive partnerships. Unlike frameworks
that treat AI as a mere tool or replacement, symbiotic epistemology positions
AI as a reasoning partner, fostering calibrated trust by aligning human
confidence with AI reliability through explicit reasoning patterns and
confidence assessments. SynLang (Symbiotic Syntactic Language) is introduced as
a formal protocol for transparent human-AI collaboration. The framework is
empirically validated through actual human-AI dialogues demonstrating AI's
adaptation to structured reasoning protocols and successful metacognitive
intervention. The protocol defines two complementary mechanisms: TRACE for
high-level reasoning patterns and TRACE_FE for detailed factor explanations. It
also integrates confidence quantification, declarative control over AI
behavior, and context inheritance for multi-agent coordination. By structuring
communication and embedding confidence-calibrated transparency, SynLang,
together with symbiotic epistemology, enables AI systems that enhance human
intelligence, preserve human agency, and uphold ethical accountability in
collaborative decision-making. Through dual-level transparency, beginning with
high-level reasoning patterns and progressing to granular explanations, the
protocol facilitates rapid comprehension and supports thorough verification of
AI decision-making.

</details>


### [164] [Artificial intelligence for sustainable wine industry: AI-driven management in viticulture, wine production and enotourism](https://arxiv.org/abs/2507.21098)
*Marta Sidorkiewicz,Karolina Królikowska,Berenika Dyczek,Edyta Pijet-Migon,Anna Dubel*

Main category: cs.AI

TL;DR: AI offers sustainable solutions in viticulture, production, and enotourism by optimizing resources, reducing impacts, and enhancing customer experiences.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore how AI can address environmental and economic challenges in the wine industry by optimizing resource use and improving customer engagement.

Method: The study employs a questionnaire survey of Polish winemakers and a comprehensive analysis of AI methods in viticulture, production, and tourism.

Result: AI technologies such as predictive analytics, machine learning, and computer vision improve vineyard monitoring, irrigation, and production processes. In enotourism, AI enhances personalized experiences through chatbots, recommendation systems, and virtual tastings.

Conclusion: AI enhances sustainability and efficiency in the wine industry through improved resource management, environmental impact reduction, and consumer engagement.

Abstract: This study examines the role of Artificial Intelligence (AI) in enhancing
sustainability and efficiency within the wine industry. It focuses on AI-driven
intelligent management in viticulture, wine production, and enotourism. As the
wine industry faces environmental and economic challenges, AI offers innovative
solutions to optimize resource use, reduce environmental impact, and improve
customer engagement. Understanding AI's potential in sustainable winemaking is
crucial for fostering responsible and efficient industry practices. The
research is based on a questionnaire survey conducted among Polish winemakers,
combined with a comprehensive analysis of AI methods applicable to viticulture,
production, and tourism. Key AI technologies, including predictive analytics,
machine learning, and computer vision, are explored. The findings indicate that
AI enhances vineyard monitoring, optimizes irrigation, and streamlines
production processes, contributing to sustainable resource management. In
enotourism, AI-powered chatbots, recommendation systems, and virtual tastings
personalize consumer experiences. The study highlights AI's impact on economic,
environmental, and social sustainability, supporting local wine enterprises and
cultural heritage. Keywords: Artificial Intelligence, Sustainable Development,
AI-Driven Management, Viticulture, Wine Production, Enotourism, Wine
Enterprises, Local Communities

</details>


### [165] [Leveraging Generative AI to Enhance Synthea Module Development](https://arxiv.org/abs/2507.21123)
*Mark A. Kramer,Aanchal Mathur,Caroline E. Adams,Jason A. Walonoski*

Main category: cs.AI

TL;DR: 使用大规模语言模型助力Synthea模块开发，既能提高数据质量，又存在需要人类监督等挑战。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过使用大规模语言模型（LLMs）来协助开发Synthea的新疾病模块。Synthea是一个开源的合成健康数据生成器。

Method: 本文提出了四种利用LLMs支持Synthea模块创建的方法：生成疾病档案、从疾病档案生成疾病模块、评估现有的Synthea模块以及优化现有模块。并引入了逐步优化的概念，通过迭代评估LLMs生成的模块的语法正确性和临床准确性来修改模块。

Result: 研究结果表明，LLMs在支持Synthea模块创建方面具有潜力，同时也指出了其使用中的挑战和局限性，例如需要人工监督、严格测试与验证的重要性，以及LLMs生成内容中可能存在的不准确性。

Conclusion: 本文认为使用LLM进行合成数据创建虽然有潜力，但仍需克服一些挑战。定期进行验证和人为介入至关重要。

Abstract: This paper explores the use of large language models (LLMs) to assist in the
development of new disease modules for Synthea, an open-source synthetic health
data generator. Incorporating LLMs into the module development process has the
potential to reduce development time, reduce required expertise, expand model
diversity, and improve the overall quality of synthetic patient data. We
demonstrate four ways that LLMs can support Synthea module creation: generating
a disease profile, generating a disease module from a disease profile,
evaluating an existing Synthea module, and refining an existing module. We
introduce the concept of progressive refinement, which involves iteratively
evaluating the LLM-generated module by checking its syntactic correctness and
clinical accuracy, and then using that information to modify the module. While
the use of LLMs in this context shows promise, we also acknowledge the
challenges and limitations, such as the need for human oversight, the
importance of rigorous testing and validation, and the potential for
inaccuracies in LLM-generated content. The paper concludes with recommendations
for future research and development to fully realize the potential of LLM-aided
synthetic data creation.

</details>


### [166] [Measuring and Analyzing Intelligence via Contextual Uncertainty in Large Language Models using Information-Theoretic Metrics](https://arxiv.org/abs/2507.21129)
*Jae Wan Shim*

Main category: cs.AI

TL;DR: 提出了一种通过熵衰减曲线分析大型语言模型认知动态的新方法，实现对模型操作机制的深入理解。


<details>
  <summary>Details</summary>
Motivation: 深入探索大型语言模型内部产生结果的机制，而不仅仅是通过任务特定的基准测试来评估模型能做什么。

Method: 采用无任务依赖的方法，通过"熵衰减曲线"和信息增益跨度（IGS）指数，量化和可视化模型在不同上下文长度下的预测不确定性变化。

Result: 应用该方法对多个先进的LLMs进行分析，发现模型的认知概况在规模和文本复杂性方面具有独特且一致的特征。引入的IGS指数也有效地总结了衰减轨迹的优越性。

Conclusion: 本文提出了一种新的方法，以"熵衰减曲线"为中心，创建模型的"认知概况"，从而为分析和比较人工智能的内在运行动态提供了一种新视角。

Abstract: The remarkable capabilities of Large Language Models (LLMs) are now
extensively documented on task-specific benchmarks, yet the internal mechanisms
that produce these results are the subject of intense scientific inquiry. This
paper contributes to this inquiry by moving beyond metrics that measure
\textit{what} models can do, to a methodology that characterizes \textit{how}
they process information. We introduce a novel, task-agnostic approach to probe
these dynamics by creating a quantitative ``Cognitive Profile" for any given
model. This profile is centered on the \textbf{Entropy Decay Curve}, a
visualization that traces how a model's normalized predictive uncertainty
changes as a function of context length. Applying this methodology to several
state-of-the-art LLMs across diverse texts, we uncover unique and consistent
cognitive profiles that are sensitive to both model scale and text complexity.
We also introduce the Information Gain Span (IGS) index to summarize the
desirability of the decay trajectory. This work thus provides a new, principled
lens for analyzing and comparing the intrinsic operational dynamics of
artificial intelligence.

</details>


### [167] [INTEGRALBENCH: Benchmarking LLMs with Definite Integral Problems](https://arxiv.org/abs/2507.21130)
*Bintao Tang,Xin Yang,Yuhao Wang,Zixuan Qiu,Zimo Ji,Wenyuan Jiang*

Main category: cs.AI

TL;DR: INTEGRALBENCH是用于评估LLM在定积分问题上的表现的基准测试，揭示了模型性能及难度相关性的显著缺口，促进了自动化数学推理。


<details>
  <summary>Details</summary>
Motivation: 研究者们寻求一种方法来评估大规模语言模型（LLM）在处理定积分问题上的性能。

Method: 设计了一种名为INTEGRALBENCH的基准测试，提供符号和数值的标准答案，并附有人工难度标注来评估模型。

Result: 评估了九种最先进的LLM，揭示了显著的性能差距及难度与准确性之间的强相关性，同时建立了该领域的基准指标。

Conclusion: INTEGRALBENCH为定积分计算提供了一个严谨的评估框架，旨在推动自动化数学推理的发展。

Abstract: We present INTEGRALBENCH, a focused benchmark designed to evaluate Large
Language Model (LLM) performance on definite integral problems. INTEGRALBENCH
provides both symbolic and numerical ground truth solutions with manual
difficulty annotations. Our evaluation of nine state-of-the-art LLMs reveals
significant performance gaps and strong correlations between problem difficulty
and model accuracy, establishing baseline metrics for this challenging domain.
INTEGRALBENCH aims to advance automated mathematical reasoning by providing a
rigorous evaluation framework specifically tailored for definite integral
computation.

</details>


### [168] [NPO: Learning Alignment and Meta-Alignment through Structured Human Feedback](https://arxiv.org/abs/2507.21131)
*Madhava Gaikwad,Ashwini Ramchandra Doke*

Main category: cs.AI

TL;DR: NPO是一种增强人机决策系统对齐的学习框架，通过反馈驱动的适应机制实现动态环境中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将对齐视为静态或事后特性，缺乏适应性和可操作性。

Method: 通过场景评分、阈值调整、策略验证和结构化反馈摄取，在可扩展的操作环中实现。

Result: NPO在超大规模部署环境中表现出明显的价值，并且理论收敛结果表明对齐损失和监控保真度可加性收敛。

Conclusion: NPO 提供了一种可操作的学习框架，通过持续监测和调整增强动态环境中的实际可靠性。

Abstract: We present NPO, an alignment-aware learning framework that operationalizes
feedback-driven adaptation in human-in-the-loop decision systems. Unlike prior
approaches that treat alignment as a static or post-hoc property, NPO
introduces a formalization of alignment loss that is measurable, supervisable,
and reducible under structured feedback. In parallel, we propose meta-alignment
as the fidelity of the monitoring process that governs retraining or override
triggers, and show that it is formally reducible to primary alignment via
threshold fidelity. Our implementation spans a scalable operational loop
involving scenario scoring, threshold tuning, policy validation, and structured
feedback ingestion, including "likes", overrides, and abstentions. We provide
formal convergence results under stochastic feedback and show that both
alignment loss and monitoring fidelity converge additively. Empirically, NPO
demonstrates measurable value in hyperscale deployment settings. A
simulation-based artifact and ablation studies further illustrate the
theoretical principles in action. Together, NPO offers a compact, inspectable
architecture for continual alignment monitoring, helping bridge theoretical
alignment guarantees with practical reliability in dynamic environments.

</details>


### [169] [Can You Trust an LLM with Your Life-Changing Decision? An Investigation into AI High-Stakes Responses](https://arxiv.org/abs/2507.21132)
*Joshua Adrian Cahyono,Saran Subramanian*

Main category: cs.AI

TL;DR: LLMs can fail in providing reliable life advice due to sycophancy and over-confidence. Experiments show robust models ask clarifying questions and cautiousness can be controlled.


<details>
  <summary>Details</summary>
Motivation: LLMs are used for critical life advice but lack safeguards, leading to potential risks from erroneous responses.

Method: Conducted three experiments: multiple-choice evaluation, free-response analysis using safety typology, and mechanistic interpretability experiment with a "high-stakes" activation vector.

Result: Some models exhibit sycophancy, others are robust. High safety scores are achieved by models asking clarifying questions. Activation steering can control model cautiousness.

Conclusion: LLMs need nuanced benchmarks to ensure reliability in high-stakes situations, as some models can show sycophancy and over-confidence.

Abstract: Large Language Models (LLMs) are increasingly consulted for high-stakes life
advice, yet they lack standard safeguards against providing confident but
misguided responses. This creates risks of sycophancy and over-confidence. This
paper investigates these failure modes through three experiments: (1) a
multiple-choice evaluation to measure model stability against user pressure;
(2) a free-response analysis using a novel safety typology and an LLM Judge;
and (3) a mechanistic interpretability experiment to steer model behavior by
manipulating a "high-stakes" activation vector. Our results show that while
some models exhibit sycophancy, others like o4-mini remain robust.
Top-performing models achieve high safety scores by frequently asking
clarifying questions, a key feature of a safe, inquisitive approach, rather
than issuing prescriptive advice. Furthermore, we demonstrate that a model's
cautiousness can be directly controlled via activation steering, suggesting a
new path for safety alignment. These findings underscore the need for nuanced,
multi-faceted benchmarks to ensure LLMs can be trusted with life-changing
decisions.

</details>


### [170] [Project Patti: Why can You Solve Diabolical Puzzles on one Sudoku Website but not Easy Puzzles on another Sudoku Website?](https://arxiv.org/abs/2507.21137)
*Arman Eisenkolb-Vaithyanathan*

Main category: cs.AI

TL;DR: 提出两个新度量标准用于数独难度评级，实验表明这些标准在四个网站上与原有难度标注一致，构建通用难度评级系统。


<details>
  <summary>Details</summary>
Motivation: 研究旨在回答是什么构成了不同数独网站的难度评级，并提出统一的难度分类系统以解决跨网站难度标注不一致的问题。

Method: 论文使用两种方法解决每个数独题目。第一种方法将数独题目转换为其对应的可满足性(SAT)问题，并从SAT子句长度分布中导出难度度量。第二种方法将四种流行的数独策略结合到回溯算法中，模拟人类解题过程，并通过计算在随机Nishio算法迭代中应用数独策略的次数来导出第二个难度度量。

Result: 实验结果显示，对于五个数独网站中的四个，所提出的通用分类系统与网站标记难度级别一致。构建的通用分类系统能够将数独题目和不同网站的难度级别分为通用容易、通用中等和通用困难三个类别。

Conclusion: 研究提出了两个新的度量标准来表征数独难度，这些度量标准可以有效地将不同网站的数独难度进行统一分类，使得跨网站的数独难度标注更加一致。

Abstract: In this paper we try to answer the question "What constitutes Sudoku
difficulty rating across different Sudoku websites?" Using two distinct methods
that can both solve every Sudoku puzzle, I propose two new metrics to
characterize Sudoku difficulty. The first method is based on converting a
Sudoku puzzle into its corresponding Satisfiability (SAT) problem. The first
proposed metric is derived from SAT Clause Length Distribution which captures
the structural complexity of a Sudoku puzzle including the number of given
digits and the cells they are in. The second method simulates human Sudoku
solvers by intertwining four popular Sudoku strategies within a backtracking
algorithm called Nishio. The second metric is computed by counting the number
of times Sudoku strategies are applied within the backtracking iterations of a
randomized Nishio. Using these two metrics, I analyze more than a thousand
Sudoku puzzles across five popular websites to characterize every difficulty
level in each website. I evaluate the relationship between the proposed metrics
and website-labeled difficulty levels using Spearman's rank correlation
coefficient, finding strong correlations for 4 out of 5 websites. I construct a
universal rating system using a simple, unsupervised classifier based on the
two proposed metrics. This rating system is capable of classifying both
individual puzzles and entire difficulty levels from the different Sudoku
websites into three categories - Universal Easy, Universal Medium, and
Universal Hard - thereby enabling consistent difficulty mapping across Sudoku
websites. The experimental results show that for 4 out of 5 Sudoku websites,
the universal classification aligns well with website-labeled difficulty
levels. Finally, I present an algorithm that can be used by early Sudoku
practitioners to solve Sudoku puzzles.

</details>


### [171] [The Geometry of Harmfulness in LLMs through Subconcept Probing](https://arxiv.org/abs/2507.21141)
*McNair Shah,Saleena Angeline,Adhitya Rajendra Kumar,Naitik Chheda,Kevin Zhu,Vasu Sharma,Sean O'Brien,Will Cai*

Main category: cs.AI

TL;DR: 研究通过学习线性探针，定义有害子空间，并探究在模型内部消除该空间的有效性，显著降低LLM的有害行为，同时对其效用影响最小。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在最近的发展中表现出了潜在的有害性，因此有必要更好地理解和控制这些有害行为。

Method: 本研究提出了一种多维框架，用于探测和引导模型内部有害内容。具体地，针对55个不同的有害子概念，我们学习了线性探针，试图从模型内部剔除整个有害子空间或子空间的主要方向。

Result: 研究发现，通过主要方向的引导，几乎可以消除有害性，同时功能性下降很小。证明了有害性子空间是低秩的，提示可以通过概念子空间更好地理解和控制LLM的行为。

Conclusion: 本研究展示了通过概念子空间来理解和控制大型语言模型有害行为的潜力，为未来审计和加强此类模型提供了实用工具。

Abstract: Recent advances in large language models (LLMs) have intensified the need to
understand and reliably curb their harmful behaviours. We introduce a
multidimensional framework for probing and steering harmful content in model
internals. For each of 55 distinct harmfulness subconcepts (e.g., racial hate,
employment scams, weapons), we learn a linear probe, yielding 55 interpretable
directions in activation space. Collectively, these directions span a
harmfulness subspace that we show is strikingly low-rank. We then test ablation
of the entire subspace from model internals, as well as steering and ablation
in the subspace's dominant direction. We find that dominant direction steering
allows for near elimination of harmfulness with a low decrease in utility. Our
findings advance the emerging view that concept subspaces provide a scalable
lens on LLM behaviour and offer practical tools for the community to audit and
harden future generations of language models.

</details>


### [172] [Adaptive XAI in High Stakes Environments: Modeling Swift Trust with Multimodal Feedback in Human AI Teams](https://arxiv.org/abs/2507.21158)
*Nishani Fernando,Bahareh Nakisa,Adnan Ahmad,Mohammad Naim Rastgoo*

Main category: cs.AI

TL;DR: 提出了一个使用生理和行为信号的适应性XAI框架，提高在高压环境下的人机协作信任。


<details>
  <summary>Details</summary>
Motivation: 在高压场景中，现有的可解释AI方法提供统一解释，且严重依赖显式反馈机制，这在高压力场景中通常不切实际，亟需解决这一问题。

Method: 采用生理和行为信号（如EEG，ECG和眼动跟踪）来推断用户状态，并支持解释适应。核心是一个多目标的个性化信任估计模型，将工作负荷、压力和情绪映射到动态信任估计。

Result: 通过生理和行为信号促进XAI的解释适应，提高人机协作中的快速信任。

Conclusion: 本文提出了一个适应性XAI的概念框架，通过响应用户的实时认知和情绪状态，非侵入性地增强在高压力环境中的快速信任。

Abstract: Effective human-AI teaming heavily depends on swift trust, particularly in
high-stakes scenarios such as emergency response, where timely and accurate
decision-making is critical. In these time-sensitive and cognitively demanding
settings, adaptive explainability is essential for fostering trust between
human operators and AI systems. However, existing explainable AI (XAI)
approaches typically offer uniform explanations and rely heavily on explicit
feedback mechanisms, which are often impractical in such high-pressure
scenarios. To address this gap, we propose a conceptual framework for adaptive
XAI that operates non-intrusively by responding to users' real-time cognitive
and emotional states through implicit feedback, thereby enhancing swift trust
in high-stakes environments. The proposed adaptive explainability trust
framework (AXTF) leverages physiological and behavioral signals, such as EEG,
ECG, and eye tracking, to infer user states and support explanation adaptation.
At its core is a multi-objective, personalized trust estimation model that maps
workload, stress, and emotion to dynamic trust estimates. These estimates guide
the modulation of explanation features enabling responsive and personalized
support that promotes swift trust in human-AI collaboration. This conceptual
framework establishes a foundation for developing adaptive, non-intrusive XAI
systems tailored to the rigorous demands of high-pressure, time-sensitive
environments.

</details>


### [173] [Adaptive Cluster Collaborativeness Boosts LLMs Medical Decision Support Capacity](https://arxiv.org/abs/2507.21159)
*Zhihao Peng,Liuxin Bao,Shengyuan Liu,Yixuan Yuan*

Main category: cs.AI

TL;DR: 本文提出了一种自适应集群协同方法，通过自我多样性和交叉一致性最大化机制，显著提升了LLMs在医学决策支持场景中的表现，实验结果优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的架构依赖于预定义的LLM集群，在医疗决策支持场景中表现欠佳，因此有必要开发新的方法来提升LLMs的协作效能。

Method: 采用自适应集群协同方法，其中包括自我多样性和交叉一致性最大化机制，以提高LLMs的医疗决策支持能力。

Result: 在NEJMQA和MMLU-Pro-health两个医学数据集上的大量实验表明，提出的方法在多个医学领域中表现出色，特别是在NEJMQA上，在所有学科中均达到公共官方通过分数，特别是在妇产科领域，其准确率为65.47％而GPT-4仅为56.12％。

Conclusion: 所提出的方法显著提升了LLMs在医疗决策支持场景中的表现，通过自我多样性和交叉一致性最大化机制，在不需要训练的条件下优化LLM集群的组件选择。

Abstract: The collaborativeness of large language models (LLMs) has proven effective in
natural language processing systems, holding considerable promise for
healthcare development. However, it lacks explicit component selection rules,
necessitating human intervention or clinical-specific validation. Moreover,
existing architectures heavily rely on a predefined LLM cluster, where partial
LLMs underperform in medical decision support scenarios, invalidating the
collaborativeness of LLMs. To this end, we propose an adaptive cluster
collaborativeness methodology involving self-diversity and cross-consistency
maximization mechanisms to boost LLMs medical decision support capacity. For
the self-diversity, we calculate the fuzzy matching value of pairwise outputs
within an LLM as its self-diversity value, subsequently prioritizing LLMs with
high self-diversity values as cluster components in a training-free manner. For
the cross-consistency, we first measure cross-consistency values between the
LLM with the highest self-diversity value and others, and then gradually mask
out the LLM having the lowest cross-consistency value to eliminate the
potential inconsistent output during the collaborative propagation. Extensive
experiments on two specialized medical datasets, NEJMQA and MMLU-Pro-health,
demonstrate the effectiveness of our method across physician-oriented
specialties. For example, on NEJMQA, our method achieves the accuracy rate up
to the publicly official passing score across all disciplines, especially
achieving ACC of 65.47\% compared to the 56.12\% achieved by GPT-4 on the
Obstetrics and Gynecology discipline.

</details>


### [174] [Large Language Model Powered Automated Modeling and Optimization of Active Distribution Network Dispatch Problems](https://arxiv.org/abs/2507.21162)
*Xu Yang,Chenhui Lin,Yue Yang,Qi Wang,Haotian Liu,Haizhou Hua,Wenchuan Wu*

Main category: cs.AI

TL;DR: 提出了一种由大型语言模型驱动的自动建模和优化方法来提高 ADN 调度的效率，并通过测试验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着分布式能源资源的增加，活跃配电网络的调度变得至关重要，但许多新整合的 ADN 操作员缺乏专业知识，因此依赖人类专家既昂贵又耗时。

Method: 论文提出了一个由大型语言模型驱动的自动建模和优化方法，将 ADN 调度问题分解为多个阶段，并设计了多 LLM 协调架构。

Result: 提出的方法通过简单的自然语言查询，极大地提高了 ADN 操作员的调度效率，验证了框架在多个测试用例下的有效性。

Conclusion: 通过使用大型语言模型来自动化 ADN 调度，可以显著提高调度效率并降低对人类专家的依赖。该框架证明其在各种测试用例中的有效性和可靠性。

Abstract: The increasing penetration of distributed energy resources into active
distribution networks (ADNs) has made effective ADN dispatch imperative.
However, the numerous newly-integrated ADN operators, such as distribution
system aggregators, virtual power plant managers, and end prosumers, often lack
specialized expertise in power system operation, modeling, optimization, and
programming. This knowledge gap renders reliance on human experts both costly
and time-intensive. To address this challenge and enable intelligent, flexible
ADN dispatch, this paper proposes a large language model (LLM) powered
automated modeling and optimization approach. First, the ADN dispatch problems
are decomposed into sequential stages, and a multi-LLM coordination
architecture is designed. This framework comprises an Information Extractor, a
Problem Formulator, and a Code Programmer, tasked with information retrieval,
optimization problem formulation, and code implementation, respectively.
Afterwards, tailored refinement techniques are developed for each LLM agent,
greatly improving the accuracy and reliability of generated content. The
proposed approach features a user-centric interface that enables ADN operators
to derive dispatch strategies via simple natural language queries, eliminating
technical barriers and increasing efficiency. Comprehensive comparisons and
end-to-end demonstrations on various test cases validate the effectiveness of
the proposed architecture and methods.

</details>


### [175] [An ontological analysis of risk in Basic Formal Ontology](https://arxiv.org/abs/2507.21171)
*Federico Donato,Adrien Barton*

Main category: cs.AI

TL;DR: 论文通过BFO分类探索风险的性质，认为其属于角色类别并提供充分条件的分析。


<details>
  <summary>Details</summary>
Motivation: 为了明确风险的充分条件，并区分其作为角色或倾向的分类批判。

Method: 运用BFO的角色分类对风险进行建模，并通过实例推广到整体风险分析。

Result: 识别并阐明了成为风险的充分条件，未来工作将探讨必要条件。

Conclusion: 风险可以被定义为BFO中的一个角色类别，而不是倾向类别。

Abstract: The paper explores the nature of risk, providing a characterization using the
categories of the Basic Formal Ontology (BFO). It argues that the category Risk
is a subclass of BFO:Role, contrasting it with a similar view classifying Risk
as a subclass of BFO:Disposition. This modeling choice is applied on one
example of risk, which represents objects, processes (both physical and mental)
and their interrelations, then generalizing from the instances in the example
to obtain an overall analysis of risk, making explicit what are the sufficient
conditions for being a risk. Plausible necessary conditions are also mentioned
for future work. Index Terms: ontology, risk, BFO, role, disposition

</details>


### [176] [Ontological Foundations of State Sovereignty](https://arxiv.org/abs/2507.21172)
*John Beverley,Danielle Limbaugh*

Main category: cs.AI

TL;DR: 本文探讨了国家主权的性质及处理相关数据的策略，为国际事务本体的应用研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 作者希望通过理论分析，为有关国际事务的应用工作奠定基础，从而促进在国家主权问题上的理解和研究。

Method: 本文采用理论分析的方法来探讨国家主权的性质，以及如何处理关于哪些国家是主权国家的模糊或矛盾的数据。

Result: 本文揭示了一种处理有关国家主权的数据的策略，并为进一步的国际事务本体研究提供了理论支持。

Conclusion: 本文旨在为关于国家主权性质及其重要性提供一个入门指南，并揭示如何处理有关国家主权模糊或自相矛盾的数据的一种策略。

Abstract: This short paper is a primer on the nature of state sovereignty and the
importance of claims about it. It also aims to reveal (merely reveal) a
strategy for working with vague or contradictory data about which states, in
fact, are sovereign. These goals together are intended to set the stage for
applied work in ontology about international affairs.

</details>


### [177] [Tell Me You're Biased Without Telling Me You're Biased -- Toward Revealing Implicit Biases in Medical LLMs](https://arxiv.org/abs/2507.21176)
*Farzana Islam Adiba,Rahmatollah Beheshti*

Main category: cs.AI

TL;DR: 提出了一个新框架，将知识图谱与语言模型相结合，有效揭示医学语言模型中的偏差。


<details>
  <summary>Details</summary>
Motivation: 在临床决策应用中使用语言模型前，识别偏差模式以减轻其影响至关重要。

Method: 结合知识图谱与辅助大型语言模型，采用对抗性扰动技术和定制化多跳知识图谱表征。

Result: 通过综合实验表明，提出的框架能够更好地揭示语言模型的复杂偏差模式。

Conclusion: 该研究提出的框架有效识别医学语言模型中的复杂偏差模式，并优于现有基线方法。

Abstract: Large language models (LLMs) that are used in medical applications are known
to show biased and unfair patterns. Prior to adopting these in clinical
decision-making applications, it is crucial to identify these bias patterns to
enable effective mitigation of their impact. In this study, we present a novel
framework combining knowledge graphs (KGs) with auxiliary LLMs to
systematically reveal complex bias patterns in medical LLMs. Specifically, the
proposed approach integrates adversarial perturbation techniques to identify
subtle bias patterns. The approach adopts a customized multi-hop
characterization of KGs to enhance the systematic evaluation of arbitrary LLMs.
Through a series of comprehensive experiments (on three datasets, six LLMs, and
five bias types), we show that our proposed framework has noticeably greater
ability and scalability to reveal complex biased patterns of LLMs compared to
other baselines.

</details>


### [178] [Agentic Web: Weaving the Next Web with AI Agents](https://arxiv.org/abs/2507.21206)
*Yingxuan Yang,Mulei Ma,Yuxuan Huang,Huacan Chai,Chenyu Gong,Haoran Geng,Yuanjian Zhou,Ying Wen,Meng Fang,Muhao Chen,Shangding Gu,Ming Jin,Costas Spanos,Yang Yang,Pieter Abbeel,Dawn Song,Weinan Zhang,Jun Wang*

Main category: cs.AI

TL;DR: 本文探讨了Agentic Web的技术基础、架构挑战及未来发展方向，并提供了一份关于代理网络的相关研究合集。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型驱动的人工智能代理的出现，互联网正向Agentic Web转变，这一阶段以自主、目标驱动的交互为特点。

Method: 本文提出了一个理解和构建Agentic Web的结构化框架，并追溯其从PC和移动互联网时代的发展历程。

Result: 分析了创建可扩展代理系统所涉及的架构和基础设施挑战，包括通信协议、编排策略、以及Agent Attention Economy等新兴范式。

Conclusion: 通过探讨代理系统的潜在应用、社会风险和治理问题，提出了发展开放、安全及智能生态系统的研究方向。

Abstract: The emergence of AI agents powered by large language models (LLMs) marks a
pivotal shift toward the Agentic Web, a new phase of the internet defined by
autonomous, goal-driven interactions. In this paradigm, agents interact
directly with one another to plan, coordinate, and execute complex tasks on
behalf of users. This transition from human-driven to machine-to-machine
interaction allows intent to be delegated, relieving users from routine digital
operations and enabling a more interactive, automated web experience. In this
paper, we present a structured framework for understanding and building the
Agentic Web. We trace its evolution from the PC and Mobile Web eras and
identify the core technological foundations that support this shift. Central to
our framework is a conceptual model consisting of three key dimensions:
intelligence, interaction, and economics. These dimensions collectively enable
the capabilities of AI agents, such as retrieval, recommendation, planning, and
collaboration. We analyze the architectural and infrastructural challenges
involved in creating scalable agentic systems, including communication
protocols, orchestration strategies, and emerging paradigms such as the Agent
Attention Economy. We conclude by discussing the potential applications,
societal risks, and governance issues posed by agentic systems, and outline
research directions for developing open, secure, and intelligent ecosystems
shaped by both human intent and autonomous agent behavior. A continuously
updated collection of relevant studies for agentic web is available at:
https://github.com/SafeRL-Lab/agentic-web.

</details>


### [179] [CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting](https://arxiv.org/abs/2507.21257)
*David Maria Schmidt,Raoul Schubert,Philipp Cimiano*

Main category: cs.AI

TL;DR: 文章研究大型语言模型解读问题的组合性，生成多个数据集进行测试，结果显示其在解读复杂问题上存在困难。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型在问题解读能力方面的组合性。

Method: 生成三个难度不同的数据集，通过实验测试和评估LLM解读复杂问题的能力。使用不同大小的模型进行实验，应用各种提示和少样本优化技术以及微调。

Result: 随着偏离样本优化程度的增加，宏F1性能从0.45下降到0.26，再到0.09。即使在输入中提供所有必要信息，最低复杂性数据集的F1得分也未超过0.57。

Conclusion: LLMs struggle to systematically and compositionally interpret questions and map them into SPARQL queries.

Abstract: Language interpretation is a compositional process, in which the meaning of
more complex linguistic structures is inferred from the meaning of their parts.
Large language models possess remarkable language interpretation capabilities
and have been successfully applied to interpret questions by mapping them to
SPARQL queries. An open question is how systematic this interpretation process
is. Toward this question, in this paper, we propose a benchmark for
investigating to what extent the abilities of LLMs to interpret questions are
actually compositional. For this, we generate three datasets of varying
difficulty based on graph patterns in DBpedia, relying on Lemon lexica for
verbalization. Our datasets are created in a very controlled fashion in order
to test the ability of LLMs to interpret structurally complex questions, given
that they have seen the atomic building blocks. This allows us to evaluate to
what degree LLMs are able to interpret complex questions for which they
"understand" the atomic parts. We conduct experiments with models of different
sizes using both various prompt and few-shot optimization techniques as well as
fine-tuning. Our results show that performance in terms of macro $F_1$ degrades
from $0.45$ over $0.26$ down to $0.09$ with increasing deviation from the
samples optimized on. Even when all necessary information was provided to the
model in the input, the $F_1$ scores do not exceed $0.57$ for the dataset of
lowest complexity. We thus conclude that LLMs struggle to systematically and
compositionally interpret questions and map them into SPARQL queries.

</details>


### [180] [LeMix: Unified Scheduling for LLM Training and Inference on Multi-GPU Systems](https://arxiv.org/abs/2507.21276)
*Yufei Li,Zexin Li,Yinglun Zhu,Cong Liu*

Main category: cs.AI

TL;DR: LeMix系统通过对服务和训练工作负载的联合管理，提高了LLM的资源利用率和服务响应性能。


<details>
  <summary>Details</summary>
Motivation: 在当前大规模语言模型的部署中，推理服务和持续再训练通常分离进行，这导致了资源利用效率低下以及新数据的适应延迟。

Method: LeMix系统通过离线分析、执行预测机制和运行时调度，实现资源的动态分配。

Result: LeMix系统使得吞吐量最高提高3.53倍，推理损失减少到0.61倍，响应时间服务等级目标达成率提升到2.12倍。

Conclusion: LeMix通过资源动态分配，提高了LLM的利用率和服务质量，同时不影响服务响应速度。

Abstract: Modern deployment of large language models (LLMs) frequently involves both
inference serving and continuous retraining to stay aligned with evolving data
and user feedback. Common practices separate these workloads onto distinct
servers in isolated phases, causing substantial inefficiencies (e.g., GPU
idleness) and delayed adaptation to new data in distributed settings. Our
empirical analysis reveals that these inefficiencies stem from dynamic request
arrivals during serving and workload heterogeneity in pipeline-parallel
training. To address these challenges, we propose LeMix, a system for
co-locating and managing concurrent LLM serving and training workloads. LeMix
integrates offline profiling, execution prediction mechanisms, and runtime
scheduling to dynamically adapt resource allocation based on workload
characteristics and system conditions. By understanding task-specific behaviors
and co-execution interference across shared nodes, LeMix improves utilization
and serving quality without compromising serving responsiveness. Our evaluation
shows that LeMix improves throughput by up to 3.53x, reduces inference loss by
up to 0.61x, and delivers up to 2.12x higher response time SLO attainment over
traditional separate setups. To our knowledge, this is the first work to
uncover and exploit the opportunities of joint LLM inference and training,
paving the way for more resource-efficient deployment of LLMs in production
environments.

</details>


### [181] [Curiosity by Design: An LLM-based Coding Assistant Asking Clarification Questions](https://arxiv.org/abs/2507.21285)
*Harsh Darji,Thibaud Lutellier*

Main category: cs.AI

TL;DR: 开发了一种能够通过澄清问题改进代码生成的LLM辅助工具，效果优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 提升代码生成的准确度和用户意图推断能力。

Method: 构建了一个端到端系统，包括用于检测不清楚查询的查询分类器和生成澄清问题的微调LLM。

Result: 微调LLM在生成澄清问题方面优于标准零样本提示。用户研究表明，该模型生成的澄清问题优于基线。

Conclusion: 通过生成澄清问题，可以提供更准确和有帮助的代码响应，提升了代码助手的性能。

Abstract: Large Language Models (LLMs) are increasingly used as coding assistants.
However, the ambiguity of the developer's prompt often leads to incorrect code
generation, as current models struggle to infer user intent without extensive
prompt engineering or external context. This work aims to build an LLM-based
coding assistant that mimics the human code review process by asking
clarification questions when faced with ambiguous or under-specified queries.
  Our end-to-end system includes (1) a query classifier trained to detect
unclear programming-related queries and (2) a fine-tuned LLM that generates
clarification questions. Our evaluation shows that the fine-tuned LLM
outperforms standard zero-shot prompting in generating useful clarification
questions. Furthermore, our user study indicates that users find the
clarification questions generated by our model to outperform the baseline,
demonstrating that our coding assistant produces more accurate and helpful code
responses compared to baseline coding assistants.

</details>


### [182] [Structured Relevance Assessment for Robust Retrieval-Augmented Language Models](https://arxiv.org/abs/2507.21287)
*Aryan Raj,Astitva Veer Garg,Anitha D*

Main category: cs.AI

TL;DR: 该论文提出了一种框架，通过多维评分系统增强 RALM 的稳健性，并显著降低幻觉率。


<details>
  <summary>Details</summary>
Motivation: 减少 RALMs 在文档相关性评估和知识整合方面的事实错误，尤其是在动态环境中提高问答系统的可靠性。

Method: 使用多维评分系统，通过考虑语义匹配和源可靠性，通过基于嵌入的相关性评分和混合质量文档的合成训练数据来实现。进行了针对特定主题的专门基准测试，研发了知识整合机制，并实施了针对知识覆盖不足查询的“未知”响应协议。

Result: 初步评估显示显著降低了幻觉率，并改善了推理过程中的透明度。

Conclusion: 该论文提出了一种框架，通过改进文档评估、知识整合以及对不可回答查询的有效处理，增强了检索增强语言模型（RALM）的稳健性。

Abstract: Retrieval-Augmented Language Models (RALMs) face significant challenges in
reducing factual errors, particularly in document relevance evaluation and
knowledge integration. We introduce a framework for structured relevance
assessment that enhances RALM robustness through improved document evaluation,
balanced intrinsic and external knowledge integration, and effective handling
of unanswerable queries. Our approach employs a multi-dimensional scoring
system that considers both semantic matching and source reliability, utilizing
embedding-based relevance scoring and synthetic training data with
mixed-quality documents. We implement specialized benchmarking on niche topics,
a knowledge integration mechanism, and an "unknown" response protocol for
queries with insufficient knowledge coverage. Preliminary evaluations
demonstrate significant reductions in hallucination rates and improved
transparency in reasoning processes. Our framework advances the development of
more reliable question-answering systems capable of operating effectively in
dynamic environments with variable data quality. While challenges persist in
accurately distinguishing credible information and balancing system latency
with thoroughness, this work represents a meaningful step toward enhancing RALM
reliability.

</details>


### [183] [Games Agents Play: Towards Transactional Analysis in LLM-based Multi-Agent Systems](https://arxiv.org/abs/2507.21354)
*Monika Zamojska,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 本文介绍了一种名为Trans-ACT的新方法，将交易分析原则引入多智能体系统，以生成具有现实心理动力学的智能体，并通过实验展示了在社交互动中的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统在模拟人类社交互动时，缺乏对人类行为认知复杂性的考虑，因此需要一种能够捕捉人类心理动态的新方法。

Method: 引入Trans-ACT（交易分析认知工具包），将交易分析（TA）原理嵌入多智能体系统中，构建具有父母、自我和儿童三种自我状态的认知结构。每种自我状态从特定情境的记忆中获取信息，并据此对新情况作出回应。

Result: 实验模拟结果表明，引入TA原则的智能体在认知和TA原理的引导下，产生了更具深度并且情境感知更强的互动。

Conclusion: Trans-ACT通过将TA原则引入多智能体系统，用于模拟具有现实心理动力学的人类行为，证明了其在社交交互上的有效性和深度。

Abstract: Multi-Agent Systems (MAS) are increasingly used to simulate social
interactions, but most of the frameworks miss the underlying cognitive
complexity of human behavior. In this paper, we introduce Trans-ACT
(Transactional Analysis Cognitive Toolkit), an approach embedding Transactional
Analysis (TA) principles into MAS to generate agents with realistic
psychological dynamics. Trans-ACT integrates the Parent, Adult, and Child ego
states into an agent's cognitive architecture. Each ego state retrieves
context-specific memories and uses them to shape response to new situations.
The final answer is chosen according to the underlying life script of the
agent. Our experimental simulation, which reproduces the Stupid game scenario,
demonstrates that agents grounded in cognitive and TA principles produce deeper
and context-aware interactions. Looking ahead, our research opens a new way for
a variety of applications, including conflict resolution, educational support,
and advanced social psychology studies.

</details>


### [184] [Efficacy of AI RAG Tools for Complex Information Extraction and Data Annotation Tasks: A Case Study Using Banks Public Disclosures](https://arxiv.org/abs/2507.21360)
*Nicholas Botti,Flora Haberkorn,Charlotte Hoopes,Shaun Khan*

Main category: cs.AI

TL;DR: AI工具可以显著加快复杂注释任务的执行速度，并提高准确性，特别是在交互使用条件下，可以节省大量时间。


<details>
  <summary>Details</summary>
Motivation: 理解AI检索增强生成工具在信息提取和数据注释任务中的效果。

Method: 使用被试内设计和随机任务分配进行研究，模拟真实世界的复杂注释任务，测试了一种"幼稚"AI使用条件和一种"交互"AI处理条件。

Result: AI工具在执行任务上加速高达10倍，并提升了准确性，交互条件下尤为明显，预测可节省268小时。此外，注释者的技能也影响表现。

Conclusion: 使用AI工具可以显著加快信息提取和数据注释任务的执行速度，尤其在交互条件下，并提高任务的准确性。

Abstract: We utilize a within-subjects design with randomized task assignments to
understand the effectiveness of using an AI retrieval augmented generation
(RAG) tool to assist analysts with an information extraction and data
annotation task. We replicate an existing, challenging real-world annotation
task with complex multi-part criteria on a set of thousands of pages of public
disclosure documents from global systemically important banks (GSIBs) with
heterogeneous and incomplete information content. We test two treatment
conditions. First, a "naive" AI use condition in which annotators use only the
tool and must accept the first answer they are given. And second, an
"interactive" AI treatment condition where annotators use the tool
interactively, and use their judgement to follow-up with additional information
if necessary. Compared to the human-only baseline, the use of the AI tool
accelerated task execution by up to a factor of 10 and enhanced task accuracy,
particularly in the interactive condition. We find that when extrapolated to
the full task, these methods could save up to 268 hours compared to the
human-only approach. Additionally, our findings suggest that annotator skill,
not just with the subject matter domain, but also with AI tools, is a factor in
both the accuracy and speed of task performance.

</details>


### [185] [Optimizing Multi-Tier Supply Chain Ordering with LNN+XGBoost: Mitigating the Bullwhip Effect](https://arxiv.org/abs/2507.21383)
*Chunan Tong*

Main category: cs.AI

TL;DR: 研究提出混合LNN和XGBoost模型优化多级供应链订购策略，缓解牛鞭效应，提高盈利能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以应对动态市场条件，而液体神经网络（LNN）由于其适应性、低计算成本和对噪声的鲁棒性，适合实时决策和边缘计算。然而，其在供应链优化中的潜力未被充分探索。

Method: 该研究引入了液体神经网络（LNN）与XGBoost模型的结合，通过LNN的动态特征提取和XGBoost的全局优化能力来优化供应链管理中的订购策略。

Result: 混合模型利用LNN和XGBoost的本地和全局协同效应，成功解决了供应链管理中的适应性和效率问题。

Conclusion: 研究提出的混合LNN和XGBoost模型能够有效地优化多级供应链的订购策略，缓解牛鞭效应，提高整体盈利能力。

Abstract: Supply chain management faces significant challenges, including demand
fluctuations, inventory imbalances, and amplified upstream order variability
due to the bullwhip effect. Traditional methods, such as simple moving
averages, struggle to address dynamic market conditions. Emerging machine
learning techniques, including LSTM, reinforcement learning, and XGBoost, offer
potential solutions but are limited by computational complexity, training
inefficiencies, or constraints in time-series modeling. Liquid Neural Networks,
inspired by dynamic biological systems, present a promising alternative due to
their adaptability, low computational cost, and robustness to noise, making
them suitable for real-time decision-making and edge computing. Despite their
success in applications like autonomous vehicles and medical monitoring, their
potential in supply chain optimization remains underexplored. This study
introduces a hybrid LNN and XGBoost model to optimize ordering strategies in
multi-tier supply chains. By leveraging LNN's dynamic feature extraction and
XGBoost's global optimization capabilities, the model aims to mitigate the
bullwhip effect and enhance cumulative profitability. The research investigates
how local and global synergies within the hybrid framework address the dual
demands of adaptability and efficiency in SCM. The proposed approach fills a
critical gap in existing methodologies, offering an innovative solution for
dynamic and efficient supply chain management.

</details>


### [186] [Teaching Language Models To Gather Information Proactively](https://arxiv.org/abs/2507.21389)
*Tenghao Huang,Sihao Chen,Muhao Chen,Jonathan May,Longqi Yang,Mengting Wan,Pei Zhou*

Main category: cs.AI

TL;DR: 引入主动信息收集任务，通过强化微调提升LLMs在不完整信息下的主动提问能力，提升协作性，与o3-mini相比，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 当前的LLMs在面临信息不完整或未指定的提示时，往往缺乏主动获取关键信息从而提供高质量解决方案的能力。

Method: 设计了一个可扩展的框架来生成部分特定的真实任务，利用强化微调策略来奖励能提取隐含用户信息的问题。

Result: 训练的Qwen-2.5-7B模型在自动评估指标上优于o3-mini 18%，在人类评估中，生成的澄清问题和最终提纲分别受到42%和28%的人类注释者的青睐。

Conclusion: 我们的方法可以显著提升LLMs在信息不完整时主动获取信息的能力，使其成为真正的协作伙伴。

Abstract: Large language models (LLMs) are increasingly expected to function as
collaborative partners, engaging in back-and-forth dialogue to solve complex,
ambiguous problems. However, current LLMs often falter in real-world settings,
defaulting to passive responses or narrow clarifications when faced with
incomplete or under-specified prompts, falling short of proactively gathering
the missing information that is crucial for high-quality solutions. In this
work, we introduce a new task paradigm: proactive information gathering, where
LLMs must identify gaps in the provided context and strategically elicit
implicit user knowledge through targeted questions. To systematically study and
train this capability, we design a scalable framework that generates partially
specified, real-world tasks, masking key information and simulating authentic
ambiguity. Within this setup, our core innovation is a reinforcement finetuning
strategy that rewards questions that elicit genuinely new, implicit user
information -- such as hidden domain expertise or fine-grained requirements --
that would otherwise remain unspoken. Experiments demonstrate that our trained
Qwen-2.5-7B model significantly outperforms o3-mini by 18% on automatic
evaluation metrics. More importantly, human evaluation reveals that
clarification questions and final outlines generated by our model are favored
by human annotators by 42% and 28% respectively. Together, these results
highlight the value of proactive clarification in elevating LLMs from passive
text generators to genuinely collaborative thought partners.

</details>


### [187] [Shapley Uncertainty in Natural Language Generation](https://arxiv.org/abs/2507.21406)
*Meilin Zhu,Gaojie Jin,Xiaowei Huang,Lijun Zhang*

Main category: cs.AI

TL;DR: 该论文提出一种Shapley-based不确定性度量方法，可更准确预测LLM在问答任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 面对问答任务时，确定何时信任输出对于大语言模型的对齐至关重要。作者提出更为细致的度量框架来替代简单的语义阈值。

Method: 开发了一种基于Shapley的细化不确定性度量方法，该方法捕捉语义关系的连续性质并满足三个基本属性。

Result: 通过大量实验，显示Shapley不确定性度量较同类基线方法更有效预测LLM性能。

Conclusion: 我们的Shapley不确定性度量在预测LLM在问答任务中的性能方面更准确。

Abstract: In question-answering tasks, determining when to trust the outputs is crucial
to the alignment of large language models (LLMs). Kuhn et al. (2023) introduces
semantic entropy as a measure of uncertainty, by incorporating linguistic
invariances from the same meaning. It primarily relies on setting threshold to
measure the level of semantic equivalence relation. We propose a more nuanced
framework that extends beyond such thresholding by developing a Shapley-based
uncertainty metric that captures the continuous nature of semantic
relationships. We establish three fundamental properties that characterize
valid uncertainty metrics and prove that our Shapley uncertainty satisfies
these criteria. Through extensive experiments, we demonstrate that our Shapley
uncertainty more accurately predicts LLM performance in question-answering and
other datasets, compared to similar baseline measures.

</details>


### [188] [Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects](https://arxiv.org/abs/2507.21407)
*Yixin Liu,Guibin Zhang,Kun Wang,Shiyuan Li,Shirui Pan*

Main category: cs.AI

TL;DR: 本文综述了图增强LLM代理的最新进展，分类现有方法及其对LLM代理系统的贡献，并提出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 自主代理基于大型语言模型（LLM）在多个应用领域表现出强大的能力，但在一些关键程序上仍有限制，图可以作为增强复杂代理工作流的强大结构。

Method: 本文根据LLM代理系统中GLA的主要功能对现有方法进行分类，并分析图和图学习算法如何对每个功能施加影响。

Result: 本文通过对GLA解决方案在多代理系统中的协作、效率优化和可靠性方面的贡献进行讨论，展示了图在LLM代理系统中的重要角色。

Conclusion: 本文为图增强LLM代理（GLA）的研究提供了全面的概述，并指出了未来研究的重要方向，旨在促进GLA领域的进步。

Abstract: Autonomous agents based on large language models (LLMs) have demonstrated
impressive capabilities in a wide range of applications, including web
navigation, software development, and embodied control. While most LLMs are
limited in several key agentic procedures, such as reliable planning, long-term
memory, tool management, and multi-agent coordination, graphs can serve as a
powerful auxiliary structure to enhance structure, continuity, and coordination
in complex agent workflows. Given the rapid growth and fragmentation of
research on Graph-augmented LLM Agents (GLA), this paper offers a timely and
comprehensive overview of recent advances and also highlights key directions
for future work. Specifically, we categorize existing GLA methods by their
primary functions in LLM agent systems, including planning, memory, and tool
usage, and then analyze how graphs and graph learning algorithms contribute to
each. For multi-agent systems, we further discuss how GLA solutions facilitate
the orchestration, efficiency optimization, and trustworthiness of MAS.
Finally, we highlight key future directions to advance this field, from
improving structural adaptability to enabling unified, scalable, and multimodal
GLA systems. We hope this paper can serve as a roadmap for future research on
GLA and foster a deeper understanding of the role of graphs in LLM agent
systems.

</details>


### [189] [GovRelBench:A Benchmark for Government Domain Relevance](https://arxiv.org/abs/2507.21419)
*Haiquan Wang,Yi Chen,Shang Zeng,Yun Bian,Zhe Cui*

Main category: cs.AI

TL;DR: 为了更好评估政府领域大型语言模型的核心能力，本文提出了GovRelBench及其评价工具GovRelBERT，并通过SoftGovScore方法优化评估。


<details>
  <summary>Details</summary>
Motivation: 当前在政府领域对大型语言模型的评估主要集中在特定场景的安全考虑上，而对模型自身核心能力尤其是领域相关性的评估仍显不足。

Method: 采用基于ModernBERT架构的SoftGovScore方法，将硬标签转换为软分数，从而训练GovRelBERT模型，以准确计算文本的政府领域相关性得分。

Result: GovRelBench基准包括政府领域的提示语以及一个专门的评估工具GovRelBERT，提升了大型模型在政府领域的能力评估框架。

Conclusion: 本文提出了GovRelBench，这是一种专门为评估政府领域的大型语言模型核心能力而设计的基准。

Abstract: Current evaluations of LLMs in the government domain primarily focus on
safety considerations in specific scenarios, while the assessment of the
models' own core capabilities, particularly domain relevance, remains
insufficient. To address this gap, we propose GovRelBench, a benchmark
specifically designed for evaluating the core capabilities of LLMs in the
government domain. GovRelBench consists of government domain prompts and a
dedicated evaluation tool, GovRelBERT. During the training process of
GovRelBERT, we introduce the SoftGovScore method: this method trains a model
based on the ModernBERT architecture by converting hard labels to soft scores,
enabling it to accurately compute the text's government domain relevance score.
This work aims to enhance the capability evaluation framework for large models
in the government domain, providing an effective tool for relevant research and
practice. Our code and dataset are available at
https://github.com/pan-xi/GovRelBench.

</details>


### [190] [Evo-DKD: Dual-Knowledge Decoding for Autonomous Ontology Evolution in Large Language Models](https://arxiv.org/abs/2507.21438)
*Vishal Raman,Vijai Aravindh R*

Main category: cs.AI

TL;DR: Evo-DKD通过双解码器框架和动态注意力机制，实现自主本体演化，优于仅结构化或非结构化方法。


<details>
  <summary>Details</summary>
Motivation: 本体和知识图谱需要不断演化以保持全面性和准确性，但手动编纂工作量大。大型语言模型具有广泛的非结构化知识，但维护结构一致性存在困难。

Method: Evo-DKD采用一种新的双解码器框架，结合结构化本体遍历与非结构化文本推理，通过动态注意力门控机制协调两个解码流，在每一步决定如何融合结构化和非结构化知识。

Result: Evo-DKD在医疗保健本体改进、语义搜索提升和文化遗产时间线建模等用例上展示了其有效性，实验结果显示该方法超越了仅使用结构化或非结构化解码的基线。

Conclusion: Evo-DKD提供了一种结合符号和神经推理的新范式，用于可持续的本体演化。与仅使用结构化或非结构化解码的基线相比，该方法在本体更新精度和下游任务性能上表现更佳。

Abstract: Ontologies and knowledge graphs require continuous evolution to remain
comprehensive and accurate, but manual curation is labor intensive. Large
Language Models (LLMs) possess vast unstructured knowledge but struggle with
maintaining structured consistency. We propose Evo-DKD, a novel dual-decoder
framework for autonomous ontology evolution that combines structured ontology
traversal with unstructured text reasoning. Evo-DKD introduces two parallel
decoding streams within an LLM: one decoder generates candidate ontology edits
(e.g., new concepts or relations) while the other produces natural-language
justifications. A dynamic attention-based gating mechanism coordinates the two
streams, deciding at each step how to blend structured and unstructured
knowledge. Due to GPU constraints, we simulate the dual-decoder behavior using
prompt-based mode control to approximate coordinated decoding in a
single-stream mode. The system operates in a closed reasoning loop: proposed
ontology edits are validated (via consistency checks and cross-verification
with the text explanations) and then injected into the knowledge base, which in
turn informs subsequent reasoning. We demonstrate Evo-DKD's effectiveness on
use cases including healthcare ontology refinement, semantic search
improvement, and cultural heritage timeline modeling. Experiments show that
Evo-DKD outperforms baselines using structured-only or unstructured-only
decoding in both precision of ontology updates and downstream task performance.
We present quantitative metrics and qualitative examples, confirming the
contributions of the dual-decoder design and gating router. Evo-DKD offers a
new paradigm for LLM-driven knowledge base maintenance, combining the strengths
of symbolic and neural reasoning for sustainable ontology evolution.

</details>


### [191] [Validating Pharmacogenomics Generative Artificial Intelligence Query Prompts Using Retrieval-Augmented Generation (RAG)](https://arxiv.org/abs/2507.21453)
*Ashley Rector,Keaton Minor,Kamden Minor,Jeff McCormack,Beth Breeden,Ryan Nowers,Jay Dorris*

Main category: cs.AI

TL;DR: 研究验证了Sherpa Rx在药物基因组学中的表现，结合CPIC和PharmGKB资源后，该AI工具在准确性和性能上有显著提升，且在实际应用中优于其他模型。


<details>
  <summary>Details</summary>
Motivation: 验证Sherpa Rx作为人工智能工具在药物基因组学中利用大型语言模型和检索增强生成（RAG）方法的关键响应指标的性能。

Method: 采用两个阶段的实验，第一阶段嵌入CPIC数据，第二阶段则加入PharmGKB内容进行评估，使用Wilcoxon符号秩检验比较两个阶段及与ChatGPT-4omini的准确性。

Result: Sherpa Rx在真实世界应用中表现出色，显示高准确性（90%），在各方面超过其他模型，尤其在Phase 2中显著优于ChatGPT-4omini。

Conclusion: 研究表明，像Sherpa Rx这样的生成式AI在药物基因组学中具有变革潜力，通过提供准确、个性化的响应来改善决策制定。

Abstract: This study evaluated Sherpa Rx, an artificial intelligence tool leveraging
large language models and retrieval-augmented generation (RAG) for
pharmacogenomics, to validate its performance on key response metrics. Sherpa
Rx integrated Clinical Pharmacogenetics Implementation Consortium (CPIC)
guidelines with Pharmacogenomics Knowledgebase (PharmGKB) data to generate
contextually relevant responses. A dataset (N=260 queries) spanning 26 CPIC
guidelines was used to evaluate drug-gene interactions, dosing recommendations,
and therapeutic implications. In Phase 1, only CPIC data was embedded. Phase 2
additionally incorporated PharmGKB content. Responses were scored on accuracy,
relevance, clarity, completeness (5-point Likert scale), and recall. Wilcoxon
signed-rank tests compared accuracy between Phase 1 and Phase 2, and between
Phase 2 and ChatGPT-4omini. A 20-question quiz assessed the tool's real-world
applicability against other models. In Phase 1 (N=260), Sherpa Rx demonstrated
high performance of accuracy 4.9, relevance 5.0, clarity 5.0, completeness 4.8,
and recall 0.99. The subset analysis (N=20) showed improvements in accuracy
(4.6 vs. 4.4, Phase 2 vs. Phase 1 subset) and completeness (5.0 vs. 4.8).
ChatGPT-4omini performed comparably in relevance (5.0) and clarity (4.9) but
lagged in accuracy (3.9) and completeness (4.2). Differences in accuracy
between Phase 1 and Phase 2 was not statistically significant. However, Phase 2
significantly outperformed ChatGPT-4omini. On the 20-question quiz, Sherpa Rx
achieved 90% accuracy, outperforming other models. Integrating additional
resources like CPIC and PharmGKB with RAG enhances AI accuracy and performance.
This study highlights the transformative potential of generative AI like Sherpa
Rx in pharmacogenomics, improving decision-making with accurate, personalized
responses.

</details>


### [192] [An LLM Driven Agent Framework for Automated Infrared Spectral Multi Task Reasoning](https://arxiv.org/abs/2507.21471)
*Zujie Xie,Zixuan Chen,Jiheng Liang,Xiangyang Yu,Ziru Yu*

Main category: cs.AI

TL;DR: 研究采用LLM框架解决低数据条件下红外光谱分析的挑战，显著优于传统机器学习和深度学习方法。


<details>
  <summary>Details</summary>
Motivation: 红外光谱分析具有潜力，但由于光谱复杂性而面临挑战。LLM模型具备推理和泛化能力，可自动化科学工作流，但在红外光谱分析中的应用尚未开发。此研究旨在解决低数据条件下自动红外光谱解释的挑战。

Method: 引入一个端到端的LLM驱动框架，集成了结构化文献知识库、自动化光谱预处理、特征提取以及多任务推理。通过查询经过同行评审的红外文献，系统自动选择验证过的方法来处理光谱数据。使用闭环、多轮协议动态优化预测。

Result: 在多种材料的数据集中，该多轮LLM框架实现了优于单轮推理的效果，在低数据条件下与机器学习和深度学习模型相媲美甚至超越。

Conclusion: 使用LLM框架进行红外光谱分析在低数据条件下表现优越，超过了传统的机器学习和深度学习模型。

Abstract: Infrared spectroscopy offers rapid, non destructive measurement of chemical
and material properties but suffers from high dimensional, overlapping spectral
bands that challenge conventional chemometric approaches. Emerging large
language models (LLMs), with their capacity for generalization and reasoning,
offer promising potential for automating complex scientific workflows. Despite
this promise, their application in IR spectral analysis remains largely
unexplored. This study addresses the critical challenge of achieving accurate,
automated infrared spectral interpretation under low-data conditions using an
LLM-driven framework. We introduce an end-to-end, large language model driven
agent framework that integrates a structured literature knowledge base,
automated spectral preprocessing, feature extraction, and multi task reasoning
in a unified pipeline. By querying a curated corpus of peer reviewed IR
publications, the agent selects scientifically validated routines. The selected
methods transform each spectrum into low dimensional feature sets, which are
fed into few shot prompt templates for classification, regression, and anomaly
detection. A closed loop, multi turn protocol iteratively appends mispredicted
samples to the prompt, enabling dynamic refinement of predictions. Across
diverse materials: stamp pad ink, Chinese medicine, Pu'er tea, Citri
Reticulatae Pericarpium and waste water COD datasets, the multi turn LLM
consistently outperforms single turn inference, rivaling or exceeding machine
learning and deep learning models under low data regimes.

</details>


### [193] [Learning to Imitate with Less: Efficient Individual Behavior Modeling in Chess](https://arxiv.org/abs/2507.21488)
*Zhenwei Tang,Difan Jiao,Eric Xue,Reid McIlroy-Young,Jon Kleinberg,Siddhartha Sen,Ashton Anderson*

Main category: cs.AI

TL;DR: Maia4All是一个个性化人类决策建模框架，通过两阶段优化和仅用20盘棋，实现高效和高保真的人类行为预测，适用于多种AI系统的个性化适配。


<details>
  <summary>Details</summary>
Motivation: 随着人们希望与人工智能（AI）系统进行合作、学习和更好地理解，开发能够准确模拟个体决策的AI变得愈发重要。

Method: Maia4All采用两阶段优化过程：（1）丰富步骤，通过原型丰富模型桥接群体和个体行为建模；（2）民主化步骤，利用能力水平或用户原型以最小数据初始化和优化个体嵌入。

Result: 实验结果表明，Maia4All能够高保真度地预测个人举动和分析行为模式，树立了个性化AI行为建模的新标准。

Conclusion: Maia4All可有效预测个人棋步和行为模式，其个性化建模效率高，仅需20盘棋即可进行人类行为建模，相较于以往需要的5000盘棋显著提升了数据效率。

Abstract: As humans seek to collaborate with, learn from, and better understand
artificial intelligence systems, developing AIs that can accurately emulate
individual decision-making becomes increasingly important. Chess, a
long-standing AI benchmark with precise skill measurement, offers an ideal
testbed for human-AI alignment. However, existing approaches to modeling human
behavior require prohibitively large amounts of data from each individual,
making them impractical for new or sparsely represented users. In this work, we
introduce Maia4All, a framework designed to learn and adapt to individual
decision-making styles efficiently, even with limited data. Maia4All achieves
this through a two-stage optimization process: (1) an enrichment step, which
bridges population and individual-level human behavior modeling with a
prototype-enriched model, and (2) a democratization step, which leverages
ability levels or user prototypes to initialize and refine individual
embeddings with minimal data. Our experimental results show that Maia4All can
accurately predict individual moves and profile behavioral patterns with high
fidelity, establishing a new standard for personalized human-like AI behavior
modeling in chess. Maia4All achieves individual human behavior modeling in
chess with only 20 games, compared to the 5,000 games required previously,
representing a significant improvement in data efficiency. Our work provides an
example of how population AI systems can flexibly adapt to individual users
using a prototype-enriched model as a bridge. This approach extends beyond
chess, as shown in our case study on idiosyncratic LLMs, highlighting its
potential for broader applications in personalized AI adaptation.

</details>


### [194] [Large Language Models for Supply Chain Decisions](https://arxiv.org/abs/2507.21502)
*David Simchi-Levi,Konstantina Mellou,Ishai Menache,Jeevan Pathuri*

Main category: cs.AI

TL;DR: 本研究探讨通过应用大型语言模型来提高供应链管理的决策效率，显著缩短决策时间并提高生产力和影响力。


<details>
  <summary>Details</summary>
Motivation: 由于供应链管理中决策的复杂性，以及现有工具仍需要大量人力参与解释和更新，进而减缓决策进程，研究者受到最近大型语言模型（LLMs）的进步的启发，寻求通过LLMs来简化供应链技术的使用。

Method: 利用大型语言模型（LLMs）来解决供应链管理决策中的复杂问题，减少决策所需时间。

Result: 通过应用大型语言模型技术，显著减少了决策的时间，提高了生产力和决策影响力。

Conclusion: 报告表明，通过应用大型语言模型，可以显著缩短从天和周到分钟和小时的决策时间，并显著提高计划者和高管的生产力和影响力。

Abstract: Supply Chain Management requires addressing a variety of complex
decision-making challenges, from sourcing strategies to planning and execution.
Over the last few decades, advances in computation and information technologies
have enabled the transition from manual, intuition and experience-based
decision-making, into more automated and data-driven decisions using a variety
of tools that apply optimization techniques. These techniques use mathematical
methods to improve decision-making.
  Unfortunately, business planners and executives still need to spend
considerable time and effort to (i) understand and explain the recommendations
coming out of these technologies; (ii) analyze various scenarios and answer
what-if questions; and (iii) update the mathematical models used in these tools
to reflect current business environments. Addressing these challenges requires
involving data science teams and/or the technology providers to explain results
or make the necessary changes in the technology and hence significantly slows
down decision making.
  Motivated by the recent advances in Large Language Models (LLMs), we report
how this disruptive technology can democratize supply chain technology -
namely, facilitate the understanding of tools' outcomes, as well as the
interaction with supply chain tools without human-in-the-loop. Specifically, we
report how we apply LLMs to address the three challenges described above, thus
substantially reducing the time to decision from days and weeks to minutes and
hours as well as dramatically increasing planners' and executives' productivity
and impact.

</details>


### [195] [MoHoBench: Assessing Honesty of Multimodal Large Language Models via Unanswerable Visual Questions](https://arxiv.org/abs/2507.21503)
*Yanxu Zhu,Shitong Duan,Xiangxu Zhang,Jitao Sang,Peng Zhang,Tun Lu,Xiao Zhou,Jing Yao,Xiaoyuan Yi,Xing Xie*

Main category: cs.AI

TL;DR: 该研究评估了多模态大语言模型在视觉不可回答问题上的诚实性，发现多数模型无法适当拒绝回答，诚实性受视觉信息影响，并通过监督学习和偏好学习改善诚实行为。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉-语言任务中表现出色，但其生成的内容可能具有潜在的危害或不可信性。尚缺乏关于MMLMs诚实行为的系统性研究，尤其是在视觉不可回答问题上的表现。

Method: 使用MoHoBench进行了多模态大语言模型的诚实性基准测试，并进行全面分析，设计了初步对齐方法以改善诚实行为，包括监督学习和偏好学习。

Result: 多数模型在必要时无法适当拒绝回答，并且模型的诚实性受到视觉信息的深刻影响。开发了初步对齐方法以改善多模态模型的诚实行为。

Conclusion: 研究发现多数多模态语言模型在面对不可回答的视觉问题时无法适当拒绝回答，并且模型的诚实性不仅仅是语言建模的问题，而是受到视觉信息的深刻影响。因此，需要开发专门的方法来实现多模态诚实性对齐。

Abstract: Recently Multimodal Large Language Models (MLLMs) have achieved considerable
advancements in vision-language tasks, yet produce potentially harmful or
untrustworthy content. Despite substantial work investigating the
trustworthiness of language models, MMLMs' capability to act honestly,
especially when faced with visually unanswerable questions, remains largely
underexplored. This work presents the first systematic assessment of honesty
behaviors across various MLLMs. We ground honesty in models' response behaviors
to unanswerable visual questions, define four representative types of such
questions, and construct MoHoBench, a large-scale MMLM honest benchmark,
consisting of 12k+ visual question samples, whose quality is guaranteed by
multi-stage filtering and human verification. Using MoHoBench, we benchmarked
the honesty of 28 popular MMLMs and conducted a comprehensive analysis. Our
findings show that: (1) most models fail to appropriately refuse to answer when
necessary, and (2) MMLMs' honesty is not solely a language modeling issue, but
is deeply influenced by visual information, necessitating the development of
dedicated methods for multimodal honesty alignment. Therefore, we implemented
initial alignment methods using supervised and preference learning to improve
honesty behavior, providing a foundation for future work on trustworthy MLLMs.
Our data and code can be found at https://github.com/DSTTSD/MoHoBench.

</details>


### [196] [What Does it Mean for a Neural Network to Learn a "World Model"?](https://arxiv.org/abs/2507.21513)
*Kenneth Li,Fernanda Viégas,Martin Wattenberg*

Main category: cs.AI

TL;DR: 本文提出了一种方法来精确定义神经网络是否学习了“世界模型”，并提供了一套检测标准。


<details>
  <summary>Details</summary>
Motivation: 旨在为这些通常非正式使用的术语赋予操作性意义，从而为实验研究提供一种通用语言。

Method: 定义基于线性探测文献中的思想，形式化了通过数据生成过程表示的计算概念。

Result: 定义了一个检测“世界模型”是否不是神经网络的数据或任务的平凡结果的方法。

Conclusion: 本文提出了一组精确的标准，用于判断神经网络是否学习并使用了“世界模型”。

Abstract: We propose a set of precise criteria for saying a neural net learns and uses
a "world model." The goal is to give an operational meaning to terms that are
often used informally, in order to provide a common language for experimental
investigation. We focus specifically on the idea of representing a latent
"state space" of the world, leaving modeling the effect of actions to future
work. Our definition is based on ideas from the linear probing literature, and
formalizes the notion of a computation that factors through a representation of
the data generation process. An essential addition to the definition is a set
of conditions to check that such a "world model" is not a trivial consequence
of the neural net's data or task.

</details>


### [197] [ST-GDance: Long-Term and Collision-Free Group Choreography from Music](https://arxiv.org/abs/2507.21518)
*Jing Xu,Weiqiang Wang,Cunjian Chen,Jun Liu,Qiuhong Ke*

Main category: cs.AI

TL;DR: 提出了一种通过解耦空间和时间依赖性来优化长时间且无碰撞群舞编排的新框架ST-GDance，实验结果表明其在复杂舞蹈生成任务上超过了现有的方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以建模密集的时空交互，导致可扩展性问题和多舞者的碰撞，本文提出ST-GDance来解决这些问题。

Method: 使用轻量级图卷积进行距离感知的空间建模，并加速稀疏注意力进行高效的时间建模，从而减少计算成本并确保平滑且无碰撞的交互。

Result: 实验表明，ST-GDance在AIOZ-GDance数据集上表现优于现有基线，特别是在生成长且连贯的群舞序列方面。

Conclusion: ST-GDance在生成长且连贯的群舞序列方面优于现有的最先进基线。

Abstract: Group dance generation from music has broad applications in film, gaming, and
animation production. However, it requires synchronizing multiple dancers while
maintaining spatial coordination. As the number of dancers and sequence length
increase, this task faces higher computational complexity and a greater risk of
motion collisions. Existing methods often struggle to model dense
spatial-temporal interactions, leading to scalability issues and multi-dancer
collisions. To address these challenges, we propose ST-GDance, a novel
framework that decouples spatial and temporal dependencies to optimize
long-term and collision-free group choreography. We employ lightweight graph
convolutions for distance-aware spatial modeling and accelerated sparse
attention for efficient temporal modeling. This design significantly reduces
computational costs while ensuring smooth and collision-free interactions.
Experiments on the AIOZ-GDance dataset demonstrate that ST-GDance outperforms
state-of-the-art baselines, particularly in generating long and coherent group
dance sequences. Project page: https://yilliajing.github.io/ST-GDance-Website/.

</details>


### [198] [Large Language Models for Wireless Communications: From Adaptation to Autonomy](https://arxiv.org/abs/2507.21524)
*Le Liang,Hao Ye,Yucheng Sheng,Ouya Wang,Jiacheng Wang,Shi Jin,Geoffrey Ye Li*

Main category: cs.AI

TL;DR: LLMs为人工智能带来了突破，为无线通信系统提供了智能和自适应解决方案，并指出了未来研究的挑战和机遇。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的崛起彻底改变了人工智能领域，展示了在推理、泛化和零样本学习方面的前所未有的能力。这些能力为无线通信的新前沿打开了大门，无线通信日益复杂并且变化多端，需要智能和自适应的解决方案。

Method: 文章探讨了LLMs在三个关键方向上改变无线系统的角色：适应预训练的LLMs以执行核心通信任务，开发特定于无线的基础模型以平衡通用性和效率，以及使具备自主推理和协调能力的代理化LLMs成为可能。

Result: 文章强调了LLM基础的方法相比于传统方法的独特优势，并概述了近期的进展、实际案例研究以及开放性的挑战和研究机会。

Conclusion: LLMs在无线通信领域展现了巨大潜力，通过智能、自适应和自主无线网络的发展来推动未来的进步。

Abstract: The emergence of large language models (LLMs) has revolutionized artificial
intelligence, offering unprecedented capabilities in reasoning, generalization,
and zero-shot learning. These strengths open new frontiers in wireless
communications, where increasing complexity and dynamics demand intelligent and
adaptive solutions. This article explores the role of LLMs in transforming
wireless systems across three key directions: adapting pretrained LLMs for core
communication tasks, developing wireless-specific foundation models to balance
versatility and efficiency, and enabling agentic LLMs with autonomous reasoning
and coordination capabilities. We highlight recent advances, practical case
studies, and the unique benefits of LLM-based approaches over traditional
methods. Finally, we outline open challenges and research opportunities,
including multimodal fusion, collaboration with lightweight models, and
self-improving capabilities, charting a path toward intelligent, adaptive, and
autonomous wireless networks of the future.

</details>


### [199] [Finding Uncommon Ground: A Human-Centered Model for Extrospective Explanations](https://arxiv.org/abs/2507.21571)
*Laura Spillner,Nima Zargham,Mihai Pomarlan,Robert Porzel,Rainer Malaka*

Main category: cs.AI

TL;DR: 提出个性化AI解释方法，根据用户及其偏好定制信息，以提高解释的可理解性。


<details>
  <summary>Details</summary>
Motivation: 当前AI解释主要关注黑箱模型的透明性，但对于非专业人士而言理解难度大，因此需要一种以人为中心的AI解释视角。

Method: 设计了一种以人工智能代理的世界观为模型的方法，作为一个动态的记忆系统来记录与用户的交互，帮助代理估算哪些知识对用户而言可能是新信息。

Result: 通过个性化信息提供，增强了AI解释的针对性，使信息更易于用户接受和理解。

Conclusion: 本研究提出一种个性化的解释方法，通过根据个体及其偏好情境来定制信息提供，以提高人工智能解释的可理解性。

Abstract: The need for explanations in AI has, by and large, been driven by the desire
to increase the transparency of black-box machine learning models. However,
such explanations, which focus on the internal mechanisms that lead to a
specific output, are often unsuitable for non-experts. To facilitate a
human-centered perspective on AI explanations, agents need to focus on
individuals and their preferences as well as the context in which the
explanations are given. This paper proposes a personalized approach to
explanation, where the agent tailors the information provided to the user based
on what is most likely pertinent to them. We propose a model of the agent's
worldview that also serves as a personal and dynamic memory of its previous
interactions with the same user, based on which the artificial agent can
estimate what part of its knowledge is most likely new information to the user.

</details>


### [200] [SafeDriveRAG: Towards Safe Autonomous Driving with Knowledge Graph-based Retrieval-Augmented Generation](https://arxiv.org/abs/2507.21585)
*Hao Ye,Mengshi Qi,Zhaohong Liu,Liang Liu,Huadong Ma*

Main category: cs.AI

TL;DR: 研究创建了一个名为SafeDrive228K的新基准，并提出一种名为SafeDriveRAG的基于知识图谱的增强生成方法，旨在提升视觉语言模型在交通安全关键场景中的表现，特别是在VQA任务中的理解和推理能力。实验表明，该方法对主流VLMs的性能有显著提升。


<details>
  <summary>Details</summary>
Motivation: 在当前的研究中，关于视觉语言模型（VLMs）如何在交通安全关键的驾驶场景中进行评估方面，存在明显的研究缺口，因此本工作旨在填补这一空白。

Method: 提出了一种基于知识图谱的检索增强生成方法（SafeDriveRAG），利用一个新颖的多尺度子图检索算法实现高效信息检索；并结合了从互联网收集的交通安全指南来提升模型在安全关键情境中的处理能力。

Result: 在五个主流的视觉语言模型（VLMs）上进行的全面评估表明，使用新的SafeDriveRAG方法后模型表现出显著的性能提升。特别是在交通事故任务中提升4.73%、特殊情况任务中提升8.79%，以及交通安全常识任务中提升14.57%。

Conclusion: 综合实验结果表明，通过集成RAG方法，大幅提升了VLMs在处理涉及交通安全关键任务的表现，特别是在交通事故、特殊情况以及交通安全常识任务上分别获得了4.73%、8.79%和14.57%的性能提升。

Abstract: In this work, we study how vision-language models (VLMs) can be utilized to
enhance the safety for the autonomous driving system, including perception,
situational understanding, and path planning. However, existing research has
largely overlooked the evaluation of these models in traffic safety-critical
driving scenarios. To bridge this gap, we create the benchmark (SafeDrive228K)
and propose a new baseline based on VLM with knowledge graph-based
retrieval-augmented generation (SafeDriveRAG) for visual question answering
(VQA). Specifically, we introduce SafeDrive228K, the first large-scale
multimodal question-answering benchmark comprising 228K examples across 18
sub-tasks. This benchmark encompasses a diverse range of traffic safety
queries, from traffic accidents and corner cases to common safety knowledge,
enabling a thorough assessment of the comprehension and reasoning abilities of
the models. Furthermore, we propose a plug-and-play multimodal knowledge
graph-based retrieval-augmented generation approach that employs a novel
multi-scale subgraph retrieval algorithm for efficient information retrieval.
By incorporating traffic safety guidelines collected from the Internet, this
framework further enhances the model's capacity to handle safety-critical
situations. Finally, we conduct comprehensive evaluations on five mainstream
VLMs to assess their reliability in safety-sensitive driving tasks.
Experimental results demonstrate that integrating RAG significantly improves
performance, achieving a +4.73% gain in Traffic Accidents tasks, +8.79% in
Corner Cases tasks and +14.57% in Traffic Safety Commonsense across five
mainstream VLMs, underscoring the potential of our proposed benchmark and
methodology for advancing research in traffic safety. Our source code and data
are available at https://github.com/Lumos0507/SafeDriveRAG.

</details>


### [201] [Progressive Homeostatic and Plastic Prompt Tuning for Audio-Visual Multi-Task Incremental Learning](https://arxiv.org/abs/2507.21588)
*Jiong Yin,Liang Li,Jiehua Zhang,Yuhan Gao,Chenggang Yan,Xichun Sheng*

Main category: cs.AI

TL;DR: 提出了一种新的三阶段音频视觉学习方法PHP, 在多任务学习中取得最优结果。


<details>
  <summary>Details</summary>
Motivation: 音频视觉多任务增量学习旨在不需要联合训练所有任务的情况下，持续从多个音频视觉任务中学习。在这个问题中如何保留旧任务知识，同时利用过去的经验促进新任务的学习是一个挑战。

Method: 我们引入了三阶段的渐进性稳态和可塑性音频视觉提示（PHP）方法，包括浅层阶段的任务共享模态聚合适配器，中层阶段的任务特定模态共享动态生成适配器，以及深层阶段的任务特定模态独立提示。

Result: 我们的方法在不同顺序的四项任务（AVE、AVVP、AVS和AVQA）上取得了SOTA性能。

Conclusion: 这种方法在四项任务（AVE、AVVP、AVS和AVQA）上的性能达到了最新的水平。

Abstract: Audio-visual multi-task incremental learning aims to continuously learn from
multiple audio-visual tasks without the need for joint training on all tasks.
The challenge of the problem is how to preserve the old task knowledge while
facilitating the learning of new task with previous experiences. To address
these challenges, we introduce a three-stage Progressive Homeostatic and
Plastic audio-visual prompt (PHP) method. In the shallow phase, we design the
task-shared modality aggregating adapter to foster cross-task and cross-modal
audio-visual representation learning to enhance shared understanding between
tasks. In the middle phase, we propose the task-specific modality-shared
dynamic generating adapter, which constructs prompts that are tailored to
individual tasks while remaining general across modalities, which balances the
models ability to retain knowledge against forgetting with its potential for
versatile multi-task transferability. In the deep phase, we introduce the
task-specific modality-independent prompts to further refine the understand
ability by targeting individual information for each task and modality. By
incorporating these three phases, PHP retains task-specific prompts while
adapting shared parameters for new tasks to effectively balance knowledge
sharing and specificity. Our method achieves SOTA performance in different
orders of four tasks (AVE, AVVP, AVS and AVQA). Our code can be available at
https://github.com/ENJOY-Yin-jiong/PHP.

</details>


### [202] [Exploring the Link Between Bayesian Inference and Embodied Intelligence: Toward Open Physical-World Embodied AI Systems](https://arxiv.org/abs/2507.21589)
*Bin Liu*

Main category: cs.AI

TL;DR: 探讨贝叶斯统计在具身智能中的应用，分析其未广泛应用的原因，及其在开放物理世界中应用的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管贝叶斯统计与具身智能之间有深刻的概念关联，但贝叶斯原理并没有广泛或显式应用于当今的具身智能系统。

Method: 通过分析搜索和学习这两大主题来探讨贝叶斯和现代具身智能方法。

Result: 揭示了贝叶斯推断在现代具身智能发展中未发挥核心作用的原因，以及当前具身智能系统的局限性。

Conclusion: 当前的具身智能系统主要局限于封闭的物理世界环境，贝叶斯方法可能在推动这些系统向真正开放的物理世界具身智能发展中发挥关键作用。

Abstract: Embodied intelligence posits that cognitive capabilities fundamentally emerge
from - and are shaped by - an agent's real-time sensorimotor interactions with
its environment. Such adaptive behavior inherently requires continuous
inference under uncertainty. Bayesian statistics offers a principled
probabilistic framework to address this challenge by representing knowledge as
probability distributions and updating beliefs in response to new evidence. The
core computational processes underlying embodied intelligence - including
perception, action selection, learning, and even higher-level cognition - can
be effectively understood and modeled as forms of Bayesian inference. Despite
the deep conceptual connection between Bayesian statistics and embodied
intelligence, Bayesian principles have not been widely or explicitly applied in
today's embodied intelligence systems. In this work, we examine both Bayesian
and contemporary embodied intelligence approaches through two fundamental
lenses: search and learning - the two central themes in modern AI, as
highlighted in Rich Sutton's influential essay "The Bitter Lesson". This
analysis sheds light on why Bayesian inference has not played a central role in
the development of modern embodied intelligence. At the same time, it reveals
that current embodied intelligence systems remain largely confined to
closed-physical-world environments, and highlights the potential for Bayesian
methods to play a key role in extending these systems toward truly open
physical-world embodied intelligence.

</details>


### [203] ["Teammates, Am I Clear?": Analysing Legible Behaviours in Teams](https://arxiv.org/abs/2507.21631)
*Miguel Faria,Francisco S. Melo,Ana Paiva*

Main category: cs.AI

TL;DR: 该研究将可辨识决策方法扩展至多代理场景，提高了团队合作表现。


<details>
  <summary>Details</summary>
Motivation: 针对以往研究中只关注一个代理与一个人类互动的不足，探索可辨识性在多个代理或有人的团队配置中的应用，以提高团队表现。

Method: 提出了一种将可辨识决策扩展到多代理设置的方法，并在多代理基准场景中展示了其效果。

Result: 在多代理基准场景中，具有可辨识性的代理能够超越仅由执行标准最优行为的代理组成的团队。

Conclusion: 在团队场景中，具有可辨识性的代理可以在共同工作中实现更优的表现，尤其是在有多个代理协作的情况下。

Abstract: In this paper we investigate the notion of legibility in sequential
decision-making in the context of teams and teamwork. There have been works
that extend the notion of legibility to sequential decision making, for
deterministic and for stochastic scenarios. However, these works focus on one
agent interacting with one human, foregoing the benefits of having legible
decision making in teams of agents or in team configurations with humans. In
this work we propose an extension of legible decision-making to multi-agent
settings that improves the performance of agents working in collaboration. We
showcase the performance of legible decision making in team scenarios using our
proposed extension in multi-agent benchmark scenarios. We show that a team with
a legible agent is able to outperform a team composed solely of agents with
standard optimal behaviour.

</details>


### [204] [StaffPro: an LLM Agent for Joint Staffing and Profiling](https://arxiv.org/abs/2507.21636)
*Alessio Maritan*

Main category: cs.AI

TL;DR: StaffPro是一个结合LLM和算法组件的人力资源管理工具，用于优化人员配置和分析。


<details>
  <summary>Details</summary>
Motivation: 利用LLM代理解决人力资源管理中的人员配置和分析挑战。

Method: 将人员配置和分析问题放入数学框架中，通过建立连续的人机反馈循环，实现持续的工人属性估计和优化配置。

Result: StaffPro能够成功估计工人的属性，并生成高质量的日程表。

Conclusion: StaffPro在自动化人员管理中，提供了一种强大的、可解释的和以人为中心的解决方案。

Abstract: Large language model (LLM) agents integrate pre-trained LLMs with modular
algorithmic components and have shown remarkable reasoning and decision-making
abilities. In this work, we investigate their use for two tightly intertwined
challenges in workforce management: staffing, i.e., the assignment and
scheduling of tasks to workers, which may require team formation; and
profiling, i.e., the continuous estimation of workers' skills, preferences, and
other latent attributes from unstructured data. We cast these problems in a
formal mathematical framework that links scheduling decisions to latent feature
estimation, and we introduce StaffPro, an LLM agent that addresses staffing and
profiling jointly. Differently from existing staffing solutions, StaffPro
allows expressing optimization objectives using natural language, accepts
textual task descriptions and provides high flexibility. StaffPro interacts
directly with humans by establishing a continuous human-agent feedback loop,
ensuring natural and intuitive use. By analyzing human feedback, our agent
continuously estimates the latent features of workers, realizing life-long
worker profiling and ensuring optimal staffing performance over time. A
consulting firm simulation example demonstrates that StaffPro successfully
estimates workers' attributes and generates high quality schedules. With its
innovative design, StaffPro offers a robust, interpretable, and human-centric
solution for automated personnel management.

</details>


### [205] [Self-Aware Safety Augmentation: Leveraging Internal Semantic Understanding to Enhance Safety in Vision-Language Models](https://arxiv.org/abs/2507.21637)
*Wanying Wang,Zeyu Ma,Han Zheng,Xin Tan,Mingang Chen*

Main category: cs.AI

TL;DR: 研究表明LVLMs存在安全性问题，提出SASA技术来增强其安全性能，实验结果显示方法有效且对效用影响小。


<details>
  <summary>Details</summary>
Motivation: 由于大规模视觉-语言模型（LVLMs）在处理有害输入时表现出比仅语言模型更大的脆弱性，因此研究了LVLMs的内部动态，希望通过增强模型安全感知来减少安全性方面的下降。

Method: 首先通过实验确定LVLMs模型架构中主要的安全感知、语义理解和语言表达对齐能力的位置。然后，使用线性探测来阐明模型的内部语义理解，以在生成过程之前检测风险。

Result: 提出的SASA方法显著提高了LVLMs的安全性，同时对模型的效用影响最小。

Conclusion: 提出了一种名为自我感知安全增强（SASA）的技术，可以在不进行微调的情况下，通过将中间层的信息语义表示投射到更早的安全导向层来增强LVLMs的安全性。

Abstract: Large vision-language models (LVLMs) are vulnerable to harmful input compared
to their language-only backbones. We investigated this vulnerability by
exploring LVLMs internal dynamics, framing their inherent safety understanding
in terms of three key capabilities. Specifically, we define these capabilities
as safety perception, semantic understanding, and alignment for linguistic
expression, and experimentally pinpointed their primary locations within the
model architecture. The results indicate that safety perception often emerges
before comprehensive semantic understanding, leading to the reduction in
safety. Motivated by these findings, we propose \textbf{Self-Aware Safety
Augmentation (SASA)}, a technique that projects informative semantic
representations from intermediate layers onto earlier safety-oriented layers.
This approach leverages the model's inherent semantic understanding to enhance
safety recognition without fine-tuning. Then, we employ linear probing to
articulate the model's internal semantic comprehension to detect the risk
before the generation process. Extensive experiments on various datasets and
tasks demonstrate that SASA significantly improves the safety of LVLMs, with
minimal impact on the utility.

</details>


### [206] [Assistax: A Hardware-Accelerated Reinforcement Learning Benchmark for Assistive Robotics](https://arxiv.org/abs/2507.21638)
*Leonard Hinckeldey,Elliot Fosong,Elle Miller,Rimvydas Rubavicius,Trevor McInroe,Patricia Wollstadt,Christiane B. Wiebel-Herboth,Subramanian Ramamoorthy,Stefano V. Albrecht*

Main category: cs.AI

TL;DR: Assistax是一个新的开源基准，用于优化助理机器人任务的强化学习算法，显著加速模拟过程，提供可靠的基准测试。


<details>
  <summary>Details</summary>
Motivation: 多样化强化学习基准测试，解决游戏基准无法直接应用于现实环境的问题，并处理体化交互场景复杂性。

Method: Assistax使用JAX的硬件加速实现物理模拟的显著加速，通过多智能体强化学习进行训练，以测试机器人与人类患者之间的交互能力。

Result: Assistax在开放环壁挂时间方面运行速度显著提高，比基于CPU的替代方案快370倍，为连续控制和多智能体强化学习算法的基准测试提供了可靠的基准线。

Conclusion: Assistax提供了一个开放源码的基准测试平台，专为帮助机器人任务而设计，以推进强化学习研究。通过显著提高模拟速度和多智能体零次协调能力测试，Assistax成为了一个实用的基准。

Abstract: The development of reinforcement learning (RL) algorithms has been largely
driven by ambitious challenge tasks and benchmarks. Games have dominated RL
benchmarks because they present relevant challenges, are inexpensive to run and
easy to understand. While games such as Go and Atari have led to many
breakthroughs, they often do not directly translate to real-world embodied
applications. In recognising the need to diversify RL benchmarks and addressing
complexities that arise in embodied interaction scenarios, we introduce
Assistax: an open-source benchmark designed to address challenges arising in
assistive robotics tasks. Assistax uses JAX's hardware acceleration for
significant speed-ups for learning in physics-based simulations. In terms of
open-loop wall-clock time, Assistax runs up to $370\times$ faster when
vectorising training runs compared to CPU-based alternatives. Assistax
conceptualises the interaction between an assistive robot and an active human
patient using multi-agent RL to train a population of diverse partner agents
against which an embodied robotic agent's zero-shot coordination capabilities
can be tested. Extensive evaluation and hyperparameter tuning for popular
continuous control RL and MARL algorithms provide reliable baselines and
establish Assistax as a practical benchmark for advancing RL research for
assistive robotics. The code is available at:
https://github.com/assistive-autonomy/assistax.

</details>


### [207] [Can the current trends of AI handle a full course of mathematics?](https://arxiv.org/abs/2507.21664)
*Mariam Alsayyad,Fayadh Kadhem*

Main category: cs.AI

TL;DR: 人工智能在大学数学课程管理中展现出组织和准确上的优越性，但无论是情感还是其他人性化因素仍需人类补充。


<details>
  <summary>Details</summary>
Motivation: 探讨现阶段人工智能在大学水平的数学课程管理能力。

Method: 评估人工智能在创建课程大纲、展示选材、回答学生问题和创建评估方面的能力。

Result: 人工智能在组织和准确性方面表现良好，但在涉及情感的部分仍有不足。

Conclusion: 目前人工智能无法完全替代人类在大学数学课程中的角色，需要结合人类与AI的优点来实现更好的教育成果。

Abstract: This paper addresses the question of how able the current trends of
Artificial Intelligence (AI) are in managing to take the responsibility of a
full course of mathematics at a college level. The study evaluates this ability
in four significant aspects, namely, creating a course syllabus, presenting
selected material, answering student questions, and creating an assessment. It
shows that even though the AI is strong in some important parts like
organization and accuracy, there are still some human aspects that are far away
from the current abilities of AI. There is still a hidden emotional part, even
in science, that cannot be fulfilled by the AI in its current state. This paper
suggests some recommendations to integrate the human and AI potentials to
create better outcomes in terms of reaching the target of creating a full
course of mathematics, at a university level, as best as possible.

</details>


### [208] [Unrolling Dynamic Programming via Graph Filters](https://arxiv.org/abs/2507.21705)
*Sergio Rozada,Samuel Rey,Gonzalo Mateos,Antonio G. Marques*

Main category: cs.AI

TL;DR: 提出了BellNet模型，通过图信号处理重参数化，能在较少迭代中逼近最优策略，减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决状态动作空间较大或问题涉及长期依赖时传统动态规划方法的计算开销。

Method: 运用图信号处理方法，将转移概率矩阵视为加权有向图的邻接矩阵，通过非线性图滤波器串联形式紧凑地重新参数化BellNet。

Result: BellNet能够在网格环境实验中有效逼近最优策略，并显著减少迭代次数。

Conclusion: BellNet模型能够在较少迭代次数下有效逼近最优策略。

Abstract: Dynamic programming (DP) is a fundamental tool used across many engineering
fields. The main goal of DP is to solve Bellman's optimality equations for a
given Markov decision process (MDP). Standard methods like policy iteration
exploit the fixed-point nature of these equations to solve them iteratively.
However, these algorithms can be computationally expensive when the
state-action space is large or when the problem involves long-term
dependencies. Here we propose a new approach that unrolls and truncates policy
iterations into a learnable parametric model dubbed BellNet, which we train to
minimize the so-termed Bellman error from random value function
initializations. Viewing the transition probability matrix of the MDP as the
adjacency of a weighted directed graph, we draw insights from graph signal
processing to interpret (and compactly re-parameterize) BellNet as a cascade of
nonlinear graph filters. This fresh look facilitates a concise, transferable,
and unifying representation of policy and value iteration, with an explicit
handle on complexity during inference. Preliminary experiments conducted in a
grid-like environment demonstrate that BellNet can effectively approximate
optimal policies in a fraction of the iterations required by classical methods.

</details>


### [209] [GDAIP: A Graph-Based Domain Adaptive Framework for Individual Brain Parcellation](https://arxiv.org/abs/2507.21727)
*Jianfei Zhu,Haiqi Zhu,Shaohui Liu,Feng Jiang,Baichun Wei,Chunzhi Yi*

Main category: cs.AI

TL;DR: 提出了GDAIP框架，通过跨数据集脑图的半监督训练和对未标记目标脑图顶点的预测熵进行对抗优化，解决领域间数据分布不一致的问题，实现了个性化脑分区。


<details>
  <summary>Details</summary>
Motivation: 解决不同领域的数据分布不一致，且传统方法在真实的跨数据集场景中表现不佳的问题。

Method: 提出了新的框架Graph Domain Adaptation for Individual Parcellation (GDAIP)，结合了图注意网络（Graph Attention Networks, GAT）和基于最小最大熵（MME）的领域适应方法。

Result: 实验结果显示GDAIP在个性化分区及其拓扑界限、跨会话一致性和反映功能组织的能力方面表现优秀。

Conclusion: GDAIP框架能够在跨数据集设置下实现个体化的脑区分割，提供更准确的个性化脑图谱。

Abstract: Recent deep learning approaches have shown promise in learning such
individual brain parcellations from functional magnetic resonance imaging
(fMRI). However, most existing methods assume consistent data distributions
across domains and struggle with domain shifts inherent to real-world
cross-dataset scenarios. To address this challenge, we proposed Graph Domain
Adaptation for Individual Parcellation (GDAIP), a novel framework that
integrates Graph Attention Networks (GAT) with Minimax Entropy (MME)-based
domain adaptation. We construct cross-dataset brain graphs at both the group
and individual levels. By leveraging semi-supervised training and adversarial
optimization of the prediction entropy on unlabeled vertices from target brain
graph, the reference atlas is adapted from the group-level brain graph to the
individual brain graph, enabling individual parcellation under cross-dataset
settings. We evaluated our method using parcellation visualization, Dice
coefficient, and functional homogeneity. Experimental results demonstrate that
GDAIP produces individual parcellations with topologically plausible
boundaries, strong cross-session consistency, and ability of reflecting
functional organization.

</details>


### [210] [SAT-Based Bounded Fitting for the Description Logic ALC](https://arxiv.org/abs/2507.21752)
*Maurice Funk,Jean Christoph Jung,Tom Voellmer*

Main category: cs.AI

TL;DR: 研究逻辑公式学习中的有界拟合问题，发现NP完全性及PAC框架下保证，并实现了基于SAT解算器的优化方案。


<details>
  <summary>Details</summary>
Motivation: 探讨描述逻辑ALC及其句法片段中的有界拟合，以解决从正反例中学习逻辑公式的问题。

Method: 使用有界拟合框架，通过使用SAT求解器来实现。

Result: 对于所有研究的片段来说，基础规模受限拟合问题是NP完全的。我们的研究表明有界拟合在PAC学习框架下具备概率性保证，而其他学习ALC概念的算法不提供这样的保证。

Conclusion: 我们实现了一个基于SAT解算器的有界拟合方法，并进行了优化，与其他概念学习工具进行了比较。

Abstract: Bounded fitting is a general paradigm for learning logical formulas from
positive and negative data examples, that has received considerable interest
recently. We investigate bounded fitting for the description logic ALC and its
syntactic fragments. We show that the underlying size-restricted fitting
problem is NP-complete for all studied fragments, even in the special case of a
single positive and a single negative example. By design, bounded fitting comes
with probabilistic guarantees in Valiant's PAC learning framework. In contrast,
we show that other classes of algorithms for learning ALC concepts do not
provide such guarantees. Finally, we present an implementation of bounded
fitting in ALC and its fragments based on a SAT solver. We discuss
optimizations and compare our implementation to other concept learning tools.

</details>


### [211] [Towards a rigorous evaluation of RAG systems: the challenge of due diligence](https://arxiv.org/abs/2507.21753)
*Grégoire Martinon,Alexandra Lorenzo de Brionne,Jérôme Bohard,Antoine Lojou,Damien Hervault,Nicolas J-B. Brunel*

Main category: cs.AI

TL;DR: 研究提出了一种对RAG系统进行可靠评估的方法，以提高其在工业中的应用可靠性。


<details>
  <summary>Details</summary>
Motivation: 尽管RAG系统在高风险行业中具有巨大潜力，但其在关键场合中的可靠性仍不确定，因此需要一种有效评估其性能的方法。

Method: 研究采用结合人类标注和LLM-Judge标注的评估协议来识别RAG系统的失误，并引入预测驱动推理（PPI）方法以实现高精度的性能测量和统计保证。

Result: 研究展示了一种对投资基金尽职调查使用的RAG系统的评估方法，通过结合人类和自动标注的方法可以精确测量系统性能并提供统计保证。

Conclusion: 研究提出了一种结合人类标注和LLM-Judge标注的评估协议，可有效识别系统失误，如幻觉、题外、失败引用和弃权。通过这种评估方法，可以提高RAG系统在工业应用中的可靠性和可扩展性。

Abstract: The rise of generative AI, has driven significant advancements in high-risk
sectors like healthcare and finance. The Retrieval-Augmented Generation (RAG)
architecture, combining language models (LLMs) with search engines, is
particularly notable for its ability to generate responses from document
corpora. Despite its potential, the reliability of RAG systems in critical
contexts remains a concern, with issues such as hallucinations persisting. This
study evaluates a RAG system used in due diligence for an investment fund. We
propose a robust evaluation protocol combining human annotations and LLM-Judge
annotations to identify system failures, like hallucinations, off-topic, failed
citations, and abstentions. Inspired by the Prediction Powered Inference (PPI)
method, we achieve precise performance measurements with statistical
guarantees. We provide a comprehensive dataset for further analysis. Our
contributions aim to enhance the reliability and scalability of RAG systems
evaluation protocols in industrial applications.

</details>


### [212] [Hybrid Causal Identification and Causal Mechanism Clustering](https://arxiv.org/abs/2507.21792)
*Saixiong Liu,Yuhua Qian,Jue Li,Honghong Cheng,Feijiang Li*

Main category: cs.AI

TL;DR: 本文提出了MCVCI和MCVCC方法用于识别异质因果关系，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的观测数据通常在不同环境中收集，具有异质因果关系，因此仅仅使用单一因果机制构建因果模型的方法可能不足。

Method: 本文提出了一种混合条件变分因果推断模型(MCVCI)，结合了高斯混合模型和神经网络的拟合能力，并利用变分自动编码器的概率界限作为因果决策标准。此外，还提出了混合条件变分因果聚类(MCVCC)方法，将因果异质性建模为聚类数。

Result: 所提出的方法在模拟和真实数据集上的综合表现比其他方法更优，证明了其有效性和优越性。

Conclusion: 所提出的MCVCI和MCVCC方法在多个模拟和真实数据集上表现出比现有最先进方法更好的性能，证实了其有效性。

Abstract: Bivariate causal direction identification is a fundamental and vital problem
in the causal inference field. Among binary causal methods, most methods based
on additive noise only use one single causal mechanism to construct a causal
model. In the real world, observations are always collected in different
environments with heterogeneous causal relationships. Therefore, on observation
data, this paper proposes a Mixture Conditional Variational Causal Inference
model (MCVCI) to infer heterogeneous causality. Specifically, according to the
identifiability of the Hybrid Additive Noise Model (HANM), MCVCI combines the
superior fitting capabilities of the Gaussian mixture model and the neural
network and elegantly uses the likelihoods obtained from the probabilistic
bounds of the mixture conditional variational auto-encoder as causal decision
criteria. Moreover, we model the casual heterogeneity into cluster numbers and
propose the Mixture Conditional Variational Causal Clustering (MCVCC) method,
which can reveal causal mechanism expression. Compared with state-of-the-art
methods, the comprehensive best performance demonstrates the effectiveness of
the methods proposed in this paper on several simulated and real data.

</details>


### [213] [MixGRPO: Unlocking Flow-based GRPO Efficiency with Mixed ODE-SDE](https://arxiv.org/abs/2507.21802)
*Junzhe Li,Yutao Cui,Tao Huang,Yinping Ma,Chun Fan,Miles Yang,Zhao Zhong*

Main category: cs.AI

TL;DR: 本文提出了MixGRPO，一种利用混合采样策略提升人类偏好对齐的框架，通过滑动窗口机制优化效率，并推出更快的MixGRPO-Flash，大幅减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 尽管GRPO在图像生成的人类偏好对齐中显著提升了流匹配模型，但像FlowGRPO这样的方法由于需要对马尔可夫决策过程(MDP)规定的所有去噪步骤进行采样和优化仍然效率较低。

Method: MixGRPO提出了一种滑动窗口机制，在窗口内使用SDE采样和GRPO引导优化，而在窗口之外应用ODE采样，从而限制采样的随机性并减少优化开销。

Result: MixGRPO和MixGRPO-Flash在多个维度的人类偏好对齐方面表现出显著的效率提升，MixGRPO提升效果和效率超过DanceGRPO，而MixGRPO-Flash进一步提高训练速度。

Conclusion: MixGRPO在多个维度的人类偏好对齐方面表现出显著的收益，其效率和效果均优于DanceGRPO，实现了近50%的训练时间减少。MixGRPO-Flash进一步将训练时间减少了71%。

Abstract: Although GRPO substantially enhances flow matching models in human preference
alignment of image generation, methods such as FlowGRPO still exhibit
inefficiency due to the necessity of sampling and optimizing over all denoising
steps specified by the Markov Decision Process (MDP). In this paper, we propose
$\textbf{MixGRPO}$, a novel framework that leverages the flexibility of mixed
sampling strategies through the integration of stochastic differential
equations (SDE) and ordinary differential equations (ODE). This streamlines the
optimization process within the MDP to improve efficiency and boost
performance. Specifically, MixGRPO introduces a sliding window mechanism, using
SDE sampling and GRPO-guided optimization only within the window, while
applying ODE sampling outside. This design confines sampling randomness to the
time-steps within the window, thereby reducing the optimization overhead, and
allowing for more focused gradient updates to accelerate convergence.
Additionally, as time-steps beyond the sliding window are not involved in
optimization, higher-order solvers are supported for sampling. So we present a
faster variant, termed $\textbf{MixGRPO-Flash}$, which further improves
training efficiency while achieving comparable performance. MixGRPO exhibits
substantial gains across multiple dimensions of human preference alignment,
outperforming DanceGRPO in both effectiveness and efficiency, with nearly 50%
lower training time. Notably, MixGRPO-Flash further reduces training time by
71%. Codes and models are available at
$\href{https://github.com/Tencent-Hunyuan/MixGRPO}{MixGRPO}$.

</details>


### [214] [An Agentic AI for a New Paradigm in Business Process Development](https://arxiv.org/abs/2507.21823)
*Mohammad Azarijafari,Luisa Mich,Michele Missikoff*

Main category: cs.AI

TL;DR: 该论文提出了一种通过Agentic AI进行业务流程设计的新方法，使流程围绕目标、对象和代理展开，从而在动态工业环境中实现更智能化的自动化。


<details>
  <summary>Details</summary>
Motivation: 人工智能代理是工业自动化技术持续演变中的下一个重要革命。

Method: 该论文提出了一种基于代理的业务流程设计和开发方法，通过代理来实现业务目标。此方法包括多个代理之间的合作以达成无法由单个代理完成的合并目标。

Result: 所提出的模型能够实现更模块化、更智能化的业务流程开发。

Conclusion: 该论文提出了一种围绕目标、对象和代理人进行组织的新业务流程设计方法，使得在动态工业环境中能够实现灵活且上下文感知的自动化。

Abstract: Artificial Intelligence agents represent the next major revolution in the
continuous technological evolution of industrial automation. In this paper, we
introduce a new approach for business process design and development that
leverages the capabilities of Agentic AI. Departing from the traditional
task-based approach to business process design, we propose an agent-based
method, where agents contribute to the achievement of business goals,
identified by a set of business objects. When a single agent cannot fulfill a
goal, we have a merge goal that can be achieved through the collaboration of
multiple agents. The proposed model leads to a more modular and intelligent
business process development by organizing it around goals, objects, and
agents. As a result, this approach enables flexible and context-aware
automation in dynamic industrial environments.

</details>


### [215] [DualSG: A Dual-Stream Explicit Semantic-Guided Multivariate Time Series Forecasting Framework](https://arxiv.org/abs/2507.21830)
*Kuiye Ding,Fanda Fan,Yao Wang,Ruijie jian,Xiaorui Wang,Luqi Gong,Yishan Jiang,Chunjie Luo an Jianfeng Zhan*

Main category: cs.AI

TL;DR: 此论文提出DualSG框架，利用大语言模型作为语义指导模块改进多变时间序列预测，实验显示其优于15个当前先进方法。


<details>
  <summary>Details</summary>
Motivation: 解决使用LLMs作为端到端预测工具时数值精度的损失和对模式处理的限制，以及在潜在空间中进行文本和时间序列属性对齐的困难。

Method: 提出了DualSG，一个双流框架，通过时间序列说明和语义指导来优化传统预测，同时引入一个标题指导的融合模块。

Result: 在不同领域的真实数据集上的实验表明，DualSG能持续超过15种当前最好的基线方法。

Conclusion: DualSG通过明确结合数值预测与语义指导，在多变时间序列预测中优于15个最先进的方法，展示了其价值。

Abstract: Multivariate Time Series Forecasting plays a key role in many applications.
Recent works have explored using Large Language Models for MTSF to take
advantage of their reasoning abilities. However, many methods treat LLMs as
end-to-end forecasters, which often leads to a loss of numerical precision and
forces LLMs to handle patterns beyond their intended design. Alternatively,
methods that attempt to align textual and time series modalities within latent
space frequently encounter alignment difficulty. In this paper, we propose to
treat LLMs not as standalone forecasters, but as semantic guidance modules
within a dual-stream framework. We propose DualSG, a dual-stream framework that
provides explicit semantic guidance, where LLMs act as Semantic Guides to
refine rather than replace traditional predictions. As part of DualSG, we
introduce Time Series Caption, an explicit prompt format that summarizes trend
patterns in natural language and provides interpretable context for LLMs,
rather than relying on implicit alignment between text and time series in the
latent space. We also design a caption-guided fusion module that explicitly
models inter-variable relationships while reducing noise and computation.
Experiments on real-world datasets from diverse domains show that DualSG
consistently outperforms 15 state-of-the-art baselines, demonstrating the value
of explicitly combining numerical forecasting with semantic guidance.

</details>


### [216] [Probabilistic Active Goal Recognition](https://arxiv.org/abs/2507.21846)
*Chenyuan Zhang,Cristian Rojas Cardenas,Hamid Rezatofighi,Mor Vered,Buser Say*

Main category: cs.AI

TL;DR: 本文提出了一种融合联合信念更新机制和蒙特卡洛树搜索算法的概率框架，有效地在多智能体环境中进行主动目标识别。实验证明该方法显著优于被动识别技术。


<details>
  <summary>Details</summary>
Motivation: 在多智能体环境中，有效的互动依赖于理解其他智能体的信念和意图。主动目标识别（AGR）通过战略性地收集信息以降低不确定性，推动了现有研究中的被动观察转向主动参与。

Method: 采用了一种概率框架进行主动目标识别，并提出了一种集成解决方案，将联合信念更新机制与蒙特卡洛树搜索（MCTS）算法相结合，使观察者能够高效规划并推断演员的隐秘目标。

Result: 通过在网格基础领域的全面实证评估，我们证明了联合信念更新显著优于被动目标识别，域无关的MCTS与强大的领域特定的贪婪基准表现相当。

Conclusion: 我们提出的联合信念更新和蒙特卡洛树搜索算法提供了一个强大的通用平台，能够在不依赖领域特定知识的情况下有效识别多智能体环境中的目标。我们的结果表明，该方案在主动目标识别方面比传统的被动方法表现优异，标志着向更具互动性和适应性的多智能体系统的进步。

Abstract: In multi-agent environments, effective interaction hinges on understanding
the beliefs and intentions of other agents. While prior work on goal
recognition has largely treated the observer as a passive reasoner, Active Goal
Recognition (AGR) focuses on strategically gathering information to reduce
uncertainty. We adopt a probabilistic framework for Active Goal Recognition and
propose an integrated solution that combines a joint belief update mechanism
with a Monte Carlo Tree Search (MCTS) algorithm, allowing the observer to plan
efficiently and infer the actor's hidden goal without requiring domain-specific
knowledge. Through comprehensive empirical evaluation in a grid-based domain,
we show that our joint belief update significantly outperforms passive goal
recognition, and that our domain-independent MCTS performs comparably to our
strong domain-specific greedy baseline. These results establish our solution as
a practical and robust framework for goal inference, advancing the field toward
more interactive and adaptive multi-agent systems.

</details>


### [217] [EDGE-GRPO: Entropy-Driven GRPO with Guided Error Correction for Advantage Diversity](https://arxiv.org/abs/2507.21848)
*Xingjian Zhang,Siwei Wen,Wenjun Wu,Lei Huang*

Main category: cs.AI

TL;DR: 论文提出EDGE-GRPO算法，通过熵驱动优势和误差纠正，解决GRPO算法中的优势崩溃问题，实验结果显示其在推理基准上具有优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的GRPO算法由于奖励稀疏，会出现优势崩溃问题。需要改进算法以增强模型反思能力和内部反馈，以克服这一挑战。

Method: 使用熵驱动优势和引导误差纠正的方法，以解决优势崩溃问题。通过实验和主要推理基准的测试来验证该方法的有效性。

Result: EDGE-GRPO算法在多个主要推理基准上进行了广泛的实验，证明了其有效性和优越性。

Conclusion: EDGE-GRPO算法通过熵驱动优势和引导误差纠正，有效解决了优势崩溃的问题。广泛实验表明，其效果和性能优于现有方法。

Abstract: Large Language Models (LLMs) have made remarkable progress in enhancing
step-by-step reasoning through reinforcement learning. However, the Group
Relative Policy Optimization (GRPO) algorithm, which relies on sparse reward
rules, often encounters the issue of identical rewards within groups, leading
to the advantage collapse problem. Existing works typically address this
challenge from two perspectives: enforcing model reflection to enhance response
diversity, and introducing internal feedback to augment the training signal
(advantage). In this work, we begin by analyzing the limitations of model
reflection and investigating the policy entropy of responses at the
fine-grained sample level. Based on our experimental findings, we propose the
EDGE-GRPO algorithm, which adopts \textbf{E}ntropy-\textbf{D}riven Advantage
and \textbf{G}uided \textbf{E}rror Correction to effectively mitigate the
problem of advantage collapse. Extensive experiments on several main reasoning
benchmarks demonstrate the effectiveness and superiority of our approach. It is
available at https://github.com/ZhangXJ199/EDGE-GRPO.

</details>


### [218] [MultiEditor: Controllable Multimodal Object Editing for Driving Scenarios Using 3D Gaussian Splatting Priors](https://arxiv.org/abs/2507.21872)
*Shouyi Lu,Zihan Lin,Chao Lu,Huanran Wang,Guirong Zhuo,Lianqing Zheng*

Main category: cs.AI

TL;DR: MultiEditor通过改进图像和LiDAR数据编辑，提升了自动驾驶系统对稀有车辆类别的检测性能。


<details>
  <summary>Details</summary>
Motivation: 为了克服实际数据的长尾分布对罕见但安全关键车辆类别的泛化能力的限制，提出了MultiEditor。

Method: 提出了MultiEditor，一种双分支潜在扩散框架，能够联合编辑驾驶场景中的图像和LiDAR点云。采用3D高斯展布作为目标对象的结构和外观先验，并引入深度引导的可变形跨模态条件模块，增强跨模态一致性。

Result: MultiEditor在视觉和几何保真度、编辑可控性及跨模态一致性方面表现优异，并通过生成稀有类别车辆数据提升了感知模型的检测精度。

Conclusion: MultiEditor增强了感知模型对未被充分代表类别的检测准确性。

Abstract: Autonomous driving systems rely heavily on multimodal perception data to
understand complex environments. However, the long-tailed distribution of
real-world data hinders generalization, especially for rare but safety-critical
vehicle categories. To address this challenge, we propose MultiEditor, a
dual-branch latent diffusion framework designed to edit images and LiDAR point
clouds in driving scenarios jointly. At the core of our approach is introducing
3D Gaussian Splatting (3DGS) as a structural and appearance prior for target
objects. Leveraging this prior, we design a multi-level appearance control
mechanism--comprising pixel-level pasting, semantic-level guidance, and
multi-branch refinement--to achieve high-fidelity reconstruction across
modalities. We further propose a depth-guided deformable cross-modality
condition module that adaptively enables mutual guidance between modalities
using 3DGS-rendered depth, significantly enhancing cross-modality consistency.
Extensive experiments demonstrate that MultiEditor achieves superior
performance in visual and geometric fidelity, editing controllability, and
cross-modality consistency. Furthermore, generating rare-category vehicle data
with MultiEditor substantially enhances the detection accuracy of perception
models on underrepresented classes.

</details>


### [219] [A Neuro-Symbolic Approach for Probabilistic Reasoning on Graph Data](https://arxiv.org/abs/2507.21873)
*Raffaele Pojer,Andrea Passerini,Kim G. Larsen,Manfred Jaeger*

Main category: cs.AI

TL;DR: 本文提出了一种将图神经网络（GNNs）与关系贝叶斯网络（RBNs）集成的神经符号框架，以结合两者的优点，并在节点分类与环境规划中显示了有效性。


<details>
  <summary>Details</summary>
Motivation: 虽然GNNs在图结构数据上的预测任务中表现出色，但缺乏结合符号领域知识和执行通用推理的能力。相反，RBNs能够在类图结构上进行完全生成的概率建模，并支持丰富的符号知识和概率推理。

Method: 提出了一种将GNNs无缝集成到RBNs中的神经符号框架，并开发了两种实现方案：一种是将GNN编译到RBN的原生语言中，另一种是将GNN作为外部组件保留。

Result: 通过将GNNs和RBNs结合，改进了节点分类任务和环境规划中的复杂决策问题中的准确性和性能。

Conclusion: 这项工作提出了一种有力且一致的神经符号方法，将GNNs的学习能力与RBNs的灵活推理能力结合。

Abstract: Graph neural networks (GNNs) excel at predictive tasks on graph-structured
data but often lack the ability to incorporate symbolic domain knowledge and
perform general reasoning. Relational Bayesian Networks (RBNs), in contrast,
enable fully generative probabilistic modeling over graph-like structures and
support rich symbolic knowledge and probabilistic inference. This paper
presents a neuro-symbolic framework that seamlessly integrates GNNs into RBNs,
combining the learning strength of GNNs with the flexible reasoning
capabilities of RBNs.
  We develop two implementations of this integration: one compiles GNNs
directly into the native RBN language, while the other maintains the GNN as an
external component. Both approaches preserve the semantics and computational
properties of GNNs while fully aligning with the RBN modeling paradigm. We also
propose a maximum a-posteriori (MAP) inference method for these neuro-symbolic
models.
  To demonstrate the framework's versatility, we apply it to two distinct
problems. First, we transform a GNN for node classification into a collective
classification model that explicitly models homo- and heterophilic label
patterns, substantially improving accuracy. Second, we introduce a
multi-objective network optimization problem in environmental planning, where
MAP inference supports complex decision-making. Both applications include new
publicly available benchmark datasets.
  This work introduces a powerful and coherent neuro-symbolic approach to graph
data, bridging learning and reasoning in ways that enable novel applications
and improved performance across diverse tasks.

</details>


### [220] [Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis](https://arxiv.org/abs/2507.21875)
*Stefanos Gkikas,Ioannis Kyprakis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: 研究提出了Tiny-BioMoE，一个轻量级模型，通过多种生理信号准确评估疼痛，且其开源模型显示出卓越的性能。


<details>
  <summary>Details</summary>
Motivation: 疼痛评估在医疗管理中至关重要，自动疼痛评估系统帮助持续监控，支持临床决策。利用生理信号提供更精确的客观评估。

Method: 本研究介绍了Tiny-BioMoE，这是一个用于生物信号分析的轻量级预训练嵌入模型，包含730万个参数。通过电导活动、血容量脉搏、呼吸信号、外周氧饱和度等信号的广泛实验，验证了其效果。

Result: Tiny-BioMoE在多个生理信号的联合使用下，在自动疼痛识别任务中取得了显著的效果，且相关模型架构和权重已在Github上开源。

Conclusion: Tiny-BioMoE模型在多种模式下的自动疼痛识别任务中表现出色，展示了其在痛觉评估中潜力。

Abstract: Pain is a complex and pervasive condition that affects a significant portion
of the population. Accurate and consistent assessment is essential for
individuals suffering from pain, as well as for developing effective management
strategies in a healthcare system. Automatic pain assessment systems enable
continuous monitoring, support clinical decision-making, and help minimize
patient distress while mitigating the risk of functional deterioration.
Leveraging physiological signals offers objective and precise insights into a
person's state, and their integration in a multimodal framework can further
enhance system performance. This study has been submitted to the \textit{Second
Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The
proposed approach introduces \textit{Tiny-BioMoE}, a lightweight pretrained
embedding model for biosignal analysis. Trained on $4.4$ million biosignal
image representations and consisting of only $7.3$ million parameters, it
serves as an effective tool for extracting high-quality embeddings for
downstream tasks. Extensive experiments involving electrodermal activity, blood
volume pulse, respiratory signals, peripheral oxygen saturation, and their
combinations highlight the model's effectiveness across diverse modalities in
automatic pain recognition tasks. \textit{\textcolor{blue}{The model's
architecture (code) and weights are available at
https://github.com/GkikasStefanos/Tiny-BioMoE.

</details>


### [221] [Multi-Representation Diagrams for Pain Recognition: Integrating Various Electrodermal Activity Signals into a Single Image](https://arxiv.org/abs/2507.21881)
*Stefanos Gkikas,Ioannis Kyprakis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: 新方法使用皮电活动信号进行多重表示组合，取得了比传统方法更好的疼痛评估效果。


<details>
  <summary>Details</summary>
Motivation: 由于疼痛影响了大量人群，因此迫切需要可靠和一致的评估方法，以帮助改善疼痛管理策略。在临床决策中，自动疼痛评估系统能够提供持续监测，减少痛苦，防止功能退化。通过整合生理信号，该系统可以提供客观而准确的个体状态分析。

Method: 提出了一种新的管道方法，将皮电活动信号作为输入模态。多种信号表示形式被创建并以波形可视化，并在一个单一的多表示图中共同可视化。在广泛的实验中，该方法结合了各种处理和过滤技术，以及多种表示组合。

Result: 实验表明，该方法在结果与传统融合方法相比具有可比性，在某些情况下甚至优于传统方法，确立其为整合不同信号表示或模态的稳健替代方案。

Conclusion: 提出的方法通过使用皮电活动和多重表示组合，实现了在疼痛评估中的有效性与优越性，可作为整合不同信号的稳健替代方案。

Abstract: Pain is a multifaceted phenomenon that affects a substantial portion of the
population. Reliable and consistent evaluation benefits those experiencing pain
and underpins the development of effective and advanced management strategies.
Automatic pain-assessment systems deliver continuous monitoring, inform
clinical decision-making, and aim to reduce distress while preventing
functional decline. By incorporating physiological signals, these systems
provide objective, accurate insights into an individual's condition. This study
has been submitted to the \textit{Second Multimodal Sensing Grand Challenge for
Next-Gen Pain Assessment (AI4PAIN)}. The proposed method introduces a pipeline
that leverages electrodermal activity signals as input modality. Multiple
representations of the signal are created and visualized as waveforms, and they
are jointly visualized within a single multi-representation diagram. Extensive
experiments incorporating various processing and filtering techniques, along
with multiple representation combinations, demonstrate the effectiveness of the
proposed approach. It consistently yields comparable, and in several cases
superior, results to traditional fusion methods, establishing it as a robust
alternative for integrating different signal representations or modalities.

</details>


### [222] [The Impact of Foundational Models on Patient-Centric e-Health Systems](https://arxiv.org/abs/2507.21882)
*Elmira Onagh,Alireza Davoodi,Maleknaz Nayebi*

Main category: cs.AI

TL;DR: 研究分析116个患者中心医疗应用程序的AI集成程度，结果显示大部分应用仍在AI集成的初级阶段。


<details>
  <summary>Details</summary>
Motivation: 理解AI在患者中心应用中的成熟度对于评估其可信度、透明度和实际影响至关重要。

Method: 使用大语言模型（LLMs）提取关键功能特性，并将其分类到Gartner AI成熟度模型的不同阶段。

Result: 调查显示，大多数医疗应用处于AI集成的早期阶段。

Conclusion: 大部分（86.21%）患者中心的医疗应用程序仍处于AI集成的早期阶段，只有13.79%的应用程序展示了先进的AI集成。

Abstract: As Artificial Intelligence (AI) becomes increasingly embedded in healthcare
technologies, understanding the maturity of AI in patient-centric applications
is critical for evaluating its trustworthiness, transparency, and real-world
impact. In this study, we investigate the integration and maturity of AI
feature integration in 116 patient-centric healthcare applications. Using Large
Language Models (LLMs), we extracted key functional features, which are then
categorized into different stages of the Gartner AI maturity model. Our results
show that over 86.21\% of applications remain at the early stages of AI
integration, while only 13.79% demonstrate advanced AI integration.

</details>


### [223] [Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline](https://arxiv.org/abs/2507.21886)
*Stefanos Gkikas,Ioannis Kyprakis,Manolis Tsiknakis*

Main category: cs.AI

TL;DR: 研究提出了一种利用呼吸信号和交叉注意力变压器的管道，用于痛苦评估。这种方法通过多窗口策略提高模型表现能力，并证明紧凑模型可以超越大型模型。


<details>
  <summary>Details</summary>
Motivation: 准确和持续的痛苦评估对于经历痛苦的人至关重要，并有助于有效和先进管理策略的发展。自动化痛苦评估系统提供持续监测并支持临床决策，旨在减少痛苦和防止功能下降。

Method: 提出了一种利用呼吸作为输入信号的管道，并结合了高效的交叉注意力变压器以及多窗口策略。

Result: 呼吸被证明是一种用于痛苦评估的有价值的生理方式。实验表明，经过适当优化的紧凑高效模型能够实现强大的性能，常常超越规模更大的模型。所提出的多窗口方法有效地捕捉了短期和长期特征以及全局特性，从而增强了模型的表现能力。

Conclusion: 利用呼吸信号和高效的交叉注意力变压器以及多窗口策略可以提高自动疼痛评估系统的表现能力。

Abstract: Pain is a complex condition affecting a large portion of the population.
Accurate and consistent evaluation is essential for individuals experiencing
pain, and it supports the development of effective and advanced management
strategies. Automatic pain assessment systems provide continuous monitoring and
support clinical decision-making, aiming to reduce distress and prevent
functional decline. This study has been submitted to the \textit{Second
Multimodal Sensing Grand Challenge for Next-Gen Pain Assessment (AI4PAIN)}. The
proposed method introduces a pipeline that leverages respiration as the input
signal and incorporates a highly efficient cross-attention transformer
alongside a multi-windowing strategy. Extensive experiments demonstrate that
respiration is a valuable physiological modality for pain assessment. Moreover,
experiments revealed that compact and efficient models, when properly
optimized, can achieve strong performance, often surpassing larger
counterparts. The proposed multi-window approach effectively captures both
short-term and long-term features, as well as global characteristics, thereby
enhancing the model's representational capacity.

</details>


### [224] [LLM-based Content Classification Approach for GitHub Repositories by the README Files](https://arxiv.org/abs/2507.21899)
*Malik Uzair Mehmood,Shahid Hussain,Wen Li Wang,Muhammad Usama Malik*

Main category: cs.AI

TL;DR: 研究提出了利用细调的LLMs来自动分类GitHub README文件中的不同部分，提高GitHub仓库的使用潜力。


<details>
  <summary>Details</summary>
Motivation: GitHub的README文件往往没有达到推荐的详细程度，影响其采用和使用率。本研究探讨README文件的全面性对其接受和使用的影响，并提出解决方案。

Method: 在研究中，使用了BERT、DistilBERT和RoBERTa三种编码器专用的LLM，通过参数高效的微调技术进行细化，并使用4226个README文件段落的金标准数据集进行训练。

Result: 该方法超越当前最先进的方法，实现了整体F1分数0.98，并探讨使用参数高效微调技术如LoRA，作为不损失性能的经济替代方案。

Conclusion: 研究证明LLMs可用来设计GitHub README文件内容自动分类器，并为改进GitHub仓库的识别和潜在使用开发自动化工具。

Abstract: GitHub is the world's most popular platform for storing, sharing, and
managing code. Every GitHub repository has a README file associated with it.
The README files should contain project-related information as per the
recommendations of GitHub to support the usage and improvement of repositories.
However, GitHub repository owners sometimes neglected these recommendations.
This prevents a GitHub repository from reaching its full potential. This
research posits that the comprehensiveness of a GitHub repository's README file
significantly influences its adoption and utilization, with a lack of detail
potentially hindering its full potential for widespread engagement and impact
within the research community. Large Language Models (LLMs) have shown great
performance in many text-based tasks including text classification, text
generation, text summarization and text translation. In this study, an approach
is developed to fine-tune LLMs for automatically classifying different sections
of GitHub README files. Three encoder-only LLMs are utilized, including BERT,
DistilBERT and RoBERTa. These pre-trained models are then fine-tuned based on a
gold-standard dataset consisting of 4226 README file sections. This approach
outperforms current state-of-the-art methods and has achieved an overall F1
score of 0.98. Moreover, we have also investigated the use of
Parameter-Efficient Fine-Tuning (PEFT) techniques like Low-Rank Adaptation
(LoRA) and shown an economical alternative to full fine-tuning without
compromising much performance. The results demonstrate the potential of using
LLMs in designing an automatic classifier for categorizing the content of
GitHub README files. Consequently, this study contributes to the development of
automated tools for GitHub repositories to improve their identifications and
potential usages.

</details>


### [225] [Libra: Large Chinese-based Safeguard for AI Content](https://arxiv.org/abs/2507.21929)
*Ziyang Chen,Huimu Yu,Xing Wu,Dongqin Liu,Songlin Hu*

Main category: cs.AI

TL;DR: 研究提出Libra-Guard系统以提高中文LLM的安全性，采用两阶段训练减少人工注释需求，并引入Libra-Test评估其有效性。结果显示Libra-Guard表现优异，接近闭源模型。


<details>
  <summary>Details</summary>
Motivation: LLM在文本理解和生成方面表现卓越，但在高风险应用中存在显著的安全和伦理问题。为降低这些风险，需开发用于提高中文LLM安全性的系统。

Method: 采用两阶段课程训练流程，先进行合成样本的训练，再进行高质量真实数据的微调，从而减少对人工注释的依赖。此外，设计了Libra-Test基准，以通过领域专家的注释样本进行严谨的安全评估。

Result: Libra-Guard系统在安全评估中取得了86.79%的准确率，优于其他开源模型（例如Qwen2.5-14B-Instruct的74.33%及ShieldLM-Qwen-14B-Chat的65.69%），并接近闭源模型Claude-3.5-Sonnet和GPT-4o。

Conclusion: Libra-Guard和Libra-Test系统为提高中文大语言模型(LLM)的安全性提供了坚实的框架。实验结果显示Libra-Guard在安全评估中的性能优于其他开源模型，接近一些闭源模型。这些贡献为开发更安全、更可靠的中文AI系统奠定了基础。

Abstract: Large language models (LLMs) excel in text understanding and generation but
raise significant safety and ethical concerns in high-stakes applications. To
mitigate these risks, we present Libra-Guard, a cutting-edge safeguard system
designed to enhance the safety of Chinese-based LLMs. Leveraging a two-stage
curriculum training pipeline, Libra-Guard enhances data efficiency by employing
guard pretraining on synthetic samples, followed by fine-tuning on
high-quality, real-world data, thereby significantly reducing reliance on
manual annotations. To enable rigorous safety evaluations, we also introduce
Libra-Test, the first benchmark specifically designed to evaluate the
effectiveness of safeguard systems for Chinese content. It covers seven
critical harm scenarios and includes over 5,700 samples annotated by domain
experts. Experiments show that Libra-Guard achieves 86.79% accuracy,
outperforming Qwen2.5-14B-Instruct (74.33%) and ShieldLM-Qwen-14B-Chat
(65.69%), and nearing closed-source models like Claude-3.5-Sonnet and GPT-4o.
These contributions establish a robust framework for advancing the safety
governance of Chinese LLMs and represent a tentative step toward developing
safer, more reliable Chinese AI systems.

</details>


### [226] [UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding](https://arxiv.org/abs/2507.22025)
*Shuquan Lian,Yuhang Wu,Jia Ma,Zihan Song,Bingqi Chen,Xiawu Zheng,Hui Li*

Main category: cs.AI

TL;DR: UI-AGILE introduces new approaches to training and inference for GUI agents, achieving a significant boost in performance and setting new standards on benchmarks.


<details>
  <summary>Details</summary>
Motivation: Address limitations of current GUI agent training and inference techniques, including reasoning design dilemmas, ineffective rewards, and visual noise challenges.

Method: Proposes improvements for the Supervised Fine-Tuning process in training and introduces Decomposed Grounding with Selection for inference, aiming at improving precision and efficiency.

Result: UI-AGILE shows significant performance improvements, notably a 23% increase in grounding accuracy on the ScreenSpot-Pro benchmark compared to the best baseline.

Conclusion: UI-AGILE framework effectively enhances GUI agent performance, achieving state-of-the-art results on benchmarks with significant improvements in grounding accuracy.

Abstract: The emergence of Multimodal Large Language Models (MLLMs) has driven
significant advances in Graphical User Interface (GUI) agent capabilities.
Nevertheless, existing GUI agent training and inference techniques still suffer
from a dilemma for reasoning designs, ineffective reward, and visual noise. To
address these issues, we introduce UI-AGILE, a comprehensive framework
enhancing GUI agents at both the training and inference stages. For training,
we propose a suite of improvements to the Supervised Fine-Tuning (SFT) process:
1) a Continuous Reward function to incentivize high-precision grounding; 2) a
"Simple Thinking" reward to balance planning with speed and grounding accuracy;
and 3) a Cropping-based Resampling strategy to mitigate the sparse reward
problem and improve learning on complex tasks. For inference, we present
Decomposed Grounding with Selection, a novel method that dramatically improves
grounding accuracy on high-resolution displays by breaking the image into
smaller, manageable parts. Experiments show that UI-AGILE achieves the
state-of-the-art performance on two benchmarks ScreenSpot-Pro and
ScreenSpot-v2. For instance, using both our proposed training and inference
enhancement methods brings 23% grounding accuracy improvement over the best
baseline on ScreenSpot-Pro.

</details>


### [227] [Thou Shalt Not Prompt: Zero-Shot Human Activity Recognition in Smart Homes via Language Modeling of Sensor Data & Activities](https://arxiv.org/abs/2507.21964)
*Sourish Gunesh Dhekane,Thomas Ploetz*

Main category: cs.AI

TL;DR: 提出了一种不依赖于提示LLM的零样本人类活动识别方法，利用自然语言和嵌入进行分类，避免现有方法的隐私和一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本人类活动识别方法依赖于对大型语言模型（LLM）的提示，但存在隐私风险、依赖外部服务以及由于版本变化导致预测不一致的问题，因此需要开发新的方法。

Method: 提出了一种利用自然语言及其嵌入进行零样本分类的方法，从而绕过对LLM进行提示的需求。

Result: 论文通过基于六个数据集的详细案例研究，展示了语言建模如何在零样本人类活动识别中增强HAR系统。

Conclusion: 通过使用自然语言描述传感器数据和活动并利用其嵌入进行零样本分类，可以避免依赖于LLM的提示，从而实现更加可靠的零样本人类活动识别。

Abstract: Developing zero-shot human activity recognition (HAR) methods is a critical
direction in smart home research -- considering its impact on making HAR
systems work across smart homes having diverse sensing modalities, layouts, and
activities of interest. The state-of-the-art solutions along this direction are
based on generating natural language descriptions of the sensor data and
feeding it via a carefully crafted prompt to the LLM to perform classification.
Despite their performance guarantees, such ``prompt-the-LLM'' approaches carry
several risks, including privacy invasion, reliance on an external service, and
inconsistent predictions due to version changes, making a case for alternative
zero-shot HAR methods that do not require prompting the LLMs. In this paper, we
propose one such solution that models sensor data and activities using natural
language, leveraging its embeddings to perform zero-shot classification and
thereby bypassing the need to prompt the LLMs for activity predictions. The
impact of our work lies in presenting a detailed case study on six datasets,
highlighting how language modeling can bolster HAR systems in zero-shot
recognition.

</details>


### [228] [UserBench: An Interactive Gym Environment for User-Centric Agents](https://arxiv.org/abs/2507.22034)
*Cheng Qian,Zuxin Liu,Akshara Prabhakar,Zhiwei Liu,Jianguo Zhang,Haolin Chen,Heng Ji,Weiran Yao,Shelby Heinecke,Silvio Savarese,Caiming Xiong,Huan Wang*

Main category: cs.AI

TL;DR: 本文提出UserBench，以评估代理在与用户模糊目标和偏好的多轮交互中的合作能力，揭示当前LLMs在任务完成与用户对齐方面的限制。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs在与用户主动合作方面的能力，特别是在用户目标模糊、不断变化或间接表达的情况下。

Method: 引入了UserBench，一个用户中心的基准，用于评估代理在多轮、偏好驱动的交互中的表现。UserBench模拟用户开始时目标不明确，并逐步透露偏好，要求模型主动澄清意图并使用工具进行决策。

Result: 最先进的模型在探索用户偏好方面仅能发现不到30%。这些结果表明，构建能够主动合作的代理仍然具有挑战性。

Conclusion: 当前的LLMs在任务完成与用户对齐方面存在显著脱节，不能完全满足用户的所有意图和偏好。

Abstract: Large Language Models (LLMs)-based agents have made impressive progress in
reasoning and tool use, enabling them to solve complex tasks. However, their
ability to proactively collaborate with users, especially when goals are vague,
evolving, or indirectly expressed, remains underexplored. To address this gap,
we introduce UserBench, a user-centric benchmark designed to evaluate agents in
multi-turn, preference-driven interactions. UserBench features simulated users
who start with underspecified goals and reveal preferences incrementally,
requiring agents to proactively clarify intent and make grounded decisions with
tools. Our evaluation of leading open- and closed-source LLMs reveals a
significant disconnect between task completion and user alignment. For
instance, models provide answers that fully align with all user intents only
20% of the time on average, and even the most advanced models uncover fewer
than 30% of all user preferences through active interaction. These results
highlight the challenges of building agents that are not just capable task
executors, but true collaborative partners. UserBench offers an interactive
environment to measure and advance this critical capability.

</details>


### [229] [Reasoning Language Models for Root Cause Analysis in 5G Wireless Networks](https://arxiv.org/abs/2507.21974)
*Mohamed Sana,Nicola Piovesan,Antonio De Domenico,Yibin Kang,Haozhe Zhang,Merouane Debbah,Fadhel Ayed*

Main category: cs.AI

TL;DR: 提出了一种使用大型语言模型进行故障根本原因分析的轻量框架，通过两阶段训练方法进行领域适应，实验表明性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有开源推理大模型在故障根本原因分析能力上存在困难，强调领域适应以提高其表现。

Method: 提出了一种两阶段训练方法，结合监督微调和强化学习，以提高大型语言模型的准确性和推理质量。

Result: 大量实验表明，经过领域适应的大模型在多个尺寸上实现显著的性能提升，包括对随机化测试变体的强泛化能力。

Conclusion: 带有推理增强的领域适应型大型语言模型在网络运营和管理中具有实用性和可解释性，对于实际故障根本原因分析有着良好的表现。

Abstract: Root Cause Analysis (RCA) in mobile networks remains a challenging task due
to the need for interpretability, domain expertise, and causal reasoning. In
this work, we propose a lightweight framework that leverages Large Language
Models (LLMs) for RCA. To do so, we introduce TeleLogs, a curated dataset of
annotated troubleshooting problems designed to benchmark RCA capabilities. Our
evaluation reveals that existing open-source reasoning LLMs struggle with these
problems, underscoring the need for domain-specific adaptation. To address this
issue, we propose a two-stage training methodology that combines supervised
fine-tuning with reinforcement learning to improve the accuracy and reasoning
quality of LLMs. The proposed approach fine-tunes a series of RCA models to
integrate domain knowledge and generate structured, multi-step diagnostic
explanations, improving both interpretability and effectiveness. Extensive
experiments across multiple LLM sizes show significant performance gains over
state-of-the-art reasoning and non-reasoning models, including strong
generalization to randomized test variants. These results demonstrate the
promise of domain-adapted, reasoning-enhanced LLMs for practical and
explainable RCA in network operation and management.

</details>


### [230] [The Effect of Compression Techniques on Large Multimodal Language Models in the Medical Domain](https://arxiv.org/abs/2507.21976)
*Tanvir Ahmed Khan,Aranya Saha,Ismam Nur Swapnil,Mohammad Ariful Haque*

Main category: cs.AI

TL;DR: 研究了结构裁剪和量化对微调LLAVA模型在医疗应用中的影响，提出了一种新的层选择方法，使得7B参数的模型能在4GB内存中运行，减少内存使用70%，模型性能提高4%。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在医疗领域有巨大潜力，但由于计算成本高，需要高效的压缩技术来降低使用的计算资源。

Method: 我们使用了一种新颖的层选择方法进行裁剪，并分析不同的量化技术，通过裁剪-微调-量化的流程评估性能权衡。

Result: 提出的方法减少了70%的内存使用，同时在相同比例的压缩下提高了4%的模型性能。

Conclusion: 通过使用结构裁剪和激活感知量化技术，提出了一种使7B参数的多模态LLM运行在4GB VRAM中的新方法，显著减少了内存使用，同时相较于传统裁剪和量化技术提高了模型性能。

Abstract: Multimodal Large Language Models (MLLMs) hold huge potential for usage in the
medical domain, but their computational costs necessitate efficient compression
techniques. This paper evaluates the impact of structural pruning and
activation-aware quantization on a fine-tuned LLAVA model for medical
applications. We propose a novel layer selection method for pruning, analyze
different quantization techniques, and assess the performance trade-offs in a
prune-SFT-quantize pipeline. Our proposed method enables MLLMs with 7B
parameters to run within 4 GB of VRAM, reducing memory usage by 70% while
achieving 4% higher model performance compared to traditional pruning and
quantization techniques in the same compression ratio.

</details>


### [231] [PHAX: A Structured Argumentation Framework for User-Centered Explainable AI in Public Health and Biomedical Sciences](https://arxiv.org/abs/2507.22009)
*Bahar İlgen,Akshat Dubey,Georges Hattab*

Main category: cs.AI

TL;DR: PHAX框架通过结构化辩论为公共卫生AI提供以人为本的解释，提高了透明度和信任。


<details>
  <summary>Details</summary>
Motivation: 在公共卫生和生物医学科学系统中确保透明度和信任不仅需要准确的预测，还需要清晰、情境化、社会责任的解释。现有的可解释AI方法缺乏应对不同健康利益相关者（如临床医生、政策制定者和公众）的结构和适应性。

Method: PHAX框架是一个多层架构，结合了可废推理、自适应自然语言技术和用户建模，以产生情境感知和面向受众的正当性。

Result: 通过用例展示PHAX的适用性，包括医学术语简化、患者与临床医生的沟通以及政策的正当性。特别是，展示了如何将简化决策建模为论证链，并根据用户专业知识进行个性化，提高了解释性和信任。

Conclusion: PHAX通过将正式推理方法与沟通需求对齐，为公共卫生中透明、以人为本的AI提供了支持。

Abstract: Ensuring transparency and trust in AI-driven public health and biomedical
sciences systems requires more than accurate predictions-it demands
explanations that are clear, contextual, and socially accountable. While
explainable AI (XAI) has advanced in areas like feature attribution and model
interpretability, most methods still lack the structure and adaptability needed
for diverse health stakeholders, including clinicians, policymakers, and the
general public. We introduce PHAX-a Public Health Argumentation and
eXplainability framework-that leverages structured argumentation to generate
human-centered explanations for AI outputs. PHAX is a multi-layer architecture
combining defeasible reasoning, adaptive natural language techniques, and user
modeling to produce context-aware, audience-specific justifications. More
specifically, we show how argumentation enhances explainability by supporting
AI-driven decision-making, justifying recommendations, and enabling interactive
dialogues across user types. We demonstrate the applicability of PHAX through
use cases such as medical term simplification, patient-clinician communication,
and policy justification. In particular, we show how simplification decisions
can be modeled as argument chains and personalized based on user
expertise-enhancing both interpretability and trust. By aligning formal
reasoning methods with communicative demands, PHAX contributes to a broader
vision of transparent, human-centered AI in public health.

</details>


### [232] [The Interspeech 2025 Speech Accessibility Project Challenge](https://arxiv.org/abs/2507.22047)
*Xiuwen Zheng,Bornali Phukon,Jonghwan Na,Ed Cutrell,Kyu Han,Mark Hasegawa-Johnson,Pan-Pan Jiang,Aadhrik Kuila,Colin Lea,Bob MacDonald,Gautam Mantena,Venkatesh Ravichandran,Leda Sari,Katrin Tomanek,Chang D. Yoo,Chris Zwilling*

Main category: cs.AI

TL;DR: 语音可及性挑战项目显著提升了自动语音识别系统对语音障碍者的识别能力，多个团队超越基线表现，设定了新标准。


<details>
  <summary>Details</summary>
Motivation: 现有的自动语音识别系统在处理有语音障碍的个人时表现不佳，主要原因是公共训练数据不足。这篇论文旨在解决这一问题。

Method: 2025年国际语音学会发起了语音可及性项目挑战，收集了来自500多人、超过400小时的多样化语音障碍数据进行训练。挑战通过Word Error Rate和Semantic Score评估提交结果。

Result: 22个有效团队中有12个团队在Word Error Rate上表现优于基线系统，而17个团队在语义分数上超越了基线。顶尖团队实现了8.11%的最低Word Error Rate和88.44%的最高语义分数。

Conclusion: 此次语音可及性项目挑战为未来自动语音识别系统设定了新的基准，大幅提升了识别有障碍语音的能力。

Abstract: While the last decade has witnessed significant advancements in Automatic
Speech Recognition (ASR) systems, performance of these systems for individuals
with speech disabilities remains inadequate, partly due to limited public
training data. To bridge this gap, the 2025 Interspeech Speech Accessibility
Project (SAP) Challenge was launched, utilizing over 400 hours of SAP data
collected and transcribed from more than 500 individuals with diverse speech
disabilities. Hosted on EvalAI and leveraging the remote evaluation pipeline,
the SAP Challenge evaluates submissions based on Word Error Rate and Semantic
Score. Consequently, 12 out of 22 valid teams outperformed the whisper-large-v2
baseline in terms of WER, while 17 teams surpassed the baseline on SemScore.
Notably, the top team achieved the lowest WER of 8.11\%, and the highest
SemScore of 88.44\% at the same time, setting new benchmarks for future ASR
systems in recognizing impaired speech.

</details>
